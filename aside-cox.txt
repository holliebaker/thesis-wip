### An aside on polynomial ideals and Zariski closures

@lazard10 uses the trick of saturating the ideal $\langle f,g \rangle$ by some $h$, which is not a multiple of $g$. The key to this trick lies in Zariski closures.
We will now discuss how this proof works, with the aim of extending it to higher dimensions.
We will closely follow @cox2013 and all results are proved in a generic polynomial ring $K[x_1,\ldots,x_n]$ unless otherwise stated.

#### Ideals, Groebner bases and Buchberger's algorithm

::: {.definition}
Let $K[x_1,\ldots,x_n]$ be a polynomial ring. A subset $I \subset K[x_1,\ldots,x_n]$ is called a polynomial ideal if

- $0 \in I$,
- if $a,b \in I$ then $a+b \in I$, and
- if $a \in I, b \in K[x_1,\ldots,x_n]$, then $ab \in I$.
:::

::: {.definition}
Let $K$ be a field and $f_1,\ldots, f_k \in K[x_1,\ldots,x_n]$. We set
$$
\left\langle f_{1},\ldots,f_{k}\right\rangle =\left\{ h_{1}f_{1}+\cdots+h_{k}f_{k}\mid h_{1},\ldots,h_{k}\in K[x_{1},\ldots,h_{n}]\right\}
$$
and call it the ideal generated by $f_1,\ldots,f_k$.
:::

@hilbert1890 proved, nonconstructively, that every polynomial ideal is finitely generated.

::: {.theorem}
Every ideal $I \subset K[x_1, \ldots, x_n]$ has a finite generating set. I.e., $I = \langle g_1, \ldots, g_t\rangle$ for some finite collection of polynomials $g_1, \ldots, g_t\in I$.
:::

A proof can be found in [@cox2013, p76].

Later, @buchberger1965 published an algorithm for computing this finite set of generators. He also introduced the concept of a Groebner basis.

A Groebner basis requires an ordering on monomials to be defined first.

::: {.definition}
A monomial ordering on $K[x_1, \ldots, x_n]$ is a relation $\succ$ on $\Z^n_{\ge 0}$, or
equivalently, a relation on the set of monomials $x^\alpha, \alpha\in \Z_{\ge 0}$, satisfying the following properties.

- $\succ$ is a total order\footnote{
Total order: a reflexive, antisymmetric, and transinive relation $R$ on a set $X$ such that either $(a,b) \in R$ or $(b,a) \in R$ for all $a,b \in X$.
} on $\Z^n_{\ge 0}$.
- If $\alpha \succ \beta$ and $\gamma \in \Z^n_{\ge 0}$, then $\alpha + \gamma \succ \beta + \gamma$.
- $\succ$ is a well-ordering on $\Z^n_{\ge 0}$.
I.e., every nonempty subset of $\Z^n_{\ge 0}$ has a minimal element under $\succ$.
:::

Some examples of monomial orderings used in computing Groebner bases include

- **lex:** Let $\alpha = (\alpha_1, \ldots, \alpha_n), \beta = (\beta_1, \ldots, \beta_n) \in \Z^n_{\ge 0}$. We say $\alpha \succ \beta$ if the leftmost nonzero element of $\alpha - \beta \in \Z^n$ is positive. This imposes a lexicographic order on variables $x_1 \succ x_2 \succ \cdots \succ x_n$.

- **grlex:** (graded lex) Let $\alpha, \beta \in \Z^n_{\ge 0}$ and let $|\alpha| = \alpha_1 + \cdots + \alpha_n$ and $|\beta| = \beta_1 + \cdots + \beta_n$. We sate $\alpha \succ \beta$ if $|\alpha| > |\beta|$, or if $|\alpha| = |\beta|$ and $\alpha \succ_{\rm{lex}} \beta$.

- **grevlex:** (graded reverse lex) Let $\alpha, \beta \in \Z^n_{\ge 0}$, and d efine $|\alpha|$ and $|\beta|$ as before. We set $\alpha \succ_{\rm{grevlex}} \beta$ if $|\alpha| > |\beta|$ or if $|\alpha| = |\beta|$ and the rightmost nonzero entry of $\alpha - \beta$ is negative.

::: {.definition}
Let $f$ be a polynomial in $K[x_1,\ldots,x_n]$ with monomials labelled by indices in $\Z^n$, of the form $\sum_{\alpha} a_\alpha x_1^{\alpha_1} \cdots x_n^{\alpha_n}$, and fix a monomial order $\succ$. Define the following

- $\multideg(f) = \max\left( \alpha \in \Z^n_{\ge 0} \mid a_{\alpha} \ne 0 \right)$,

- $\lc(f) = a_{\alpha} \mid \alpha = \multideg(f)$,

- $\lm(f) = x_1^{\alpha_1} \cdots x_n^{\alpha_n} \mid \alpha = \multideg(f)$.

- $\ldt(f) = \lc(f) \cdot \lm(f)$
:::

::: {.definition}
Fix a monomial ordering $\succ$ on $K[x_1,\ldots,x_n]$. Let $I \subset K[x_1,\ldots,x_n]$ be an ideal. A finite set $G = \{ g_1, \ldots, g_t \} \subset I$ is called a Groebner basis if
$$
\langle \ldt(g_1),\ldots,\ldt(g_t) \rangle = \langle\ldt(I)\rangle
$$
where $\ldt(I) = \{ \ldt(f) \mid f \in I \}$
:::

::: {.definition}
We write $\overline{f}^{F}$ for the remainder of division of $f$ by the tuple $F = (g_1,\ldots,g_t)$. If $F$ is a Groebner basis, $F$ can be considered as an (unordered) set by [@cox2013 p83, Proposition 1].
:::

::: {.definition}
Let $f,g \in K[x_1,\ldots,x_n]$ such that $\multideg(f) = \alpha$ and $\multideg(g) = \beta$. Define $\gamma = \max(\alpha, \beta)$ (where $\max$ is taken component-wise). $x_1^{\gamma^1} \cdots x_n^{\gamma^n} = \lcm ( \lm(f), \lm(g) )$ is called the least common multiple of the leading monomials of $f$ and $g$.
:::

::: {.lemma #multideg}
Let $f,g \in K[x_1,\ldots,x_n]$ be nonzero polynomials. Then

1. $\multideg(fg) = \multideg(f) + \multideg(g)$,

2. If $f+g \ne 0$ then $\multideg(f+g) \le \max(\multideg(f), \multideg(g))$.
  As a special case, if $\multideg(f) \ne \multideg(g)$ then equality occurs.
:::

::: {.proof}
Write $f = ax^\alpha + f'$ and $f = bx^\beta + g'$ so that $\multideg(f) = \alpha$ and $\multideg(g) = \beta$. Observe that $\multideg(f') < \alpha$ and $\multideg(g') = \beta$ and $\lm(f) \cdot \lm(g) = x^\alpha \cdot x^\beta = x^{\alpha + \beta}$. Since $\multideg(f') < \alpha$ and $\multideg(g') < \beta$, we have $\multideg(f' \cdot g') < \alpha + \beta$. Hence $\multideg(f \cdot g) = \alpha + \beta$. This proves property 1.

Now consider $(ax^\alpha + f') + (bx^\beta + g') = (ax^\alpha + bx^\beta) + (f' + g')$. We have $\multideg(f') < \alpha$ and $\multideg(g') < \beta$ as before, so it suffices to consider $ax^\alpha + bx^\beta$. If $\alpha \ne \beta$ then $\multideg(f+g) = \max(\alpha, \beta)$. If $\alpha = \beta$ then if $a+b\ne 0$ we have $ax^\alpha + bx^\alpha = (a+b)x^\alpha$, hence $\multideg(f+g) = \alpha$. Otherwise we have $ax^\alpha + bx^\alpha = 0x^\alpha$ so $\multideg(f + g) = \multideg(f' + g') < \alpha$. This proves property 2.
:::

::: {.lemma #remainder-condition}
Let $I \subset K[x_1,\ldots,x_n]$ be an ideal, $G = \{g_1,\ldots, g_t\}$ be a Groebner basis for $I$ and $f$ be an arbitrary polynomial in $K[x_1,\ldots,x_n]$.
Then there exists a unique $r \in K[x_1,\ldots,x_n]$ such that

1. no term of $r$ is divisible by any of $\ldt(g_1), \ldots, \ldt(g_t)$, and

2. there exists $g\in I$ such that $f = g + r$.

In particular, $r$ is the remainder of division of $f$ by all elements of $G$ (taken in any order).
:::

::: {.proof}
Firstly, using division, we can write $f = h_1 g_1 + \cdots + h_t g_t + r$, hence $r$ is not divisible by any polynomials in $G$ (first condition).
This decomposition of $f$ can be used to set $g = h_1 g_1 + \cdots + h_t g_t \in I$, so that $f = g + r$ (satisfying the second condition).

Now, to prove that $r$ is unique, suppose that $f = g + r = g' + r'$ for $g,g'$ and $r,r'$ satisfying both conditions. Then $r-r' = g-g' \in I$ (by definition of an ideal). Assume $r\ne r'$, then $\ldt(r-r') = \langle \ldt(I)\rangle = \langle \ldt(g_1),\ldots, \ldt(g_t) \rangle$ since $G$ is a Groebner basis for $I$. By [@cox2013 p70, Lemma 2], this implies $\ldt(r-r')$ is divisible by some $\ldt(g_i)$, which is a contradiction since $r$ and $r'$ cannot be divisible by any of the $\ldt(g_i)$'s.

The final part of the proposition follows from uniqueness of $r$.
:::

::: {.corollary #div-zero}
Let $G = \{ g_1,\ldots,g_k \}$ be a Groebner basis for an ideal $I \subset K[x_1,\ldots,x_n]$ and let $f \in K[x_1,\ldots,x_n]$. Then $f \in I$ if and only if the remainder on division of $f$ by $G$ is zero.
:::

::: {.proof}
If the remainder on division is zero, then we already proved that $f \in I$.
Conversely, if $f \in I$ then $f = f+0$ satisfies the two conditions of Lemma~\@ref(lem:remainder-condition). It follows that the remainder on division of $f$ by $G$ is zero.
:::

::: {.definition}
Let $f,g \in K[x_1,\ldots,x_n]$. The $S$-polynomial of $f$ and $g$ is defined as
$$
S(f,g) = \dfrac{\lcm(\ldt(f),\ldt(g))f}{\ldt(f)} - \dfrac{\lcm(\ldt(f),\ldt(g))g}{\ldt(g)}.
$$
:::

$S$-polynomials are constructed to reduce the degree of terms, as shown in the following lemma.

::: {.lemma #linear-combination}
Suppose that $f \in K[x_1,\ldots, x_n]$ is a sum of polynomials $\sum_{i=1}^s p_i$ such that $\multideg(p_i) = \delta$ for all $1\le i \le s$.
If $\multideg( \sum_{i=1}^s p_i )$ is a linear combination $\sum_{(i,j) \in \{1\ldots,s\}^2} a_{ij} S(p_i,p_j)$ where all $a_{ij} \in K$. Furthermore all $\multideg(S(p_i,p_j)) < \delta$.
:::

::: {.proof}
We can write each $p_i = c_i (x_1^{\delta_1} \cdots x_n^{\delta_n} + g_i)$ where $\delta = (\delta_1,\ldots, \delta_n)$, $c_i \in K$ and $\multideg(g_i) < \delta$.
In order for $\multideg(\sum_{i=1}^s p_i) < \delta$, leading monomials of $p_i$'s must cancel in the sum. I.e., $\sum_{i=1}^s c_i\ldt(p_i) = 0$ implies $\sum_{i=1}^s c_i = 0$.

Since $\multideg(p_i) = \multideg(p_j)$ for all $i.j$, $\lcm(\ldt(p_i),\ldt(p_j)) = x_1^{\delta_i} \cdots x_n^{\delta_n} = h = \tfrac{1}{c_i}\ldt(p_i) = \tfrac{1}{c_j}\ldt(p_j)$. Consider
$$
S(p_i,p_j) = \dfrac{\lcm(p_i,p_j)p_i}{\ldt(p_i)} - \dfrac{\lcm(p_i,p_j)p_j}{\ldt(p_j)} = \dfrac{h p_i}{c_i h} - \dfrac{h p_j}{c_j h} = \dfrac{1}{c_i}p_i - \dfrac{1}{c_j}p_j.
$$
Hence
$$
S(p_i,p_j) = \sum_{i=1}^s c_i\dfrac{1}{c_i}(x_1^{\delta_1}\cdots x_n^{\delta_n} + g_i) - \dfrac{1}{c_j}c_j(x_1^{\delta_1}\cdots x_n^{\delta_n} + g_j) = \sum_{i=1}^s g_i - g_j.
$$
Since $\multideg(g_i) < \delta$ and $\multideg(g_j) < \delta$, their linear combination, $S(p_i,p_j)$ has multidegree less than $\delta$.

Now return to the sum
$$
\sum_{i=1}^s p_i = \sum_{i=1}^s c_i (x_1^{\delta_1} \cdots x_n^{\delta_n} + g_i).
$$
Since terms of the kind $x_1^{\delta_1}\cdots x_n^{\delta_n}$ cancel,
$$\sum_{i=1}^s p_i = \sum_{i=1}^s c_ig_i = c_1g_1 + \cdots + c_s g_s.$$
We show that this is a linear combination of $S$-polynomials.

Consider the sum
$$
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = \sum_{i=1}^{s-1} c_i( g_i - p_s)
= \sum_{i=1}^{s-1} cg_i - c_ig_s,
$$ hence
$$
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = c_1g_1 + \cdots + c_{s-1}g_{s-1} - \left( c_1 + \cdots + c_{s-1} \right) p_s.
$$
Since $c_1 + \cdots + c_{s-1} + c_s = 0$, we have $c_1 + \ldots + c_{s-1} = -c_s$, and we can write
$$
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = g_1 + \cdots + g_{s-1} - (-c_s) \cdot p_s = \sum_{i=1}^{s} c_i g_i,
$$
proving that $\sum_{i=1}^s p_i$ is a linar combination of $S$-polynomials.
:::

We are now ready to present Buchhberger's Criterion, the condition under which Buchberger's algorithm will terminate.

::: {.lemma #buchberger-criterion}
Let $I$ be a polynomial ideal. Then a basis $G = \{g_1, \ldots, g_t\}$ of $I$ is a Groebner basis of $I$ if and only if, for all pairs $i \ne j$, the
remainder from division of $S(g_i, g_j)$ by $G$ (with a fixed order) is zero.
:::

::: {.proof}
$\Rightarrow:$
If $G$ is a Groebner basis for $I$, then $S(g_i,g_j) \in I$ for all $g_i,g_j \in G$ and, by Corollary \@ref(cor:div-zero), the remainder of $\overline{S(g_i,g_j)}^F$ is zero.

$\Leftarrow:$
Let $f \in I$ be a nonzero polynomial. We need to show that $\ldt(f) \in \langle \ldt(g_1), \ldots, \ldt(g_k) \rangle$. We have to show that
$$
f = \sum^k_{i=1} h_ig_i
$$
where $h_i \in K[x_1,\ldots,x_n], 1 \le i \le k$. By Lemma \@ref(lem:multideg), we have
$$
\multideg(f) \le \max(\multideg(h_ig_i) \mid h_ig_i \ne 0).
$$
We want to try to find the ''most efficient'' representation of $f$. I.e., one where
$$
\delta = \max(\multideg(h_ig_i) \mid h_ig_i \ne 0)
$$
is minimal. Such a $\delta$ exists by the well-ordering property (a minimal element always exists). We have
$$
\multideg(f) \le \delta = \max(\multideg(h_ig_i) \mid h_ig_i \ne 0)
$$

First consider the case when $\multideg(f) = \delta$. We have $\multideg(f) = \multideg(h_ig_i)$ for some $1 \le i \le k$. Therefore $\ldt(f)$ is divisible by $\ldt(g_i)$. Hence $\ldt(f) \in \langle g_i, \ldots, g_k \rangle$.

Now suppose that $\multideg(f) < \delta$. We can write $f$ as follows
$$
\sum_{i=1}^{k}h_{i}g_{i}=\sum_{i=1}^{k}\ldt(h_{i})g_{i}+\sum_{i=1}^{k}(h_{i}-\ldt(h_{i}))g_{i}
$$
and use this representation to isolate terms with maximum multidegree
$$
\sum_{\multideg(h_{i}g_{i})=\delta}\ldt(h_{i})g_{i}+\sum_{\multideg(h_{i}g_{i})=\delta}(h_{i}-\ldt(h_{i}))g_{i}+\sum_{\multideg(h_{i}g_{i})<\delta}h_{i}g_{i}.
$$
The last two terms have $\multideg < \delta$, so we attempt to rewrite $\sum_{\multideg(h_ig_i)= \delta} \ldt(h_i)g_i$ to decrease $\delta$, thereby obtaining a contradiction. Applying Lemma \@ref(lem:linear-combination) with $p_i = \ldt(h_i)g_i$ with multidegree $\delta$ and $f$ with multidegree $< \delta$, we can write $\sum_{\multideg(h_ig_i) = \delta} \ldt(h_i)g_i$ as a linear combination (with coefficients in $K$) of $S$-polynomials having multidegree $< \delta$. Hence, we know that $f$ can be rewritten as a sum of polynomials with multidegree $< \delta$, contradicting the assumption that $\delta$ is minimal.

Given an expression $f = \sum^t_{i=1} h_i g_i$ with minimal $\delta$, we begin by isolating the part of the sum having multidegree $\delta$.

\begin{align}
f=&\sum_{{\rm multideg}(h_{i}g_{i})=\delta}h_{i}g_{i}+\sum_{{\rm multideg}(h_{i}g_{i})<\delta}h_{i}g_{i}\\
=&\sum_{{\rm multideg}(h_{i}g_{i})=\delta}(h_{i}-{\rm lt}(h_{i}))g_{i}+\sum_{{\rm multideg}(h_{i}g_{i})<\delta}h_{i}g_{i} (\#eq:multideg-delta-simp)
\end{align}
The second and third sums in Equaton \@ref(eq:multideg-delta-simp) have multidegree $< \delta$. Since $\multideg(f) < \delta$, the multidegree of the first sum in Equation \@ref(eq:multideg-delta-simp) must also have multidefree $< \delta$.

The key to decreasing $\delta$ is to rewrite the first term in this sum in two stages:

- use [@cox2013, Lemma 5] to rewrite the first term in the sum in terms of $S$-polynomials,
- then use $S(g_i,g_j) = 0$ to rewrite the $S$-polynomials without cancellation.

By [@cox2013, Lemma 5],
$$
\sum_{\rm(multideg)(h_i g_i) < \delta} \rm{lt}(h_i) g_i
$$
is a linear combination of the coeffinients in $K$ of the $S$-polynomials
$$
S(\ldt(h_i) g_i, \ldt(h_j), g_j),
$$
since each $\ldt(f_i) g_i$ has multidegree $\delta$ while the sum has multidegree $< \delta$.

We have
\begin{equation}
(\#eq:sum-lt)
S(\rm{lt}(h_i) g_i, \rm{lt}(h_j) g_j) = x^{\delta - \gamma_{i,j}} S(g_i,g_j)
\end{equation}
where
$x^{\gamma_{i,j}} = \lcm( \lm(g_i), \lm (g_j))$ it follows that the first sum (Equation \@ref(eq:sum-lt)) is a linear combination of $x^{\delta - \gamma_{i,j}} S(g_i,g_j)$ for appropriate pairs $(i,j)$.

Consider one of the $S(g_i,g_j)$. Since $\overline{S(g_i,g_j)}^G = 0$, we can rewrite it as
\begin{equation}
(\#eq:s-sum-a)
S(g_i,g_j) = \sum^t_{\ell = 1} A_\ell g_\ell,
\end{equation}
where $A \in K[x_1,\ldots,x_n]$ and
\begin{equation}
(\#eq:s-lt)
\rm{multideg}(A_\ell g_\ell) \le \rm{multideg}(S(g_i,g_j))
\end{equation}
where $A_\ell g_\ell \ne 0$.
By multiplying both sides of Equation \@ref(eq:s-sum-a) by $x^{\delta - \gamma_{i,j}}$, we get
$$
x^{\delta - \gamma_{i,j}}S(g_i,g_j) = \sum^t_{\ell = 1} B_\ell g_\ell,
$$
where $B_\ell = x^{\delta - \gamma_{i,j}} A_\ell$. Then it follows from Equation \@ref(eq:s-lt) that
$$
\rm{multideg}(B_\ell g_\ell) \le \rm{multideg}(S(g_i,g_j)) < \delta
$$
since $\rm{lt}(S(g_i,g_j)) < \rm{lcm}(\rm{lm}(g_i), \rm{lm}(g_j)) = x^{\gamma_{i,j}}$.

It follows that we can rewrite the first term in the sum as
$$
\sum_{\rm{multideg}(h_i g_i) = \delta} \rm{lt}(h_i) g_i = \sum^t_{\ell = 1} \tilde{B_\ell} g_\ell
$$
with the property that when $\tilde{B_\ell}g_\ell \ne 0$, we have $\rm{multideg}(\tilde{B_\ell} g_\ell) < \delta$.

we have obtained an expression for $f$ as a polynomial combination of the $g_i$'s where every term has multidegree $< \delta$. This contradicts the assumption that $\delta$ was minimal and completes the proof.
:::


The basic idea of Buchberger's algorithm is that polynomials are added to the input set until a Groebner basis is obtained -- i.e., until Buchberger's criterion is satisfied.

There now follows a worked example to illustrate Buchberger's algorithm.

Consider $I = \langle f_1, f_2 \rangle = \langle x^3 - 2xy, x^2 y - 2y^2 + x \rangle \subset Q[x,y]$ with grlex ordering.
$\langle f_1, f_2 \rangle$ is not a Groebner basis for $I$.
Indeed,
\begin{align*}
S(f_1,f_2) &= \dfrac{x^{3}y}{x^{3}}\left(x^{3}-2xy\right)-\dfrac{x^{3}y}{x^{2}y}\left(x^{2}y-2y^{2}+x\right) \\
&= \left(x^{3}y-2xy^{2}\right)-\left(x^{3}y-2xy^{2}+x^{2}\right)\\
&= -x^2 \not \in \{\ldt(f_1), \ldt(f_2)\}
\end{align*}
Compute $$
\overline{ S(f_1,f_2) }^F.
$$
We have
$$
S\left(f_{1},f_{2}\right)=-x^{2}=g_{1}\left(x^{3}-2xy\right)+g_{2}\left(x^{2}y-2y^{2}+x\right)+h.
$$
Setting $g_1 = -y,g_2 = x$ gives
\begin{align*}
&-y\left(x^{3}-2xy\right)+x\left(x^{2}y-2y^{2}+x\right) + h\\
=&-x^{3}y+2xy^{2}+x^{3}y-2xy^{2}+x^{2} + h\\
\Rightarrow& h = -x^2\\
\end{align*}
Add $-x^2$ to $F$.
Since $-x^2 \in I$, we have $\overline{S(f_1,f_2)}^F = 0$.

We now need to consider $S(f_1,f_3)$ and $S(f_2,f_3)$.
\begin{align*}
S\left(f_{1},f_{3}\right)&=\dfrac{x^{3}}{x^{3}}\left(x^{3}-2xy\right)-\dfrac{x^{3}}{x^{2}}x^{2}=-2xy\\S(f_{2},f_{3})&=\dfrac{x^{2}y}{x^{2}y}\left(x^{2}y-2y^{2}+x\right)-\dfrac{x^{2}y}{x^{2}}x^{2}=-2y^{2}+x
\end{align*}
The remainder of $\overline{S(f_1,f_3)}^F$ is $-2xy \i I$, so we add $-2xy$ to $F$. Similarly, the remainder $\overline{S(f_2,f_3)}^F$ is $-2y^{2}+x$, so we add $-2y^{2}+x$ to $F$.

We have $$F = \left( x^3 - 2xy, x^2 y - 2y^2 + x, -x^2, -2xy, -2y^2 + x \right),$$
and $\overline{S(f_i,f_j)}^F=0$ for all $f_i,f_j \in F$. We conclude that $F$ is a Groebner basis for $I$.

We now present Buchberger's algorithm.

**Input:** $F = \{ f_1,\ldots,f_k \} \subset K[x_1,\ldots,x_n]$ -- a finite set of multivariate polynomials

**Output:** A Groebner basis $G$ for $I = \langle f_1,\ldots,f_k \rangle$, s.t. $F \subset G$

  - Let $G := F$

  - do

    - let $G' := G$

    - for $f,g\in G$ s.t. $f \neq g$:
      - let $r = \overline{S(f,g)}^{G'}$

      - if $r \ne 0$ then $G := \{r\} \cup G$

  - while $G \ne G'$

  - return $G$

See [@cox2013 p91, Theorem 2] for a proof that this algorithm does indeed produce a Groebner basis for $F$ and always terminates in a finite number of steps. Following the publication of Buchberger's algorithm, there were several improvements in efficiency. For example, the F4 algorithm [@fauger1999] replaces multiple $S$-polynomial reductions by a row reduction on a sinlge large matrix. In many cases, the most efficient choice of monomial ordering may be different from that needed to solve tho problem at hand. The FGLM algorithm [@fauger2017] uses basis conversion to address this.
Groebner bases remain a vital tool in computer algebra and an active area of research.

#### Zariski closures and saturations

Let $f_1,\ldots,f_k \in K[x_1,\ldots,x_n]$. We define
$$
V(f_1,\ldots,f_k) := \{ x \in K^n \mid f_1(x), \ldots, f_k(x) = 0 \}.
$$
If $I \subset K[x_1,\ldots,x_n]$ is a polynomial ideal, we write
$$
V(I) := \{ x \in K^n \mid f(x) = 0 \text{ for all } f \in I \}.
$$

Let $V \subset K^n$ be an affine algebraic variety. Then
$$
I(V) := \{ f \in K[x_1,\ldots,x_n] \mid f(a) = 0 \text{ for all } a \in V \}.
$$

To every variety belongs an ideal:

::: {.lemma}
If $V \subset K^n$ is an affine variety, then $V(I) \subset K[x_1,\ldots,k_n]$ is an ideal (called the ideal of $V$).
:::

::: {.proof}
We prove $I\left(V\right)$ satisfies the properties of an ideal.

- $0\left(x\right)=0$ for all $x\in K^{n}$, hence $0\left(x\right)=0$ for all $x\in V$, so $0\in I\left(V\right)$.

- Let $x\in V$. If $f,g\in I\left(V\right)$ then by definition we have $f\left(x\right)=0$ and $g\left(x\right)=0$. Then $f\left(x\right)+g\left(x\right)=0+0=0$, hence $f+g\in I\left(V\right)$.

- Let $x\in V$. If $f\in I\left(V\right)$ and $h\in K[x_{1},\ldots,x_{n}]$. By definition we have $f\left(x\right)=0. h\left(x\right)f\left(x\right)=h\left(x\right)\cdot 0=0$, hence $hf\in I\left(V\right)$ for all $h\in K[x_{1},\ldots,x_{n}]$.
:::

...and to every ideal belongs a variety.

::: {.lemma}
$V(I)$ is an affine variety. In particular if $I = \langle f_1,\ldots,f_k\rangle$ then $V(I) = V(f_1,\ldots,f_k)$.
:::

::: {.proof}
By the Hilbert Basis Theorem $I$ is finitely generated, therefore $I = \langle f_1,\ldots, f_k \rangle$ for some finite set of generators in $K[x_1,\ldots,x_n]$. We want to show that $V(I) = V(f_1,\ldots,f_k)$.

Since $f1 \ldots,f_k \in I$ and $f(a) = 0$ for all $f\in I$, $V(I) \subset V(f_1,\ldots,f_k)$.
On the other hand, suppose $x \in V(f_1,\ldots,f_k)$. Since $I = \langle f_1,\ldots,f_k \rangle$, every $f \in I$ can be written
$$
f = h_1f_1 + \cdots + h_kf_k.
$$
Since $f_i(x) = 0$ for all $1 \le i \le k$, we have
$$
f(x) = h_1(x) \cdot 0 + \cdots + h_k(x) \cdot 0 = 0 + \cdots + 0 = 0.
$$
Therefore $V(f_1,\ldots,f_k) \subset V(I)$, hence $V(I) = V(f_1,\ldots,f_k)$.
:::

Let $S \subset K^n$ be an arbitrary subset, not necesarily an affine algebraic variety. $I(S)$ (defined in the same way as above) is an ideal and by the ideal-variety correspondance, $V(I(S))$ if an affine algebraic variety.

::: {.lemma}
Let $S \subset K^n$. $V(I(S))$ is the smallest affine algebraic variety containing $S$.

(I.e., for all affine algebraic varieties $W \supset S$, $V(I(S)) \subset W$.)
:::

::: {.proof}
If $S \subset W$, then $I(W) \subset I(S)$ because the operation $I$ is inclusion reversing.
In addition, $V(I(S)) \subset V(I(W))$ because $V$ is also inclusion reversing.
Since $W$ is an affine algebraic variety, $V(I(W)) = W$, so we have $V(I(S)) \subset W$.
:::

::: {.definition}
The Zariski closure of a subset $S \subset K^n$ is the smallest affine algebraic variety containing $S$. We denote the Zariski closure of $S$ by $\overline{S}$.
:::


