% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Thesis},
  pdfauthor={Hollie},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Thesis}
\author{Hollie}
\date{2024-03-15}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\A}{\mathbb{A}}

\newcommand{\sign}{\operatorname{sign}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\lc}{\operatorname{lc}}
\newcommand{\lm}{\operatorname{lm}}
\newcommand{\ldt}{\operatorname{lt}}
\newcommand{\multideg}{\operatorname{multideg}}
\newcommand{\red}{\operatorname{red}}
\newcommand{\prim}{\operatorname{prim}}
\newcommand{\psrc}{\operatorname{psrc}}
\newcommand{\res}{\operatorname{Res}}
\newcommand{\lex}{<_{\rm{lex}}}
\newcommand{\lexeq}{\le_{\rm{lex}}}
\newcommand{\projop}[1]{{\proj_{\R^{#1}}}}

\newcommand{\projops}[1]{{\proj_{\opspan{#1}}}}
\newcommand{\opspan}[1]{{\operatorname{span} \{#1\}}}
\newcommand{\cl}[1]{{\operatorname{cl} \left( #1 \right)}}
\newcommand{\cls}[2]{{\operatorname{cl}_{#1} \left( #2 \right)}}
\newcommand{\fr}[1]{{\operatorname{fr} \left( #1 \right)}}
\newcommand{\frt}[2]{{\operatorname{fr}_{#1} \left( #2 \right)}}

\hypertarget{cylindrical-algebraic-decompositions-with-monotone-cells}{%
\chapter{Cylindrical algebraic decompositions with monotone cells}\label{cylindrical-algebraic-decompositions-with-monotone-cells}}

A Cylindrical Algebraic Decomposition (CAD) is a finite partition of n-dimensional space into so-called Cylindrical Cells. The
key idea of cylindricity is that cells are arranged in \emph{stacks}. I.e., the projection of any two cells onto dimension
n-1 is either disjoint or identical.

CAD provides a constructive and computationally tractable proof of the famous Tarski-Seidenberg theorem, which states that semialgebraic sets are
closed under projection, or, equivalently, that quantifier elimination is possible over the reals. Indeed, QE is
possibly the most famous application of CAD. CAD also has applications in computing topological properties of
semialgebraic sets and solving motion-planninng problems. However, for these applications, a basic CAD will not suffice.
Instead, we may have to introduce some additional constraints to the construction. One such constraint, which is useful
in topology, is that every cell in the CAD is a \emph{topologically regular cell}. Put briefly, its boundary should be
homeomorphic to a circle. Another useful property is the \emph{frontier condition}. I.e., the boundary of every cell in the
decomposition must be a union of some other cells in the decomposition of smaller dimension. This property is necessary
to solve motion planning problems.

The goal of this thesis is to develop an algorithm to construct such a CAD. In fact, a CAD satisfying a slightly stronger condition -- such that every cell contained in some input set in \textbf{monotone}. It has been proved that a \textbf{monotone cell} is a \textbf{topologically regular cell}. The constructive proof that such a CAD exists is due to \citep{bgv15}, and this thesis will aim to extract an algorithm from the formal description.
\citep{bgv15} work over the category of sub-pfaffian sets, using an algorithm due to \textbf{TODO} to construct the base
cylindrical decomposition. However, the algorithm presented here will work with semialgebraic sets, using the more
familiar CAD due to \citep{collins1975}. This will allow the tools of computer algobra to be used. In addition, an implementation would not be possible over sub-pfaffian sets, as an oracle is needed to determine whether a set is empty.

\hypertarget{things-to-explain}{%
\section{Things to explain}\label{things-to-explain}}

\begin{itemize}
\tightlist
\item
  some background on CAD

  \begin{itemize}
  \tightlist
  \item
    algorithms (including pfaffian one), implementations and upper bounds
  \end{itemize}
\item
  monotone cells are obtained by refinements, i.e., more cells

  \begin{itemize}
  \tightlist
  \item
    why might one want to introduce more cells?
  \end{itemize}
\item
  motivation

  \begin{itemize}
  \tightlist
  \item
    what can we do with monotone cad that we cannot do with ordinary
  \item
    frontier condition: Schwartz and Sharir and Gabrielov and Vorobjov
  \item
    definitions and motivating examples

    \begin{itemize}
    \tightlist
    \item
      start with my favourite example in R\^{}2. x\^{}2 + y\^{}2 \textless{} 1. observe that the curves forming the top and the bottom of the cell are not monotone - they are not even quasi-affine. we can see, by considering the curves as a function of x, that they are not strictly increasing in, strictly decreasing in, or independent of x. from our intuition, it's clear that we can split these curves where they ``change direction'' -- in other words, at their local maxima and minima. this is the basic idea ofBGV's algorithm.
    \item
      note that the example of a subset of R\^{}2 which is QA but not M is a bit trivial and not instructive (two disjoint increasing / decreasing curves). being not connected, it cannot be a CAD cell. I.e., any CAD cell in R\^{}2 which is quasi-affine is also monotone. furthermore (see the theorem in QA section) any CAD cell of dimension \textless= 1 which is quasi-affine will be monotone.
    \item
      let's consider a more interesting example in R\^{}3. the smashed fragment of bowl. we see that, in the triangle, the function z = x\^{}2 + y\^{}2 is strictly increasing in both y and z. however, if we look at the projection onto the x-z plane, it is clear that this cell is not monotone. in particular, if we intersect with the plane z = 3/4, it intersects our cell in two curve intervals. being strictly increasing/decreasing/independent of each variable, it suffices to consider the one-dimensional ``top'' and ``bottom'' of each cell (see BGV lemma 3.18) and ensure that these curves are monotone. this amounts, again, to finding the points at which they ``change direction''. we will see later that this can be reduced to the problem of finding the local maxima and minima of a surface, subject to constraints defining a curve, which is a well-studied problem.
    \item
      finally, let's see some examples of the frontier condition. things are pretty simple in R\^{}2. indeed, Lazard proves that a sign-invariant CAD of R\^{}2 will always satisfy the frontier condition. (my favourite example, compatible and sign-invariant). However, things become more interesting in R\^{}3, where blow-up points may occur. Let's consider another rather famoun construction -- the Whitney umbrella. Construct a CAD sign-invariant with respect to x\^{}2 - y\^{}2 z = 0. we get three cells with sign 0 on x\^{}2 - y\^{}2 z = 0 -- two 2-dimensional sections and one one-dimensional sector above the origin. consider the frontier of one of these sections -- x=y=0,z\textgreater0. (for both) observe that the frontier of both sections coincides and has non-empty intersection with the one-cell, however it's not a union of cells and , with the polynomials we have, it's not possible to refine our one-cell such that the frontier will be a union. i.e., we need to add more polynomials. also observe that, in R\^{}3 and, in fact, for a set of dimension 2 in any ambient space, blow-up points (cells above which blow-ups occur) will have dimension at most 0.
    \item
      finally, let's consider a definable example (from BGV) of a subset which cannot satisfy the frontier condition in a simple way. observe that S i a semialgebraic set. note, however, that some projection operators, e.g., brown mc and laz (see section TODO) guarantee smooth cells, so such a construction would not occur in this case. However, the construction is cylindrical, so this is a valid CAD. considering the frontier of S, we see that it is not a topologically regular cell. in particular,the blow-up point at the origin. this means that introducing the top and bottom of S as new cells would not be possible, since the bottom of S is not a valid cylindrical cell. First, we would need to refine the bottom of S such that it is a union of valid cells. .e., wewould need to divide it into the two horizontal curve intervals, and the blow-up interval above the origin. Adding these cells directly to the CAD would destroy the cylindrical structure, so a refinement of some of the induced decompositions below it (starting with the decomposition induced by D on R\^{}1) will be needed. i.e., we would need to refine D' such that it is compatible with x \textless{} 0, x = 0 and x \textgreater{} 0. this is the basis of a novel algorithm (see section \ldots) for satisfying the frontier condition in the general case.
    \end{itemize}
  \item
    existing work: Schwartz, Lazard and Locatelli
  \end{itemize}
\item
  discussing the frontier condition

  \begin{itemize}
  \tightlist
  \item
    let's proceed with the construction due to BGV. first they observe that the boundary of every 2-dimensional cell is homeomorphic to a circle. thus, a refinement of this boundary into monotone curve intervals and points can be computed. if the boundary intersects a cell, that cell will be 2-dimensional and we can divide it into two monotone 2-dimensional cells and the one-dimensional component of the frontier. This procedure is simple, but it has the drawback that we need to find the frontier of a 2-dimensional monotone cell. the usual way of doing this is by solving a QE problem with ??? quantifier alternations. Using the singly exp algorithm from BPR, each frontier computation will hvae complexity ???. This would be unacceptable in practice.
  \item
    instead, we try to turn our attention to Lazard, who presents as construction in R\^{}3. since his cells are already assumed to be topologically regular and blow-up points are assumed to be 0-dimensional, it is sufficient to find ``bad cells'' (cells above which some polynomial vanishes identically) and try to introduce new polynomials which refine the one-dimensional curve above the bad cell and complete the frontier condition. He does this in a much different way to BGV, who are working in the definable (semi-pfaffian) case, by using properties of polynomial ideals. I don't completely understand what he is doing, but it has something to do with considering the zariski closure of the one-dimensional cells (at the extrema of the monotone cells) with the bad point removed. the zariski closure as we approach this point is part of the frontier of the set, and is the new point we need to add to satisfy the frontier condition.
  \item
    i then conjecture, since we have only 2d sets with 0d blow-ups, that we could extend this to higher dimension. in particular, we can assume that only one polynomial will blow-up at any one time (otherwise the blow-up poits would have higher dimension) and work our way up the stack of polynomials above a 0-cell until we find one with a blow-up. we now have a version of Lazard's ideal, but our 0d point lies in a higher dimension. so we can do the same again -- consider the zariski closure of the 1d cell approaching the bad point and get the required refinement. the problem here would be proving this correct. i.e., will it find all of the blow-up poits? will it even work at all, or is there somethnig he assumed that is only true in the 3d case?
  \item
    finally we should present the novel frontier algorithm and make it very clear how we stop infinite returns to higher dimension. the bit abotu constructing the cchain of cad and then reconstructing it the other way up is important, as the refinements we do on the way back up result in the final one (the refinement of the inital cad) satisfying the frontier condition. we finish off by observing that these weren't refinements at all, since the refined cads actually coincide with the cad's in the chain that we had in the first place.
  \end{itemize}
\item
  in the algorithm, change semi-monotone to monotone sector
\end{itemize}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

Based on the work of Basu, Gabrielov and Vorobjov \citep{bgv15}.

\hypertarget{background}{%
\chapter{Background}\label{background}}

\hypertarget{sets-definable-over-o-minimal-structures}{%
\subsection{Sets definable over O-minimal structures}\label{sets-definable-over-o-minimal-structures}}

We will be working mostly in the category \emph{Semialgebraic Set} and sometimes in the more general category of sets definable over an O-minimal structures.
A semialgebraic subset of \(\mathbb{R}^n\) is the set of points in \(\mathbb{R}^n\) satisfying a Boolean combination of polynomial equations and inequalities with coefficients in \(\mathbb{R}\).

\begin{definition}
\protect\hypertarget{def:semialgebraic-set}{}\label{def:semialgebraic-set}

The semialgebraic subsets of \(\mathbb{R}^n\) are the smallest class \({SA}_n\) of subsets of \(\mathbb{R}^n\) satisfying the following properties.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(f \in \mathbb{R}[x_1,\ldots,x_n]\), then \(\{ \mathbf{x} \in \mathbb{R}^n \mid f(\mathbf{x}) = 0 \}\) and \(\{ \mathbf{x} \in \mathbb{R}^n \mid f(\mathbf{x}) > 0 \}\) are elements of \({SA}_n\).
\item
  If \(A, B \in {SA}_n\), then \(A \cup B\), \(A \cap B\) and \(\mathbb{R}^n \setminus A\) are elements of \({SA}_n\).
\end{enumerate}

\end{definition}

\begin{definition}
Let \(X \subset \mathbb{R}^n\) and \(Y \subset \mathbb{R}^m\). A mapping \(f : X \to Y\) is called semialgebraic if its graph
\[
\{ (\mathbf{x},f(\mathbf{x})) \in \mathbb{R}^{n+m} \mid \mathbf{x} \in X \}
\]
is a semialgebraic set.
\end{definition}

A semialgebraic set can be represented as either a quantifier-free or first-order Boolean formula.

\begin{definition}
\protect\hypertarget{def:qff}{}\label{def:qff}

A quantifier-free Boolean formula is obtained by the following rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(f \in \mathbb{R}[x_1\ldots,x_n]\) then \(f=0\) and \(f>0\) are quantifier-free Boolean formulas,
\item
  if \(F\) and \(G\) are quantifier-free Boolean formulas then \(F \land G\), \(F \lor G\) and \(\neg F\) are quantifier-free Boolean formulas.
\end{enumerate}

\end{definition}

\begin{definition}

A first-order Boolean formula is obtained by rules 1 and 2 from Definition @\ref(def:qff) and

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  If \(F\) is a first-order Boolean formula and \(y\) is a variable ranging over \(\mathbb{R}\), then \(\exists y\ F\) and \(\forall y\ F\) are first-order Boolean formulas.
\end{enumerate}

\end{definition}

A fundamental result in semialgebraic geometry is the Tarski-Seidenberg Theorem.

\begin{theorem}
\protect\hypertarget{thm:tarski-seinedberg}{}\label{thm:tarski-seinedberg}{[}\citet{vdd1998}
Let \(S \subset \mathbb{R}^{n+1}\) and \({\operatorname{proj}_{\mathbb{R}^{n}}} : \mathbb{R}^{n+1} \to \mathbb{R}^n\) be the projection map onto the first \(n\) co-ordinates. Then \({\operatorname{proj}_{\mathbb{R}^{n}}}(S) \subset \mathbb{R}^n\) is a semialgebraic set.
\end{theorem}

One important consequence of this theorem is that quantifier elimination is possible over real numbers. In other words, a subset of \(\mathbb{R}^n\) defined by a first-order formula with quantifiers is semialgebraic and can be represented by a quantifier-free Boolean formmula. One useful application of this theorem is that the closure, \({\operatorname{cl} \left( ( \right)}S)\), of any semialgebraic set \(S \subset \mathbb{R}^n\) is also semialgebraic.

\begin{proposition}
\protect\hypertarget{prp:union-of-conjunctionss}{}\label{prp:union-of-conjunctionss}Every semialgebraic subset of \(\mathbb{R}^n\) is the (not necessarily disjoint) union of finitely many semialgebraic subsets of the kind
\[
\{ \mathbf{x} \in \mathbb{R}^n \mid f(\mathbf{x}) = 0 \land g_1(\mathbf{x}) > 0 \land \cdots \land g_k(\mathbf{x}) > 0 \}
\]
where \(k \in \mathbb{N}\) and \(f,g_1,\ldots,g_k \in \mathbb{R}[x_1,\ldots,x_n]\).
\end{proposition}

This follows from the fact that the class of finite unions of this kind satisfy properties listed in Definition \ref{def:semialgebraic-set}.

We now define the O-minimal structures over the reals.

\begin{definition}
\protect\hypertarget{def:definable-set}{}\label{def:definable-set}

A structure expanding the real closed field \(R\) is a collection \[
S := (S^n)_{n \in \mathbb{N}}
\]
where each \(S^n\) is a set of subsets of the affine space \(R^n\) satisfying the following conditions.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  All algebraic subsets of \(R^n\) are in \(S^n\).
\item
  \(S^n\) is a Boolean subalgebra of the powerset of \(R^n\).
\item
  If \(A \in S^n\) and \(B \in S^m\), then \(A \times B \in S^{n+m}\).
\item
  Let \(\operatorname{proj}: R^{n+1} \to R\) be the projection onto the first \(n\) coordinates. If \(X\in R^{n+1}\), then \(\operatorname{proj}(X) \in R^n\).
\end{enumerate}

\end{definition}

\begin{definition}
\protect\hypertarget{def:o-minimal-structure}{}\label{def:o-minimal-structure}

A structure \(S\) satisfying the properties of a definable set (listed in Definition \ref{def:definable-set}) and

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  The elements of \(S^1\) consist of the finite unions of points and open intervals of \(R\).
\end{enumerate}

\end{definition}

\begin{definition}
\protect\hypertarget{def:definable-function}{}\label{def:definable-function}A map \(f : A \to R^m\), where \(A \subset R^n\), is called \emph{definable} if its graph \(G \subset R^{n+m}\) is a definable set.
\end{definition}

\begin{remark}
Since definable sets are closed under projection, it can be easily deduced that \(A\) is a definable set.
\end{remark}

\begin{remark}
For convenience, we will call a definable map \(f : R^n \to R\) a definable function.
\end{remark}

It is easy to see that semialgebraic sets satisfy the properties of sets definable in an O-minimal structures over the reals. Another example is the sub-pfaffian sets.

\begin{definition}
\citep[Definition 2.1]{gv04}
A Pfaffian chain of order \(r \ge 0\) and degree \(\alpha \ge 1\) in an open domain \(G \subset \mathbb{R}^n\) is a sequence of analytic functions
\[
f_1, \ldots , f_r
\]
in \(G\) satisfying the differential equations
\[
{df}_j(\mathbf{x}) = \sum^n_{i=1} g_{ij}(\mathbf{x}, f_1(\mathbf{x}), \ldots, f_j(\mathbf{x})) dx_i
\]
for \(1 \le j \le r\), where \(g_{ij}(x_1,\ldots,x_n),y_1,\ldots,y_j)\) are polynomials of degree not greater than \(\alpha\).

A function \(f(\mathbf{x}) = P(\mathbf{x},f_1(\mathbf{x}),\ldots,f_r(\mathbf{x}))\), where \(P(\mathbf{x}, f_1(\mathbf{x}), \ldots, f_r(\mathbf{x}))\) is a polynomial of degree not greater than \(\beta \ge 1\) is called a Pfaffian function of order \(r\) and degree \((\alpha, \beta)\). Note that \(f\) is only defined in the domain \(G\), where all functions \(f_1,\ldots,f_r\) are analytic, even if \(f\) itself can be extended as an analytic function in a larger domain.
\end{definition}

Examples of Pfaffian functions include the exponential, logarithmic, reciprocal and trigonometric functions, as well as the polynomials.

\begin{definition}
\citep[Definition 2.7]{gv04}
A set \(X \subset \mathbb{R}^n\) is called semi-Pfaffian in an open domain
\(G \subset \mathbb{R}^n\) if it consists of points in \(G\) satisfying a Boolean combination \(F\) of some atomic equations and inequalities \(f = 0\), \(g > 0\), where \(f, g\) are Pfaffian functions having a common Pfaffian chain defined in \(G\).

\(X\) is called restricted in \(G\) if \({\operatorname{cl} \left( ( \right)}X)\) is contained in \(G\).

\(X\) is called basic if the Boolean combination \(F\) is a conjuction.
\end{definition}

\begin{definition}
\citep[Definition 2.8]{gv04}
A set \(X \subset \mathbb{R}^n\) is called sub-Pfaffian in an open domain \(G \subset \mathbb{R}^n\) if
\[
X := {\operatorname{proj}_{\mathbb{R}^{n}}}(Y),
\]
where \(Y \subset \mathbb{R}^m\) is a semi-Pfaffian set and \(\mathbb{R}^n\) is a subspace of \(\mathbb{R}^m\).
\end{definition}

\begin{definition}
\citep[2.9]{gv04}
Let \({\cal I}^k := [-1,1]^k\) be the closed cube in an open domain \(G \subset \mathbb{R}^k\).
\(X \subset {\cal I}^n\) is called restricted sub-Pfaffian if \(X := {\operatorname{proj}_{\mathbb{R}^{n}}}(Y)\), where \(Y \subset {\cal I}^{n+m}\) is a restricted semi-Pfaffian set.
\end{definition}

The restricted sub-pfaffian sets form a Boolean subalgebra. Restricted sub-pfaffian sets are clearly closed under taking finite unions and intersections. The property that the compliment of restricted sub-pfaffian set is restricted sub-pfaffian is a particular case of Gabrielov's compliment theorem \citep{gabrielov1996}. The restriction to the closed cube ensures that the restricted sub-Pfaffian sets are definable in an O-minimal structure. Furthermore, \citet{gv01} present an algorithm for constructing a cylindrical decomposition compatible with a restricted sub-Pfaffian set. Note that these properties and results may not be applied to (restricted) semi-Pfaffian sets. Since polynomials are a type of Pfaffian function, semialgebraic sets are a particular case of restricted sub-Pfaffian sets.

\hypertarget{monotone-cells}{%
\subsection{Monotone cells}\label{monotone-cells}}

It is clear from the definition that a set definable in an O-minimal structure is also a definable set and a semialgebraic set is definable in an O-minimal structure. In this section, we will introduce, closely following \citet{bgv15}, some properties of definable sets which are also applicable to semialgebraic sets.

\begin{definition}
\protect\hypertarget{def:affine-coordinate-subspace}{}\label{def:affine-coordinate-subspace}\citep[Definition 2.1]{bgv15}
Let \(L_{j,c} := \{ (x_1,\ldots,x_n) \mid x_j = c \}\) for some \(1 \le j \le n\) and \(c \in \mathbb{R}\).
Each intersection of the kind
\[
S := L_{j_1,c_1} \cap \ldots \cap L_{j_m,c_m}
\]
where \(0 \le j \le m\), \(1 \le j_1 < \cdots < j_m \le n\) and \(c_1,\ldots,c_m \in \mathbb{R}\) is called an affine coordinate subspace of \(\mathbb{R}^n\).
\end{definition}

\begin{definition}
\citep[Definition 2.2]{bgv15}
Let \(\mathbf{f} = (f_1,\ldots,f_k) : X \to \mathbb{R}^k\) be a bounded continuous map defined on an open, bounded, non-empty subset \(X \subset \mathbb{R}^n\) having the graph \(Y \subset \mathbb{R}^{n+k}\).

\(\mathbf{f}\) is called quasi-affine if, for any coordinate subspace \(L \subset \mathbb{R}^{n+k}\), the restriction \(\operatorname{proj}_{L}\vert_Y\) is injective if and only if \(\operatorname{proj}_{L}(Y)\) is \(n\)-dimensional.
\end{definition}

\begin{definition}
\protect\hypertarget{def:monotone-map}{}\label{def:monotone-map}\citep[Definition 2.3]{bgv15}
Let \(\mathbf{f} : X \to \mathbb{R}^k\) be a bounded, continuous, quasi-affne map defined on an open, bounded, non-empty subset \(X\subset \mathbb{R}^n\) having the graph \(Y \subset \mathbb{R}^{n+k}\). \(\mathbf{f}\) is called monotone if, for each affine coordinate subspace \(S \subset \mathbb{R}^{n+k}\), the intersection \(Y \cap S\) is connected.
\end{definition}

\begin{definition}
\protect\hypertarget{def:monotone-map-on}{}\label{def:monotone-map-on}\citep[Definition 2.10]{bgv15}
Let \(X \subset {\operatorname{span} \{x_1,\ldots,x_n\}}\) be a monotone cell and \(\mathbf{f} : X \to {\operatorname{span} \{y_1,\ldots,y_k\}}\) be a continuous map having graph \$Y \subset . If \(Y\) is a monotone cell, then \(\mathbf{f}\) is called monotone on \(X\).
\end{definition}

\begin{definition}
\protect\hypertarget{def:monotone-cell}{}\label{def:monotone-cell}\citep[Definition 2.5]{bgv15}
\(Y \subset {\operatorname{span} \{x_1,\ldots,x_n\}}\) is called a monotone cell if it is the graph of a monotone map \(\mathbf{f} : X \to H\) where \(H \subset {\operatorname{span} \{x_1,\ldots,x_n\}}\) and \(X \subset {\operatorname{span} \{x_1,\ldots,x_n\}} \setminus H\).
\end{definition}

\begin{example}
\leavevmode

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Observe that any quasi-affine map defined on a connected subset and having the graph in \(\mathbb{R}^2\) is also monotone. This quasi-affine map will fail to be monotone if the set it is defined on is not connected.
\item
  Let \(\Delta := \{ 0 < x < 1, y > 0, x + y < 1 \} \subset \mathbb{R}^2\) and \(\varphi(x,y) = x^2 + y^2\). Let \(Y \subset \mathbb{R}^3\) be the graph of function \(\phi\) on \(\Delta\). Observe that \(\phi\vert_Delta\) is a quasi-affine map. However, \(y \cap \{ z = 3/4 \}\) is not connected, hence \(\phi\vert_\Delta\) is not a monotone function.
\end{enumerate}

\end{example}

** TODO: Notation 2.4 about \({\operatorname{span} \{x_1,\ldots,x_n\}}\) seems quite complicated. Why is the complicated explanation needed. **

** TODO 2 figure 1 shows examples of monotone (and not monotone) cells **

\begin{proposition}
\protect\hypertarget{prp:monotone-topologically-regular}{}\label{prp:monotone-topologically-regular}\citep[Theorem 1]{bgv13}
Every monotone cell is a topologically regular cell.
\end{proposition}

The following properties of monotone cells are used in the proof of \citet{bgv15}, Theorem 3.20.

\begin{corollary}

\citep[Corollary 7, Theorem 11]{bgv13}
Let \(X \subset \mathbb{R}^n\) be a monotone cell, then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \cap \{ x_i < c \}\), \(X \cap \{ x_i = c \}\) and \(X \cap \{ x_i > c \}\), for every \(1 \le i \le n\) and \(c \in \mathbb{R}\), are either empty or monotone cells.
\item
  Let \(Y \subset X\) be a monotone cell such that \(\dim(Y) = \dim(X) - 1\) and \({\operatorname{fr} \left( ( \right)}Y) \subset {\operatorname{fr} \left( ( \right)}X)\). Then \(X \setminus Y\) is a disjoint union of two monotone cells.
\end{enumerate}

\end{corollary}

\begin{proposition}
\citep[Theorem 10]{bgv13}
Let \(X \subset \mathbb{R}^n\) be a monotone cell. Then \(\operatorname{proj}_{L}(X)\), for any affine coordinate subspace \(L \subset \mathbb{R}^n\) is also a monotone cell.
\end{proposition}

\begin{remark}
\citep[Remark 2.11]{bgv15}
Let \(Y \subset \mathbb{R}^n\) be a monotone cell and \(L\) be a coordinate subspace such that \(\operatorname{proj}_L\vert_Y\) is injective.
Then \(Y\) is the graph of a monotone map defined on \(\operatorname{proj}_L(Y)\), by \citep[Theorem 7 and Corollary 5]{bgv13}.
\end{remark}

\hypertarget{cylindrical-algebraic-decompositions}{%
\subsection{Cylindrical Algebraic Decompositions}\label{cylindrical-algebraic-decompositions}}

\begin{quote}
A section cell \(C\) is the graph, in \(\mathbb{R}^n\), of a continuous definable function \(h : C' \to \mathbb{R}\), where \(C'\) is a cylindrical cell in \(\mathbb{R}^{n-1}\).
\end{quote}

In reality, we are given a set of \emph{level-\(n\) projection factors} and \(C\) is a real root of a polynomial \(f \in \mathbb{Z}[x_1,\ldots,x_n]\), viewed as a polynomial in \(\mathbb{Z}[x_1,\ldots,x_{n-1}][x_n]\). By the construction of CAD, \(f\) has \(k\) real roots at every point \(\mathbf{c} \in C'\).

In some situations, the former representation (with functions) is more convenient (than the latter, with roots).

Observe that it is easy to convert from the function representation to the root representation. Indeed, let \(C\subset R^{n}\) be the graph of
\[h : C' \to \mathbb{R}\]
where \(C' \subset \mathbb{R}^{n-1}\) is an \((i_1,\ldots,i_{n-1})\)-cell in \(\mathbb{R}^{n-1}\). For every \(\mathbf{c} \in C'\), the graph \(C\) can be written as a root of
\[
f := h(\mathbf{c}) - x_n \in Z[x_1,\ldots,x_n]
\]
The specific root of \(f\) such that \(x_n = h(\mathbf{c})\) can be isolated, by Thom's lemma, by adding some sign conditions on partial derivatives of \(g\).

Now let \(f \in \mathbb{Z}[x_1,\ldots,x_{n-1}][x_n]\) be a polynomial in \(x_n\) and \(C' \subset \mathbb{R}^{n-1}\) be a \((i_1,\ldots,i_{n-1})\)-cell of \(\mathbb{R}^{n-1}\). Then the cylinder \(C' \times \mathbb{R}\) (``above'' \(C'\)) contains a family of section cells
\[
{\cal C} := \{ (\mathbf{c},x_n) \mid \mathbf{c} \in C', f(\mathbf{c},x_n) = 0 \}.
\]
The family \(\cal C\) consists of \(k\) connected semialgebraic sets, corresponding to the \(k\) section cells on which \(f = 0\).
Suppose we want to represent one of these section cells \(C \in {\cal C}\) as the graph of \(h : C' \to \mathbb{R}\). By Thom's lemma, we can write
\[
C = \{ (\mathbf{c},x_n) \mid \mathbf{c} \in C', f(\mathbf{c},x_n) = 0, g_1(\mathbf{c},x_n) > 0, \ldots, g_k(\mathbf{c},x_n) \}
\]
where \(g_1,\ldots,g_k\) are partial derivatives of \(f\).

\(C\) is a semialgebraic set, therefore \(h\) is certainly a definable function.
But, is \(h\) a polynomial? The answer is no. This can be seen using a simple example.

\begin{example}
Let \(D \subset \mathbb{R}^2\) be the unit disc, a semialgebraic set defined by a quantifier-free Boolean formula
\[
\{ x^2 + y^2 < 1 \}.
\]
Construct a CAD of \(\mathbb{R}^2\) compatible with \(D\) in which \(D\) is a single sector cell. Observe that the top of \(D\),
\[
D_T = \{ -1 < x < 1, y > 0, x^2 + y^2 = 0 \}
\]
and
\[
D' := {\operatorname{proj}_{\mathbb{R}^{1}}}(D) = \{ -1 < x < 1 \}.
\]
It is clear that \(D_T\) is a semialgebraic (and therefore a definable) set, so there exists a definable function
\[
h : D' \to \mathbb{R}
\]
such that \(D_T\) is the graph of \(h\vert_{D'}\). Indeed, let
\[
h(x) = +\sqrt{1-x^2}.
\]
This is clearly not a polynomial.
\end{example}

In addition, it's clear that not every definable set is the graph of a definable map. Indeed, consider
\[
C := \{ x^2 + y^2 = 1 \}
\]
and
\[
C' := {\operatorname{proj}_{\mathbb{R}^{1}}}(C) = \{ -1 \le x \le 1 \}.
\]
Both \(C\) and \(C'\) are clearly definable, but there is no map from \(C' \to \mathbb{R}\) having \(C\) as its graph. Indeed, at \(x=0\), this map should have images \(-1\) and \(1\), which contradicts the definition of a map. However, in the case of a cylindrical section cell, the map \(h\) always exists by definition.

Therefore, when working with cylindrical section cells, the map \(h : C' \to \mathbb{R}\) may be used, but algorithms will work solely with polynomials \(f \in \mathbb{Z}{x_1,\ldots,x_{n-1}}[x_n]\) from the level-\(n\) projection factor set.

\hypertarget{cylindrical-algebraic-decomposition}{%
\section{Cylindrical algebraic decomposition}\label{cylindrical-algebraic-decomposition}}

\citet{collins1975} introduced both the concept of cylindrical algebraic decomposition along with an algorithm to construct one such that each cell has constant sign on a set of input polynomials \(\mathbf{F} \subset \mathbb{R}[x_1,\ldots,x_n]\).

Before describing Collins' algorithm, we will first define, closely following \citet{bgv15}, a cylindrical cell and cylindrical decomposition. Note that \citet{bgv15} work in the broader class of definable sets.

\begin{definition}
\protect\hypertarget{def:cells}{}\label{def:cells}

Cylindrical cells are defined by induction on \(n\ge 1\). Each cylindrical cell \(C\) is a connected definable subset of \(\mathbb{R}^n\) with an \emph{index}
\[
(i_1,\ldots,i_n) \in \{0,1\}^n.
\]

\begin{itemize}
\item
  When \(n = 1\), a \((0)\)-cell (section cell) is a point \(c \in \mathbb{R}\) and a \((1)\)-cell (sector cell) is an open interval: \((a,b)\), \((-\infty,b)\), \((a,\infty)\), \((-\infty,\infty)\) where \(a,b\in \mathbb{R}\).
\item
  When \(n > 1\), suppose that \((i_1,\ldots,i_{n-1})\)-cells are already defined and let \(C'\) be one of these cells.
  An \((i_1,\ldots,i_{n-1},0)\)-cell (section cell) is the graph of a continuous definable function \(f : C' \to \mathbb{R}\).
  An - \((i_1,\ldots,i_{n-1},1)\)-cell (sector cell) is a subset of the cylinder \(C' \times \mathbb{R}\), either
  \[
  \begin{aligned}
  \{ (\mathbf{x},t) &\mid \mathbf{x} \in C', f(\mathbf{x}) < t < g(\mathbf{x})\},\\
  \{ (\mathbf{x},t) &\mid \mathbf{x} \in C', -\infty < t < g(\mathbf{x})\},\\
  \{ (\mathbf{x},t) &\mid \mathbf{x} \in C', f(\mathbf{x}) < t < \infty\},\\
  \{ (\mathbf{x},t) &\mid \mathbf{x} \in C', t \in \mathbb{R}\}
  \end{aligned}
  \]
  where \(f,g : C' \to \mathbb{R}\) are continuous definable functions such that \(f(\mathbf{x}) < g(\mathbf{x})\) for all \(\mathbf{x} \in C'\).
\end{itemize}

\end{definition}

Let \(S \subset \mathbb{R}^n\) be a definable subset of \(\mathbb{R}^n\) and define the \emph{frontier of \(S\)}
\[
{\operatorname{fr} \left( S \right)} := {\operatorname{cl} \left( S \right)} \setminus S,
\]
where \({\operatorname{cl} \left( S \right)}\) is the closure of \(S\) in the Euclidean topology.

If \(C \subset \mathbb{R}^n\) is a cylinrical cell, then it will be convenient to partition \({\operatorname{fr} \left( C \right)}\) into three subsets: the top (\(C_T\)), bottom (\(C_B\)) and side-wall (\(C_W\)).

First let \(C\) be a sector \((i_1,\ldots,i_{n-1},1)\)-cell and let \(C' := {\operatorname{proj}_{\mathbb{R}^{n-1}}}(C)\). If \(C\) is bounded from below by a continuous function \(f : C' \to \mathbb{R}\), then \(C_B\) is the graph of \(f\). Similarly, if \(C\) is bounded from above by the graph of a continuous function \(g : C' \to \mathbb{R}\), then \(C_T\) is the graph of \(g\). It is clear that the top and bottom of every cylindrical sector cell (if non-empty) are always cylindrical section cells.

Now let \(C\) be an \((i_1,\ldots,i_{k},0,\ldots,0)\)-cell, where \(i_{k}=1\), and \(C' := {\operatorname{proj}_{\mathbb{R}^{k}}}(C)\). Since \(C'\) is a sector cell, \(C'_B\) and \(C'_T\) are cylindrical section cells. The bottom \(C_B\) of \(C\) is the pre-image of \(C'_B\) by the projection map \({\operatorname{proj}_{\mathbb{R}^{k}}}\vert_{{\operatorname{cl} \left( C \right)}}\) and the top \(C_T\) of \(C\) is the pre-image of \(C'_T\) by the projection map \({\operatorname{proj}_{\mathbb{R}^{k}}}\vert_{{\operatorname{cl} \left( C \right)}}\).
It may be simpler to think of \(C_B\) as the definable set \({\operatorname{cl} \left( C \right)} \cap (C'_B \times \mathbb{R}^{n - k + 1})\) and \(C_T\) as the definable set \({\operatorname{cl} \left( C \right)} \cap (C'_T \times \mathbb{R}^{n - k + 1})\).
It is important to note that \(C_B\) and \(C_T\) may not be cylindrical cells. Indeed, they may fail to be graphs of continuous functions (see Example \ref{exm:top-bottom-not-cylindrical}.

For both section and sector cells, let the side wall, \(C_W\), be \({\operatorname{fr} \left( C \right)} \setminus (C_B \cup C_T)\).
There is no requirement that \(C_W\) will be (a union of) cylindrical cells.

\begin{example}
\protect\hypertarget{exm:top-bottom-not-cylindrical}{}\label{exm:top-bottom-not-cylindrical}In \(\mathbb{R}^3\), let \(C' := \{ (x,y) \mid -1 < x < 1, \vert x \vert < y < 1 \}\) and \(\phi(x,y) = \vert x / y \vert\) so that \(C\) is the graph of \(\phi\vert_{C'}\).
Consider \[
C_B := \{ (x,y,z) \mid -1 < x < 1, y = \vert x \vert, z = 1 \} \cup \{ (0,0,z) \mid 0 \le x \le 1 \}.
\]
\(C_B\) is not the graph of a continuous function due to the blow-up point of \(\phi\) at the origin.
\end{example}

We now define the cylindrical decomposition.

\begin{definition}

A cylindrical decomposition is defined by induction on \(n \ge 0\).

\begin{itemize}
\item
  When \(n = 0\), the unique cylindrical decomposition of \(\mathbb{R}^0\) is the unique point in \(\mathbb{R}^0\).
\item
  When \(n > 0\): Let \(\cal D\) be a partition of \(\mathbb{R}^n\) into cylindrical cells.
  Define \(\cal D'\) to be the set of all projections \(C' := {\operatorname{proj}_{\mathbb{R}^{n-1}}}(C)\) for all \(C\) in \(\cal D\).
  \(\cal D\) is a cylindrical decomposition of \(\mathbb{R}^n\) if \(\cal D'\) is a cylindrical decomposition of \(\mathbb{R}^{n-1}\). We call \(\cal D'\) the *decomposion of \(\mathbb{R}^{n-1}\) induced by \(\cal D\).
\end{itemize}

\end{definition}

Less formally, a partition \(\cal D\) of \(\mathbb{R}^n\) into definable subsets is cylindrical if the projection of any two cells of \(\cal D\) onto \(\mathbb{R}^{n-1}\) is either disjoint or coincides.

\begin{definition}
Let \(S \subset \mathbb{R}^n\) be a definable set. A cylindrical decomposition \(\cal D\) is compatible with \(S\) if every cell \(C\) of \(\cal D\) is either a subset of \(S\) or disjoint from \(S\).
\end{definition}

\begin{definition}
A cylindrical decomposition \(\cal E\) is called a refinement of \(\cal D\) if \(\cal E\) is compatible with every cell of \(\cal D\). in other words, every cell of \(\cal D\) is a union of cells in the refinement \(\cal E\).
\end{definition}

\begin{remark}
\citep[Remark 3.8]{bgv15}
Let \(\cal D\) be a cylindrical decomposition of \(\mathbb{R}^n\) and \(C\) be a cylindrical cell of \(\cal D\) such that \(c := {\operatorname{proj}_{\mathbb{R}^{1}}}(C)\) is a single point. Then it follows immediately from the definition that \(\cal D\) is compatible with the hyperplane \(\{ x_1 = c \}\) and the set of all cells of \(\cal D\) contained in this hyperplane form a cylindrical decomposition \(\cal E\) of \(\mathbb{R}^{n-1}\). Moreover, any refinement of \(\cal E\) is also a refinement of \(\cal D\).
\end{remark}

We now present some useful results proved by \citet{bgv15} relating to desirable properties of cylindrical decompositions.

\begin{definition}
Let \(S \subset \mathbb{R}^n\) be a definable set. A cylindrical decomposition, compatible with \(S\), \(\cal D\) is called monotone with respect to \(S\) if every cell \(C \subset S\) of \(\cal D\) is monotone.
\end{definition}

\begin{definition}
\protect\hypertarget{def:frontier-condition}{}\label{def:frontier-condition}Let \(\cal D\) be a cylindrical decomposition of \(\mathbb{R}^n\) and \(C\) be a cell of \(\cal D\). \(C\) satisfies the frontier condition in \(\cal D\) is \({\operatorname{fr} \left( ( \right)}C)\) is a union of cells of \(\cal D\) of smaller dimension. If it is unambiguous that \(C\) is a cell of \(\cal D\), then we just say that \(C\) satisfies the frontier condition.
If every cell in \(\cal D\) satisfies the frontier condition, then the cylindrical decomposition \(\cal D\) satisfies the frontier condition.
\end{definition}

We saw in Example \ref(exm:top-bottom-not-cylindrcilac) that the top and bottom of a 2-dimensional cylindrical section cell, even in \(\mathbb{R}^3\), need not be a union of cylindrical cells.
However, it is clear from the cylindrcicity property that, if \(C\) is a 2-dimensional section cell satisfying the frontier condition in a decomposition \(\cal D\), then the top and bottom of \(C\) are single cylindrical cells.
If \(C\) is a 2-dimensional section cell, then it is said to satisfy the strong frontier condition if the one-dimensional components of its side-wall are 1-dimensional section cells. This condition may be impossible, even in \(\mathbb{R}^3\), as Example @\ref(exm:side-wall) demonstrates.

\begin{example}
\protect\hypertarget{exm:side-wall}{}\label{exm:side-wall}Consider the two cylindrical cells
\[
V := \{ (x,y,z) \mid x > y > 0, z > 0, y = xz \}
\] and \[
W := \{ (x,y,z) \mid x > y > 0, z > 0, y = 2xz \}
\] in \(\mathbb{R}^3\).
Any cylindrical decomposition compatible with \(V\) and \(W\) is also compatible with the two intervals
\[
I_1 = \{ (0,0,z) \mid 0 \le z \le 1/2 \}, I_2 = \{ (0,0,z) \mid 1/2 \le z \le 1 \}
\]
and the point \[v = (0,0,1/2).\]
Observe that \(I = \{ (0,0,z) \mid 0 \le z \le 1 \}\) is the only one-dimensional component of te side-wall of \(V\) and \(I_1\) is the only one-dimensional component of te side-wall of \(W\). In order to obtain the strang frontier condition, we need to partition \(V\) into (at least) three cylindrical cells \(V',V'',V'''\), one of which, say \(V''\), will be one-dimensional. \(V''\) should have endpoint \(v\) (i.e., \({\operatorname{cl} \left( ( \right)}V'') \cap I = v\)).
The tangent at the origin of \(c := {\operatorname{proj}_{\mathbb{R}^{2}}}(V'')\) is \(1/2\). The pre-image of the projection map \(W' := {\operatorname{proj}_{\mathbb{R}^{2}}}^-1\vert_{{\operatorname{cl} \left( W \right)}}(c)\) would satisfy the condition \({\operatorname{cl} \left( W' \right)} \cap I = v'\), where \(v' = (0,0,1/4)\). However, \(v'\) must be a zero-dimensional cell of the decomposition, which means we need to perform another refinement of \(I\). An infinite sequence of refiniments, introducing a new 0-dimensional cell \((0,0,1/2^k), k \in \mathbb{N}_{> 0}\), will take place. Thus, a decomposition in in which the side-wals of \(V\) and \(W\) are single 1-dimensional cells cannot exist.
\end{example}

\begin{proposition}
\citep[Lemma 3.3]{bgv15}
Let \(C\) be an \((i_1,\ldots,i_{k-1},0,i_{k+1},\ldots,i_n)\)-cell. Then \(C' := {\operatorname{proj}_{{\operatorname{span} \{x_1,\ldots,x_{k-1},x_{k+1},\ldots,x_n\}}}}(C)\) is a cylindrical \((i_1,\ldots,i_{k-1},i_{k+1},\ldots,i_n)\)-cell and \(C\) is the graph of a monotone map \(f : C' \to {\operatorname{span} \{x_k\}}\).
\end{proposition}

\begin{proposition}
\citep[Lemma 3.4]{bgv15}
Let \(C \subset \mathbb{R}^n\) be a 2-dimensional cylindrical cell which is the graph of a quasi-affine map. Then the side-wall \(W \subset {\operatorname{fr} \left( C \right)}\) has exactly two connected components, each of which is either a point or a closed curve interval.
\end{proposition}

\hypertarget{sec:cad-construction}{%
\subsection{Constructing a CAD}\label{sec:cad-construction}}

\begin{remark}
A cylindrical algebraic decomposition (CAD) is a cylindrical decomposition in which every cell is a semialgebraic set. While the results of \citet{bgv15} are proved for the wider class of cylindrical deecompositions compatible with definable sets, we will restrict ourselves to CADs, allowing us to take advantage of properties of polynomials.
\end{remark}

\begin{definition}
Let \(\mathbf{F} := (f_1,\ldots,f_s) \subset \mathbb{Z}[x_1,\ldots,x_n]\) be a set of polynomials with integer coefficients. A cylindrical algebraic decomposition \(\cal D\) is called sign-invariant with respect to \(\mathbf{F}\) (or simply \(\mathbf{F}\)-invariant) if every cell \(C\) of \(\cal D\) has constant sign (either \(> 0\), \(< 0\) or \(= 0\)) on each polynomial in \(\mathbf{F}\). Here, \(\mathbf{F}\) is called the set of input polynomials.
\end{definition}

\begin{remark}
The fundamental theorem of algebra implies that for the coefficients of \(\mathbf{F}\), we may choose any ring \(K \subset \mathbb{A}\). \(\mathbb{Z}\) has been chosen for convenience, but some authors (e.g., \citet{pianomovers1983}) choose \(\mathbb{Q}\) instead.
\end{remark}

Let \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\) be a set of polynomials with integer coefficients. We will now describe the algorithm proposed by \citet{collins1975}, closely following \citet{coste2000}, for constructing an \(\mathbf{F}\)-invariant CAD of \(\mathbb{R}^n\).

Collins' algorithm uses the idea of projections and lifting. More precisely, successive projections of the set of input polynomials to smaller and smaller dimensions are taken, until a set of univariate polynomials is obtained. The CAD of \(\mathbb{R}^1\) is constructed by isolating the roots of these univariate polynomials, with section cells being the roots and sector cells being the open intervals in between them. The lifting phase then works recursively: given a collection of cells in \(\mathbb{R}^k\) and a set of polynomials in \(\mathbb{R}^{k+1}\), the roots of these polynomials within each cell \(C\) are isolated. The section cells in the cylinder \(C \times \mathbb{R}\) are the roots of these polynomials, while the sector cells are the bands in between the roots. The projection operation was designed such that the cylindrical property holds. I.e., above \(C\), each polynomial has a constant number of roots and the roots of no two polynomials crosses one another. This second property is called delineability.

Let us begin the description of the algorithm by considering a single polynomial \(f \in \mathbb{Z}[x_1,\ldots,x_n]\).
We want to partition \(\mathbb{R}^{n-1}\) into connected semialgebraic sets \(C'\) such that, for all \(\mathbf{x} \in C'\), \(f(\mathbf{x},x_n)\) has constant degree and a constant number of roots.

\begin{proposition}
\protect\hypertarget{prp:coste-polynomial-to-cell}{}\label{prp:coste-polynomial-to-cell}\citep[Proposition 2.16]{coste2000}
Let \(f \in \mathbb{Z}[x_1,\ldots,x_n]\) and, \(C' \subset \mathbb{R}^{n-1}\) be a connected semialgebraic set and \(k \le d \in \mathbb{N}\) such that, for every point \(\mathbf{x} \in C'\), the univariate polynomial \(f(\mathbf{x},x_n) \in \mathbb{A}[x_n]\) has degree \(d\) and exactly \(k\) distinct (complex) roots in \(C'\).
Then there are \(\ell \le k\) distinct semialgebraic functions
\[\psi_1,\ldots,\psi_\ell : C' \to \mathbb{R}
\]
such that, for every \(\mathbf{x} \in C'\), the set of real roots of \(f(\mathbf{x},x_n)\) is exactly
\[\{ \psi_1(\mathbf{x}, \ldots, \psi_\ell(\mathbf{x}) \}.\]
Moreover, the multiplicity of each of these roots is constant.
\end{proposition}

\begin{proof}
The argument relies on the ``continuity of roots'':

\begin{quote}
Fix \(\mathbf{c} \in C'\) and let \(z_1,\ldots,z_k\) be the distinct roots of \(f(\mathbf{c},x_n)\) with multiplicities \(m_1,\ldots,m_k\).
Choose \(\varepsilon > 0\) small enough that the open discs \(D(z_i,\varepsilon) z_i \in \mathbb{C}\) (center \(z_i\), radius \$\varepsilon) are disjoint. If \(\mathbf{b} \in C'\) is sufficiently close to \(\mathbf{c}\), then the polynomial \(f(\mathbf{b}, x_n)\) has exactly \(m_i\) roots, counted with multiplicities, in \(D(z_i,\varepsilon)\) for \(1\le i \le k\).
\end{quote}

Since \(f(\mathbf{b},x_n)\) has \(k\) distinct complex roots, and \(d = m_1+ \ldots + m_k\) complex roots counted with multiplicities, it follows that each \(D(z_i,\varepsilon)\) contains exactly one root, denoted \(\zeta_i\), of \(f(\mathbf{b},x_n)\) with multiplicity \(m_i\).
If \(z_i\) is real, then \(\zeta_i\) is real, otherwise the complex conjugate of \(\zeta_i\) would be another root of \(f(\mathbf{b},x_n)\) in the disc \(D(z_i,\varepsilon)\).
If \(z_i\) is complex then \(\zeta_i\) is also complex, since the conjugation of every point in \(D(z_i, \varepsilon)\) lies outside \(D(z_i, \varepsilon)\), forming another disc \(D(\overline{z_i}, \varepsilon)\).
It follows that, if \(\mathbf{b} \in C'\) is close enough to \(\mathbf{c}\), then \(f(\mathbf{c},x_n)\) has the same number of real roots as \(f(\mathbf{b},x_n)\). Since \(C'\) is connected, \(f(\mathbf{x},x_n)\) has the same number of real roots at every point \(\mathbf{x} \in C'\), say \(\ell\).
Define \(\psi_i(\mathbf{x}) : C' \to \mathbb{R}\) to be the continuous (by making \(\varepsilon\) small enough) semialgebraic function sending \(\mathbf{x} \in C'\) to the \(i\)-th (in ascending order) real root of \(f(\mathbf{x},x_n)\). It follows from the connectedness of \(C'\) that each \(\psi_i\) has constant multiplicity.
Observe that the graph of each \(\psi_i\) can be expressed by a first-order Boolean formula, using existential quantifiers to express each of the \(\ell\) roots of \(f(\mathbf{x},x_n)\) and an equality condition to pick out the \(i\)-th root.
It follows that the graph of each functin \(\psi_i\) is a semialgebraic set.
\end{proof}

To extend this result to more than one polynomial, we also need to ensure that the graphs corresponding to each root never intersect.

\begin{proposition}
\citep[Proposition 2.18]{coste2000}
Let \(f,g \in \mathbb{Z}[x_1,\ldots,x_n]\), \(C' \subset \mathbb{R}^{n-1}\) such that, for all \(\mathbf{x} \in C'\), the degree and number of roots of \(f(\mathbf{x},x_n)\) and \(g(\mathbf{x},x_n)\) is constant and the degree of the GCD of \(f(\mathbf{x},x_n)\) and \(g(\mathbf{x},x_n)\) is constant.
Let \(\phi,\psi : C' \to \mathbb{R}\) be continuous semialgebraic functions such that \(f(\mathbf{x},\phi(\mathbf{x})) = 0\) and \(g(\mathbf{x},\psi(\mathbf{x})) = 0\) for all \(\mathbf{x} in C'\).
If there exists \(\mathbf{c} \in C'\) such that \(\phi(\mathbf{c}) = \psi(\mathbf{c})\), then \(\phi(\mathbf{x}) = \psi(\mathbf{x})\) for all \(\mathbf{x} \in C'\).
\end{proposition}

\begin{proof}
We use the same method of proof as in the previous proposition.
For an arbitrary element \(\mathbf{c} \in C'\), let \(z_1 = \phi(\mathbf{c}) = \psi(\mathbf{c}), \ldots, z_k\) be the distinct roots in \(\mathbb{C}\) of the product
\[
f(\mathbf{c},x_n) g(\mathbf{c},x_n)
\]
(recall that \(fg = 0\) if either \(f=0\) or \(g=0\)).
Let \(m_i\) (resp \(p_i\)) be the multiplicity of \(z_i\) as a root of \(f(\mathbf{x},x_n)\) (resp. \(g(\mathbf{x}, x_n)\)) where multiplicity zero indicates that \(z_i\) is not a root.
The degree of \(\gcd(f(\mathbf{x}, x_n), g(\mathbf{x}, x_n))\) is \(\min(m_1,p_1) + \cdots + \min(m_k,p_k)\) and each \(z_i\) has multiplicity \(\min(m_i,p_i)\) as a root of this GCD.
Choose \(\varepsilon > 0\) small enough that the discs \(D(z_i,\varepsilon)\) are disjoint.
For each \(\mathbf{b} \in C'\) close enough to \(\mathbf{c}\), each disc contains a root of multiplicity \(m_i\) of \(f(\mathbf{b}, x_n)\) and a root of multiplicity \(p_i\) of \(g(\mathbf{b}, x_n)\). Since the degree of the GCD of \(f\) and \(g\) (evaluated at any \(\mathbf{x}\) \in \(C'\)) is equal to \(\min(m_1,p_1) + \cdots + \min(m_k,p_k)\), this GCD must have one root of multiplicity \(\min(m_i,p_i)\) in each disc \(D(z_i,\varepsilon)\) such that \(\min(m_i,p_i) > 0\).
In particular, it follows that \(\phi(\mathbf{b}) = \psi(\mathbf{b})\). Since \(C'\) is connected, this equality holds for all \(\mathbf{x} \in C'\).
\end{proof}

Now we have algebraic conditions on the polynomials in the set of level-\((n-1)\) projection polynomials \(\mathbf{F}' = \operatorname{proj}(\mathbf{F})\). We now describe how these properties can be satisfied and, as such, how the set \(\mathbf{F}'\) can be constructed. We will need the concept of the principal subresultant coefficient of two polynomials \(f\) and \(g\).

\begin{definition}
Let \(f,g \in \mathbb{Z}[x_1,\ldots,x_{n-1}][x_n]\) be polynomials, with degrees \(d\) and \(e\) respectively, such that
\begin{align*}
f(x_n) &= a_d x_n^d + \cdots + a_1 x_n + a_0 \\
g(x_n) &= b_e x_n^e + \cdots + b_1 x_n + b_0. \\
\end{align*}
Then the Sylvester matrix associated to \(f\) and \(g\) is the \((d + e) \times (d + e)\)-matrix defined as follows.
\[
S_{f,g}(f,g) = 
\begin{pmatrix}a_{d} & \ldots & a_{0} & 0 & \ldots & \ldots & 0\\
0 & a_{d} & \ldots & a_{0} & 0 & \ldots & 0\\
\ldots & 0 & a_{d} & \ldots & a_{0} & \ldots & 0\\
b_{e} & \ldots & b_{0} & 0 & \ldots & \ldots & 0\\
0 & b_{e} & \ldots & b_{0} & 0 & \ldots & 0\\
\ldots & 0 & b_{e} & \ldots & b_{0} & \ldots & 0
\end{pmatrix}.
\]
\end{definition}

\begin{definition}
Let \(f,g \in \mathbb{Z}[x_1,\ldots,x_{n-1}][x_n]\) be polynomials with degrees \(d\) and \(e\) respectively. The principal subresultant coefficient of order \(j\) of \(f\) and \(g\), denoted \(\operatorname{psrc}_j(f,g)\), is the determinant of the \((m + n - 2j) \times (m + n - 2j)\)-matrix obtained from the Sylvester matrix associated to \(f\) and \(g\) by deleting the first and last \(j\) rows and columns.
\end{definition}

Let \(f,g \in \mathbb{Z}[x_1,\ldots,x_{n-1}][x_n]\) and \(X \subset \mathbb{Z}[x_1,\ldots,x_n]\).

\begin{itemize}
\tightlist
\item
  \(f\) has a constant number of complex roots over \(X\) if
  \[
  \operatorname{psrc}_k(f, \partial f / \partial x_n),
  \]
  for \(1 \le k \le \deg(f)\), is either zero or nonzero everywhere in \(X\).
\item
  \(f\) and \(g\) have constant GCD in \(X\) if
  \[
  \operatorname{psrc}_k(f, g),
  \]
  for \(1 \le k \le \min(\deg(f),\deg(g))\), is either zero or nonzero and \(\deg(f) = \deg(g)\) everywher in \(X\).
\item
  If, for the leading term of \(f\) (or \(g\)) vanishes at some poitns in \(\mathbb{Z}[x_1,\ldots,x_{n-1}]\), we need to take the principal subresultant coefficients of the reductum of \(f\) (or \(g\)).
  \citep[pp36]{coste2000}
\end{itemize}

From these properties of the principal subresultant coefficient, we can define a projection operator.

\begin{definition}

Consider \(f \in \mathbb{Z}[x_1,\ldots,x_n]\) as a univariate polynomial in \(x_n\). I.e.,
\[
f(x_n) = a_d x_n^d + \cdots + a_1 x_n + a_0
\]
where \(a_d,\ldots,a_0 \in \mathbb{Z}[x_1,\ldots,x_{n-1}]\).
Let \(\operatorname{lc}{f} = a_d\) denote the leading coefficient of \(f\) and \(\operatorname{red}(f) = a_{d-1}x_n^{d-1} + \cdots + a_1 x_n^1 + a_0\) be the reductum of \(f\).

Let \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\). We define the projection operator, \(\operatorname{proj}(\mathbf{F})\) as follows:

\begin{itemize}
\item
  Let \(d := \deg(f_i)\). If \(d > 1\), then \(\operatorname{proj}(f_1,\ldots,f_i,\ldots,f_s)\) contains
  \[
  \operatorname{psrc}_k(f_i, \partial f_i / \partial x_n)
  \]
  for all \(1\le k \le d\).
\item
  Let \(d := \min(\deg(f_i), \deg(f_j))\). If \(d > 0\), then \(\operatorname{proj}(f_1,\ldots,f_i,\ldots,f_j,\ldots,f_s)\) contains
  \[
  \operatorname{psrc}_k(f_i, f_j)
  \]
  for all \(1 \le k \le d\).
\item
  If \(\deg(f_i) > 0\) and \(\operatorname{lc}(f_i)\) is non-constant, then \(\operatorname{proj}(f_1,\ldots,f_i,\ldots,f_s)\) contains
  \[
  \operatorname{lc}(f_i) \text{ and } \operatorname{proj}(f_1,\ldots,\operatorname{red}(f_i),\ldots,f_n).
  \]
\end{itemize}

\end{definition}

\begin{theorem}
\protect\hypertarget{thm:cad-lift}{}\label{thm:cad-lift}\citep[Theorem 2.19]{coste2000}
Let \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\) be a family of polynomials and let \(C'\) be a connected \(\operatorname{proj}(\mathbf{F})\)-invariant semialgebraic subset of \(\mathbb{R}^{n-1}\) -- an \((i_1,\ldots,i_{n-1})\)-cell.
Then there exist continuous definable functions
\[
\psi_1,\ldots, psi_\ell : C' \to \mathbb{R}
\]
such that for all \(\mathbf{x} \in C'\), the set \(\{ \psi_i(\mathbf{x}), \ldots, \psi_k(\mathbf{x}) \}\) coincides with the real roots of polynomials in \(\mathbf{F}\), defining the \((i_1,\ldots,i_{n-1},0)\)-cells in the cylinder \(C' \times \mathbb{R}\) and \(\{ -\infty < t < \psi_1(\mathbf{x}), \ldots, \psi_i(\mathbf{x}) < t < \psi_{i+1}(\mathbf{x}), \ldots, \psi_k(\mathbf{x}) < t < \infty \}\) are the \((i_1,\ldots, i_{n-1},1)\)-cells in the cylinder \(C' \times \mathbb{R}\).
\end{theorem}

This follows from the results previously proved. Applying Theorem @\ref(thm:cad-lift), we are able to pass from a \({\operatorname{proj}_{\mathbb{R}^{k-1}}}(\mathbf{F})\)-invariant CAD of \(\mathbb{R}^{k-1}\) to a \({\operatorname{proj}_{\mathbb{R}^{k}}}(\mathbf{F})\)-invariant CAD of \(\mathbb{R}^k\). Thus, by iterating the projection operation until we obtaina set of polynomials in \(\mathbb{Z}[x_1]\), isolating their roots, and then iteratively applying Theorem \ref{thm:cad-lift}\$, we are able to obtain an \(\mathbf{F}\)-invariant CAD of \(\mathbb{R}^n\).

\hypertarget{bounds-and-variations}{%
\subsection{Bounds and variations}\label{bounds-and-variations}}

We have described how to construct a CAD of \(\mathbb{R}^n\) which is sign-invariant with respect to a set of polynomials. We now present the bounds, along with some variations, based \citet{bpr2006}.

\begin{proposition}
\protect\hypertarget{prp:collins}{}\label{prp:collins}\citep[Algorithm 11.2]{bpr2006}
Let \(\mathbf{F} := f_1,\ldots,f_s\) be set of polynomials in \(\mathbb{Z}[x_1, \ldots ,x_n]\) with maximum degree \(d\).
There is an algorithm, taking \(\mathbf{F}\) as input, which produces an \(\mathbf{F}\)-invariant CAD \(\cal D\) of \(\mathbb{R}^n\).
The complexity of the algorithm is
\[(sd)^{O(1)^{n}}.
\]
This is also an upper bound on the number of cells in \(\cal D\), number of polynomials defining cells and their degrees.
\end{proposition}

Observe that these bounds are doubly exponential in the number of variables. Indeed, \citet{davenportHeintz1988} give an example of a CAD in which a doubly exponential number of cells is obtained. In practice, we can obtain a CAD with fewer cells, e.g., by constructing a trath invariant or partial CAD.

\begin{proposition}
\protect\hypertarget{prp:collins-sets}{}\label{prp:collins-sets}Let \(S_1,\ldots,S_k\) be a finite collection of semialgebraic subsets of \(\mathbb{R}^n\) defined by quantifier-free Boolean formulas \(F_1,\ldots,F_k\) respectively. Together, these formulas include \(s\) different polynomials in \(\mathbb{Z}[x_1,\ldots,x_n]\) with maximum degree \(d\).
There is an algorithm, taking \(\{F_1,\ldots,F_k\}\) as input, which produces a cylindrical decomposition \(\mathcal E\) of \(\mathbb{R}^n\) compatible with each set \(S_i, 1 \le i \le k\).
Complexity, number of cells, number of polynomials and degrees are the same as in Proposition \ref(prp:collins) but, in practice.
\end{proposition}

\begin{proof}
Let \(f_1,\ldots,f_s \in \mathbb{R}[x_1,\ldots,x_n]\) be the polynomials from formulas \(F_1,\ldots,F_k\) and let \(\mathcal{E}'\) be the CAD of \(\mathbb{R}^n\) produced by Proposition @ref\{prp:novel-frontier-collins\} with \(f_1,\ldots,f_s\) as input. Since \(F_i\) for each \(1\le i\le k\) provides a set of sign conditions on polynomials \(f_1,\ldots,f_s\), \(\mathcal{E}'\) is a refinement of the CAD produced by this algorithm.

Truth values of \(F_1,\ldots,F_k\) on ecah cell can easily be computed from the CAD produced by Proposition \ref{prp:novel-frontier-collins} by considering the signs of \(f_1,\ldots,f_s\) on ecah cell, which we computed in the construction of \(\mathcal{E}'\).
Observe that this does not change the asymptotic complexity or bounds in Propoosition \ref{prop:collins}.
\end{proof}

It is also common to construct a CAD compatible with a single semialgebraic set.

\begin{corollary}
\protect\hypertarget{cor:collins-set}{}\label{cor:collins-set}Let \(S\subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula \(F\) containing \(s\) different polynomials in \(\mathbb{R}[x_1,\ldots,x_n]\), having maximum degree \(d\).
There is an algorithm, taking \(F\) as input, which produces a cylindrical decomposition \(\mathcal E\) of \(\mathbb{R}^n\) compatible with \(S\).
Complexity, number of cells, number of polynomials and degrees are the same as in Proposition \ref{prp:collins}.
\end{corollary}

\begin{proof}
Immediate, by applying Proposition \ref{cor:collins-set} to \(\{ F \}\).
\end{proof}

The construction described in Proposition \ref{prp:collins-sets} is somewhat naive.
Constructions which are far more efficient in practice are presented in e.g., \citet{collins1991}. An alternative approach is presented by \citet{bradford2014}.
While very useful in practice, these constructions are unable to lower the upper bound from Proposition \ref{prp:collins} due to some extreme cases, e.g., when the input formulas define a sign-invariant CAD (see \citet{bradford2014}, Section 6.2.1{]}.

\hypertarget{the-projection-operator}{%
\subsection{The projection operator}\label{the-projection-operator}}

Since Collins published his CAD algorithm in 1975, many variations of the projection operator have been proposed. Most of these aim to minimise the number of polynomials appearing in \(\operatorname{proj}_{k-1}(\mathbf{F})\), so as to make the algorithm more efficient in practice.
For example, \citet{collins1975} observed that, in dimension \(2\), if the set \(\mathbf{F} \subset \mathbb{Z}[x_1,x_2]\) of input polynomials is
squarefree and pairwise relatively prime, then it is sufficient to include only the leading
coefficients, resultants and discriminants of pairs of polynomials in \(\operatorname{proj}(\mathbf{F})\). \citet{mccallum1988} then proved that a
similar construction is possible in dimension \(3\).
\citet{mccallum1998} later improved upon his previous work by extending this result to dimension \(n > 3\), as long as the set of input polynomials is well oriented.

:: \{.definition\}
\citep[6.1]{mccallum98}
Let \(\mathbf{F} \subset \mathbb{Z}[x_1, \ldots, x_n]\) be a set of polynomials and denote by \(\operatorname{prim}(\mathbf{F})\) the set of all primitive parts of \(\mathbf{F}\)
\(\mathbf{F}\) is called well-oriented if, when \(n > 1\),

\begin{itemize}
\item
  for each element \(f \in \operatorname{prim}(A)\), \(f(\mathbf{x},y) = 0\) for all \(y\in \mathbb{R}\) on a finite number of points \(\mathbf{x} \in \mathbb{R}^{n-1}\). \citep[condition WO1]{mccallum1998}
\item
  \(\operatorname{proj}(\mathbf{F})\) is well-oriented. \citep[condition WO2]{mccallum1998}
  :::
\end{itemize}

\citet{brown2001} then observed that even more polynomials can be discarded, creating the Reduced McCallum Projection Operator. This is commonly used in practice, e.g., in QEPCAD-B \citep{brownQepcad}.

Let \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\) be a well-oriented set of polynomials and \(\cal D\) be an \(\mathbf{F}\)-invariant CAD constructed using the McCallum projection operator \citep{mccallum1998}. Then, by \citet{mccallum1988} Theorems 2.2.3 and 2.2.4, every cell \(C\) of \(\cal D\) is an analytic submanifold of \(\mathbb{R}^n\). Informally, if \(\dim(C) = k\), thent \(C\) is a non-empty subset of \(\mathbb{R}^n\) which ``looks locally like \(\mathbb{R}^k\)'' (see Definition \ref{def:analytic-submanifold} for the precise definition).

\begin{definition}
\protect\hypertarget{def:analytic-submanifold}{}\label{def:analytic-submanifold}\(S \subset \mathbb{R}^n\) such that \(\dim(S) = k\) is an analytic submanifold if, for every point \(\mathbf{x} \in S\), there is an analytic coordinate system about \(\mathbf{x}\) with respect to which \(S\) is locally the intersection of \(n-k\) coordinate hyperplanes.
\end{definition}

\begin{proposition}
\protect\hypertarget{prp:mc-smooth}{}\label{prp:mc-smooth}Let \(S \subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula constructed from the set of polynomials \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\), such that \(\mathbf{F}\) is well-oriented.
Then a CAD \(\cal D\) of \(\mathbb{R}^n\) compatible with \(S\) and such that every cell \(C\) of \(\cal D\) is an analytic submanifold of \(\mathbb{R}^n\) can be obtained by constructing an \(\mathbf{F}\)-invariant CAD of \(\mathbb{R}^n\) using the McCallum projection operator.
\end{proposition}

More recently, \citet{mccallum2019} completed the proof that Lazard's projection operator is valid. He also proved, without the condition on well-orientedness of input polynomials, that every cell of a sign-invariant CAD constructed using Lazard's projection operator is an analytic submanifold. Thus, we can generalise Proposition \ref{prp:mc-smooth} further:

\begin{proposition}
\protect\hypertarget{prp:lz-smooth}{}\label{prp:lz-smooth}Let \(S \subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula constructed from the set of polynomials \(\mathbf{F} \subset \mathbb{Z}[x_1,\ldots,x_n]\).
Then a CAD \(\cal D\) of \(\mathbb{R}^n\) compatible with \(S\) and such that every cell \(C\) of \(\cal D\) is an analytic submanifold of \(\mathbb{R}^n\) can be obtained by constructing an \(\mathbf{F}\)-invariant CAD of \(\mathbb{R}^n\) using the McCallum projection operator.
\end{proposition}

\hypertarget{projection-polynomials-vs-semialgebraic-functions}{%
\subsection{Projection polynomials vs semialgebraic functions}\label{projection-polynomials-vs-semialgebraic-functions}}

Recall that Proposition \ref{prp:coste-polynomial-to-cell} allows us to pass from a projection polynomial \(f \in \mathbb{Z}[x_1,\ldots,x_k]\) to the continuous semialgebraic functions \(\phi : C' \to \mathbb{R}\), where \(C' \subset \mathbb{R}^{n-1}\) is a cylindrical cell, from Definition \ref{def:cells} which define some of the section cells in the cylinder \(C' \times \mathbb{R}\). The construction described in \citet{bgv15}, Theorem 3.20 (and related lemmas) works with these continuous semialgebraic functions. However, we are given only the projection polynomials \(f\) of which \(\phi\) defines one of the roots.

Let \(C\) be a section cell in \(\mathbb{R}^n\): a semialgebraic set which is the graph of a continuous semialgebraic function \(\phi : C' \to \mathbb{R}\), where \(C' \subset \mathbb{R}^{n-1}\) is a cylindrical cell. A simple example in \(\mathbb{R}^2\) demonstrates that, although \(C\) is a semialgebraic set, \(\phi\) may not be a polynomial. Indeed, let
\[ C := \{ (x,y) \in \mathbb{R}^2 \mid x > 0, y > 0, y = x^2 \} \]
be a cylindrical cell in \(\mathbb{R}^2\) such that \(C' := {\operatorname{proj}_{\mathbb{R}^{1}}}(C) = \{ x \in \mathbb{R}\mid x > 0 \}\). We can write
\[
\phi(x) = +\sqrt{x}
\]
such that \(C\) is the graph of \(\phi\vert_{C'}\). However, it's clear that \(\phi\) is not a polynomial.

In computations, we work exclusively with section cells. When dealing with sector cells, we will consider the graphs of functions defining their top and bottom.
Since we will be using SACLIB and sometimes Singular, which are polynomial libraries, we will not be able to use the functions \(\phi\) in computations. We will instead use a different representation for a section cell \(C\) in \(\mathbb{R}^n\). Let \(C\) be the root of a polynomial \(f \in \mathbb{Z}[x_1,\ldots,x_n]\) and \(C' := {\operatorname{proj}_{\mathbb{R}^{n-1}}}(C)\) satisfy the conditions in Proposition \ref(prp:coste-polynomial-to-cell). Then
\[
C \subset Z := \{ (\mathbf{x},x_n) \in \mathbb{R}^n \mid \mathbf{x} \in C', f(\mathbf{x},x_n) = 0 \} \subset C' \times \mathbb{R}.
\]
In particular, \(Z\) consists of the roots of \(f\) in the cylinder \(C' \times \mathbb{R}\), including the section cell \(C\). It is clear from the Tarski-Seidenberg theorem that it is possible to represent \(C\) as a first-order Boolean formula. In practice, since \(C\) is the root of a polynomial, we may define it using Thom's Lemma \citep{costeRoyThomLemma}. I.e., a root of a polynomial may be defined by sign conditions on its derivatives. Thus, let
\[
C = \{ (\mathbf{x},x_n) \in \mathbb{R}^n \mid \mathbf{x} \in C', f(\mathbf{x},x_n) = 0, g_1(\mathbf{x},x_n) > 0, \ldots, g_k(\mathbf{x},x_n) > 0 \}
\]
where \(g_1,\ldots,g_k\) are derivatives of the polynomial \(f\).

\hypertarget{cad-cells-and-their-defining-formulas}{%
\subsection{CAD cells and their defining formulas}\label{cad-cells-and-their-defining-formulas}}

Although it is possible to construct a ``full'' (sign-invariant) CAD, QEPCAD-B provides an implementation of the ``truth-invariant'' CAD described in Proposition \ref{prp:collins-sets}. Indeed, QEPCAD-B, being designed primarily to perform quantifier elimination, frequently constructs a ``partial'' CAD of \(\mathbb{R}^n\) \citep{brownQepcad}.
We will force the construction of the sign-invariant CAD and use McCallum's projection operator so as to obtain smooth cells (see Proosition \ref{prp:mc-smooth}).

Once constructed, one may want to examine individual cells of the CAD.
In order to do this, we will need a convenient representation for each cell.
Depending on the purpose for which the CAD has been constructed, a particular representation may be chosen. For example, if we only need a witness, i.e., some point in the cell, only the sample points will suffice. Indeed, this is a common requirement and Maple's `RegularChains::CylindricalAlgebraicDecompose' function provides output in this representation \citep{chen2014}.
On the other hand, one might want to view each cell as a semialgebraic set. In this case, a defining formula will be necessary.
Such a representation using only the input and projection polynomials may be impossible and, as such, an ``extended language'' has been introduced in both Maple and QEPCAD \citep[\citet{brownQepcad}]{chen2014}. The extended language includes the rules of first-order Boolean formulas (see Definition \ref{def:qff}) along with a means of representing ``the \(i\)-th root of polynomial \(f\)''. We find this representation a little inconvenient (TODO why?) and would prefer each cell to be representable by an ordinary first-order Boolean formula.

To see how the signs of projection factors may be insufficient to represent a cylindrical cell, consider the following simple example in \(\mathbb{R}^2\).
Let \(f = x - y^2\) and construct an \(\{f\}\)-invariant CAD. The projection polynomials
\[
P = \{ x, x - y^2 \}.
\]
** TODO: draw a picture, label cells by C\_1 and C\_2. **
The two distinct cells \(C_1\) and \(C_2\) having sign \(x > 0, x - y^2 = 0\). By Thom's Lemma, it is possible to represent these cells by sign conditions on derivatives of \(f\).
In this example, it is clear that another polynomial, \(y\), is needed to distinguish between these cells. \citet{brown99} proposed an algorithm for constructing a solution formula where the projection polynomials are not sufficient. The basic idea is that ``conflicting pairs'', distinct cells having the same signature (signs of projection factors), are identified, then additional derivatives of projection factors are added so that the conflicting pairs can be distinguished.

The algorithm proposed by \citet{brown99} is implemented as the ``solution formula construction phase'' in QEPCAD. A small modification has been made such that this algorithm may be used to construct formulas for individual cells as opposed to the set of points satisfying the input formula. More precisely, the definition of a conflicting pair was slightly modified.

\begin{definition}
Let \(C_1\) and \(C_2\) be distinct cells in a CAD \(\cal D\) of \(\mathbb{R}^n\). Each cell \(C\) is assigned a truth value \(T_C \in \{\tt{True}, \tt{False}, \tt{undet}\}\) and a list \(S_C = (S_1,\ldots,S_k)\) where \(S_i = (s_{i,1},\ldots,s_{i,s_i}, 1\le i \le k\) is the list of signs of level-\(i\) (factorised) projection polynomials \(f_1,\ldots,f_{i_s} \in \mathbb{Z}[x_1,\ldots,x_i]\), with \(s_{i,j} \in \{-1,0,1\}\).
\((C_1, C_2)\) is called a conflicting pair in \(\cal D\) if \(T_{C_1}, T_{C_2} \in \{\tt{True}, \tt{False}\}\) and \(T_{C_1} = T_{C_2}\) and \(S_{C_1} = S_{C_2}\).
\end{definition}

The condition on truth values being equal has been dropped so that every cell in the CAD may be distinguished by the signs of its projection polynomials only. In all other aspects, Brown's solution formula construction algorithm may be applied unchanged. In order to represent a cell by a quantifier-free Booleean formula, it may be necessary to split a cell into several disjoint semialgebraic sets. Thus, each cell will be represented in disjunctive normal form, where each literal is a sign condition on a projection polynomial or one of its derivatives.

\hypertarget{sec:smooth-strat}{%
\chapter{Smooth Stratification}\label{sec:smooth-strat}}

We now turn our attention to an algorithm for computing a smooth stratification of a semialgebraic set. A smooth stratification is a partition of a semialgebrac set into smooth manifolds. \citep{whitney1965} proved that every complex (and real) analytic variety admits a smooth stratification. Later, \citep{thom1969} proved that every analytic set admits a smooth stratification and \citep{le2010} proved that any set definable in an O-minimal structure also admits a Whitney stratification.

In this section, an algorithm due to \citep{gv1995} for computing a basic weak stratification of an elementary semi-pfaffian set, such that each of the strata is ``nicely defined'' will be presented.

Let \(X \subset \mathbb{R}^n\) be a semianalytic set. \(X\) is nonsingular and has dimension \(k\) at a point \(x_0 \in X\) if there exist real analytic functions \[
h_1,\ldots,h_{n-k}
\]
defined in an open set \(U\) containing \(x_0\) such that
\[
dh_1(x_0) \ne 0 \land \cdots \land  dh_{n-k}(x_0) \ne 0
\]
and
\[
X \cap U = \{ x \in U \mid h_1(x) = 0 \land \cdots \land h_{n-k}(x) = 0 \}
\]
Let \(Y \subset \mathbb{R}^n\) be a semi-pfaffian set.
\(X \subset Y\) is called effectively nonsingular (of dimension \(k\)) if functions \(h_1,\ldots,h_{n-k}\) belong to the same pfaffian chain as the functions defining \(Y\).

\begin{definition}
A basic weak stratification of a semi-pfaffian set \(X \subset \mathbb{R}^n\) is a partition of \(X\) into a finite number of non-singular manifolds \(X_k, 0 \le k \le n\) where each \(X_k\) is effectively nonsingularand has codimension \(k\).
\end{definition}

\hypertarget{description-of-the-algorithm}{%
\subsection{Description of the algorithm}\label{description-of-the-algorithm}}

We now present the algorithm from \citet{gv1995} as it is applied to semialgebraic sets. Since polynomials are a sub-class of Pfaffian functions, the algorithm can be applied directly to semialgebraic sets. However, in the original form, a bound on the number of partial derivatives is computed. For the semialgebraic case, we simply need to take the degree of polynomials defining the semialgebraic set.

Let \(f \in \mathbb{Z}[x_1,\ldots,x_n]\) be a polynomial and let \((m_1,\ldots,m_n) \subset \mathbb{Z}_{\ge 0}^n\) be a multi-index of its partial derivative. I.e., we write
\[
\partial^{(m_1,\ldots,m_n)}
\]
to mean
\[
\dfrac{\partial^{m_1} f}{\partial x_1} \cdots \dfrac{\partial^{m_n} f}{\partial x_n}.
\]

\begin{definition}
We define the partial differential operator \(\partial_{\mathbf{h}, \mathbf{i}, j} f\) (where the argument \(f\) is a polynomial) as the determinant
\[
\det\begin{pmatrix}\dfrac{\partial h_{1}}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial h_{1}}{\partial x_{i_{k}}} & \dfrac{\partial h_{1}}{\partial x_{j}}\\
 & \vdots\\
\dfrac{\partial h_{k}}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial h_{k}}{\partial x_{i_{k}}} & \dfrac{\partial h_{k}}{\partial x_{j}}\\
\dfrac{\partial f}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial f}{\partial x_{i_{k}}} & \dfrac{\partial f}{\partial x_{j}}
\end{pmatrix}.
\]
We write \(\partial^m_{\mathbf{h}, \mathbf{i}, j}\) to mean the \(m\)-th iteration of \(\partial_{\mathbf{h}, \mathbf{i}, j}\).
\end{definition}

We proceed by induction on \(i_0\).

\begin{itemize}
\item
  Base case: \(i_0 = n\), return immediately.
\item
  Recursive case:

  \begin{itemize}
  \item
    Initialise \[X' := X.\]
  \item
    Consider each multi-index \(\mathbf{m} = (i_n,\ldots,i_{k+1},j) \subset \mathbb{Z}_{\ge 0}^{n-k} \times \{1,\ldots,s\}\) in ascending lexicographical order, beginning with \[
    (0,\ldots,0,1,1).
    \]
  \end{itemize}

  Index \((i_n,\ldots,i_1,i_0)\) has the following property:
  \[
  M_{i_0} \preceq (i_n,\ldots,i_1) \preceq (0,\ldots,1), M_{i_0} = \deg(f_i).
  \]

  \begin{itemize}
  \item
    Let \((\mathbf{J}, h_k) \in \mathbf{G}\) such that \[
      \mathbf{J} = (0, \ldots, 0, i_{\ell} - 1, i_{\ell - 1}, \ldots, i_{k+1}).
      \]
  \item
    Compute
    \[
      s_k := \partial_{(h_1,\ldots,h_k), (i_1,\ldots,i_k), i_\ell} h_k
      \]
  \item
    Define
    \[
      Y_k := \{ \mathbf{x} \in X' \mid s_k(\mathbf{x}) \ne 0 \}
      \]
    (Ntoe \(h_1(\mathbf{x}) = 0\) for all \(\mathbf{x} \in Y_k\).)
  \item
    Define
    \[
      U_k := \{ \mathbf{x} \in \mathbb{R}^n \mid h_k(\mathbf{x}) = 0, s_k(\mathbf{x} \ne 0, g_1(\mathbf{x}) > 0 , \ldots, g_l(\mathbf{}) > 0 \},
      \]
    a nonsingular subset of \(\mathbb{R}^n\) having codimension \(k-1\)
  \item
    If \(Y_k\) is an open subset of \(U_k\), then \(Y_k\) is nonsingular of codimension \(k-1\).

    \begin{itemize}
    \item
      Update \[X_k := X_k \cup Y_k.\]
    \item
      Add polynomial \(s_k\), i.e.,
      \[
      \mathbf{G} := \mathbf{G} \cup \{ ((i_\ell,\ldots,i_1), s_k) \}
      \]
    \end{itemize}
  \item
    Otherwise, \(Y_k\) is not smooth. Call recursively
    \[
      Stratify((k+1, \mathbf{G}, (i_\ell,i_k,\ldots,i_1,0), (s_k,h_k,\ldots,h_1,0), \mathbf{K})
      \]
  \item
    Update
    \[
      X' := \{ \mathbf{x} \in X' \mid s_k(\mathbf{x}) = 0 \},
      \]
    a proper (possibly empty) subset of old \(X'\).
  \item
    If \(X' = \emptyset\), return. Otherwise, continue with the next index with respect to lexicographical order.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Let \(X \subset \mathbb{R}^n := \{ f_1 = 0 \land \cdots \land f_k = 0 \land g_1 > 0 \land \cdots \land g_l > 0 \}\) be a semialgebraic set. We first apply some pre-processing to the polynomials defining \(X\). Let \[
\mathbf{G} := ((0,\ldots,0,1), f_1),\ldots, ((0,\ldots,0,s),f_s)).
\]
Then the algorithm is called as follows
\[
\cal{X} = \rm{Stratify}(0, \mathbf{G}, (0), (0), (g_1,\ldots,g_t)).
\]

A couple of shortcuts can be taken in the implementation to make the code simpler and more efficient.
First, suppose that we are considering index
\[
(0,\ldots,0,i_\ell,\ldots,i_{k+1},i_k,\ldots,i_1,i_0).\]
Partial differentials with index lexicographically less than \((i_{k+1},0,\ldots,0)\) have been computed on a previous round of induction and were passed in the argument \(\mathbf{G}\).
Furthermore, the function \(h_k\), having index
\[
(0,\ldots,0,i_{\ell -1},\ldots,i_0)
\]
has already been computed, so it can be taken directly from the list \(\mathbf{G}\).
In fact, there is a convenient way to find the function with index \((0,\ldots,0,i_\ell - 1, \ldots,i_1,i_0)\). Let us first illustrate this with an example. Let \(M = (1,2,2)\) and consider the lexicographically ordered list of indices
\[
\begin{matrix}
L_1 :=\ &  (0,0,0),&(0,0,1),&(0,0,2),&(0,1,0),&(0,1,1),&(0,1,2),&(1,0,0),&(1,0,1)&\ldots\\
L_2 := \ & & (0,0,0),&(0,0,1),&(0,0,0),&(0,0,1),&(0,0,2),&(0,0,0),&(0,0,1)&\ldots.\\
\end{matrix}
\]
Observe that for indices \((0,0,1)\), \((0,1,0)\) and \((1,0,0)\) in \(L_1\), the corresponding element in \(L_2\) is \((0,0,0)\) and the corresponding elements for subsequent indices are those in the lexicographical order.
I.e., we see that the index of \(h_k\) ``chases after'' the index of \(s_k\), resetting each time \(\ell\) is incremented.
More precisely, when \(\ell = 1\) and \(s_1\) has index \((0,\ldots,0,i),i>0\), \$h\_1 has index \((0,\ldots,0,i-1)\). I.e., our initial ``chase index'' is the previous element in the list. When \(\ell\) is incremented, we need to return to the first element in the list, \((0,\ldots,0)\) and proceed lexicographically through the indices until \(\ell\) is incremented again, at which point we return to the beginning of the list. This gives us the property that when \(h_k\) has index \((0,\ldots,0,i_\ell,i_{\ell-1},\ldots,i_1)\), \(h_1\) will have index \((0,\ldots,0,i_\ell - 1,i_{\ell - 1},\ldots,i_1)\) while only requiring two very basic list operations: get the next element and return to the beginning. In the example, we considered only one polynomial. To extend to multiple polynomials, since each will have a different \(M\), we need to keep a separate ``chase list'' for each one.

Since the program has been implemented in QEPCAD, which utilises linked lists, it was important to ensure that appending to the end of the list is as efficient as possible. To avoid \(O(n)\) insertion complexity, we keep a pointer to the last-but-one element in the list, i.e., suppose \(L = (a_1,(\ldots,(a_{r-1},(a_r,(\rm{NIL})))\ldots)\) then \(L_{\rm{append}} = (a_{r-1},(a_r,(\rm{NIL})))\). Then, if we wish to append \(b\) to the end of \(L\), we simply need to set the reductum of \(L_{\rm{append}}\) to \((a_r,(b,(NIL)))\).

Secondly, observe that only the last row and last column in the \((k\times k\)-matrix for the partial differential operater
\[
\partial_{\mathbf{h},\mathbf{i},j} f = \det\begin{pmatrix}\dfrac{\partial h_{1}}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial h_{1}}{\partial x_{i_{k}}} & \dfrac{\partial h_{1}}{\partial x_{j}}\\
 & \vdots\\
\dfrac{\partial h_{k}}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial h_{k}}{\partial x_{i_{k}}} & \dfrac{\partial h_{k}}{\partial x_{j}}\\
\dfrac{\partial f}{\partial x_{i_{1}}} & \cdots & \dfrac{\partial f}{\partial x_{i_{k}}} & \dfrac{\partial f}{\partial x_{j}}
\end{pmatrix}.
\]
depend on \(f\) and \(i\). As a result, we can re-use the \((k-1\times k-1)\)-matrix consisting of the first \(k-1\) rows and columns of \(\partial_{\mathbf{h}, \mathbf{i}, j} f\).
In the implementation, we can receive as an argument, from the previous round of induction, this \((k-1\times k-1)\)-matrix which will be used throughout that round. We still, however, need to compute the determinant for every new \(s_k\).

We will now present, from \citep[Theorem 1]{gv1995}, the proof that this algorithm does indeed produce smooth strata and also that it terminates.

This algorithm is doubly exponential in the number of variables. For the polynomial case, the complexity is
\[
s^n (d+1)^{2^{O(n)}}
\]
where \(s\) is the number of polynomials \(f_1,\ldots,f_s\), \(d\) is their degree and \(n\) is the number of variables. \citep[Section 4]{gv1995}

\hypertarget{worked-example}{%
\subsection{Worked example}\label{worked-example}}

We illustrate the smooth stratification algorithm with a worked example. Consider
\[
\{ z = 0, x^2-y^2=0 \} \subset \mathbb{R}^3.
\]
Note that the algorithm imposes an order on polynomials. In this case, \(h_1 = z\) will be considered first. The algorithm proceeds as follows

\(k=1,G_{1}=\left(z,x^{2}-y^{2}\right),J=\begin{pmatrix}\partial h_{1}/\partial y_{1}\end{pmatrix}\)
\begin{equation}
\begin{matrix}
i = 1 & M=(0,0,1,1), & h_{1}=z, & s_{1}=0, & \text{skip}\\
i = 1 & M=(0,0,1,2), & h_{1}=x^{2}-y^{2} & s_{1}=2x, & Y_{1}:=\left\{ z=0,x^{2}-y^{2}=0,2x\ne0\right\} =X\setminus\left\{ x=0\right\} \\
&  &  &  & U_{1}:=\left\{ x^{2}-y^{2}=0,2x\ne0\right\} 
\end{matrix}
\end{equation}
\(Y_{1}\) is not an open subset of \(U_{1}\), recurse.

\(k=2,G_{2}=\left(z,x^{2}-y^{2},2x\right),J=\begin{pmatrix}2x & \partial s_{1}/\partial y_{2}\\ \partial h_{2}/\partial x & \partial h_{2}/\partial y_{2} \end{pmatrix}\)
\begin{equation}
\begin{matrix}
i = 2 & M=(0,1,1), & h_{2}=z, & s_{2}=\det\begin{pmatrix}2x & 2y\\
0 & 0
\end{pmatrix}=0, & \text{skip}\\
i = 2 & M=(0,1,2), & h_{2}=x^{2}-y^{2} & s_{2}=\det\begin{pmatrix}2x & 2y\\
2x & 2y
\end{pmatrix}=0 & \text{skip}\\
i = 2 & M=(0,1,3) & h_{2}=2x & \det\begin{pmatrix}2x & 2y\\
0 & 0
\end{pmatrix}=0 & \text{skip}\\
i = 3 & M=(1,0,1) & h_{1}=z & \det\begin{pmatrix}2x & 0\\
0 & 1
\end{pmatrix}=2x & Y_{2}:=Y_{1}\cap\left\{ 2x\ne0\right\} =Y_{2}\\
&  &  &  & U_{2}:=\left\{ z=0,2x\ne0\right\} 
\end{matrix}
\end{equation}
\(Y_{2}\) is an open subset of \(U_{2}\), hence \(Y_{2}=Y_{1}\) is a smooth subset of codimension \(2\). Set \$X\_\{2\} = Y\_\{2\} = Y\_\{1\}. Return to round \(k=1\), Recall that the last index considered in step \(k=1\) was \((0,0,1,2)\).
\begin{equation}
\begin{matrix}
i = 1 & M=(0,0,1,2), & h_{1}=x^{2}-y^{2} & s_{1}=2x, & Y_{1}:=\left\{ z=0,x^{2}-y^{2}=0,2x\ne0\right\} =X\setminus\left\{ x=0\right\} \\
\vdots &  &  & \text{skip until next nenzero partial derivative}\\
i = 2 & M=(0,1,0,2) & h_{1}=x^{2}-y^{2} & h_{1}=2y & Y_{1}:=\left\{ z=0,x^{2}-y^{2}=0,2x=0,2y\ne0\right\} =\emptyset\\
\vdots &  &  & \text{the rest of the partial derivatives do not exist}
\end{matrix}
\end{equation}

At the end of round \(k=1\), \(X_{1}=\emptyset\) and we are left with
\[
X':=\left\{ z=0,x^{2}+y^{2}=0,2x=0,2y=0\right\}=(0,0,0),
\] a single point. \(X_{0}\) is set to \(X'\) and the algorithm terminates.

Note that this weak stratification does not impose any conditions on the boundaries of strata. In particular, the boundary of a stratum need not be a union of strata.

\hypertarget{sec:quasi-affine}{%
\chapter{Quasi-affine cells}\label{sec:quasi-affine}}

Let \[
V := V_1 \cup \ldots \cup V_k
\]
be a family of semialgebraic sets such that \(\dim(V_i) \le 2\) for \(1\le i \le k\).
According to \citep[ Theorem 3.20]{bgv15}, the first step in constructing a CAD with monotone cells is to construct a CAD \(\cal D\) compatible with \(V\) such that each cell of \(\cal D\) is the graph of a quasi-affine map. We do this following \citep[Lemma 3.19]{bgv15}.

\hypertarget{computing-the-smooth-twe-dimensional-locus-of-v}{%
\section{\texorpdfstring{Computing the smooth twe-dimensional locus of \(V\)}{Computing the smooth twe-dimensional locus of V}}\label{computing-the-smooth-twe-dimensional-locus-of-v}}

We begin by computing the smooth 2-dimensional locus, \(W\), of \(V\). This can be done by computing a smooth stratification of \(V\) (as described in Section \ref(sec:smooth-strat)). Let
\[
f_1,\ldots,f_s
\]
be the polynomials defining \(V\). We use a slightly modified version of the smooth stratification algorithm which will avoid the expensive emptiness check. Instead of checking whether each set \(Y_k\) is empty, we just compute all possible partial differentials \(f_M\) for each \(M = (i_n,\ldots,i_1,j)\). A CAD which is sign-invariant with respect to \(f_1,\ldots,f_s\) and all \(f_M\) will be compatible with \(V\) and the smooth two-dimensional locus \(W\).

Alternatively, recall, from Section \ref{sec:cad-construction}), thet smooth cells can be guaranteed by choosing a certain projection operator.
More specifically, according to \citep[ Theorems 2.2.3 and 2.2.4]{mccallum1988}, if there is a finite number of blow-up poits, which will be the case since input sets have dimension at most 2, then smooth cells will be obtained if McCallus's projection operator is used.
Looking towards extend the construction to sets of higher dimension, \citet{mccallum2019} proved that we could use Lazard's projection operator, which does not have the restriction on the dimension of blow-up points.

\hypertarget{ensuring-that-every-cell-is-the-graph-of-a-quasi-affine-map}{%
\section{Ensuring that every cell is the graph of a quasi-affine map}\label{ensuring-that-every-cell-is-the-graph-of-a-quasi-affine-map}}

In order to obtain quasi-affine cells, \citep[Lemma 3.19]{bgv15} states that we need to consider the critical points, \(W_{i}\) and \$W\_\{i,j\}, of projections of \(W\) onto one and two-dimensional coordnate subspaces (indexed by \(i\) and \(j\)) respectively. The classical CAD compatible with \(V, W\) and all \(W_i\) and \(W_{i,j}\), \(1 \le i \le j \le n\) will contain quasi-affine cells.

Let \(f\) be one of the polynomials in \(f_1,\ldots,f_s\). Then the critical points of the projection map onto \({\operatorname{span} \{x_i\}}\) can be found by computing the partial derivative and solving
\[
\dfrac{\partial f}{\partial x_i} = 0.
\]
The solutions of \(\{ f = 0, \partial f / \partial x_i = 0 \}\) are the local maxima and minima of \(f\) along the \(x_i\)-axis. Similarly, the critical points of the projection map onto the two-dimensional subspace \({\operatorname{span} \{x_i,x_j\}}\) are given by the solutions to the system
\[
\{ f = 0, \partial f / \partial x_i = 0, \partial f / \partial x_j \}.
\]
Thus, \(W_i\), the set of critical points of the projection map \({\operatorname{proj}_{{\operatorname{span} \{x_i\}}}}\), are given by \(\lor_{1 \le k \le s} \{ f_k = 0, \partial f_k / \partial x_i = 0 \}\) and \(W_{i,j}\), the set of critical points of \({\operatorname{proj}_{{\operatorname{span} \{x_i,x_j\}}}}\), is given by \(\lor_{1 \le k \le s} \{ f_k = 0, \partial f_k / \partial x_i = 0, \partial f_k / \partial x_j = 0 \}\).
Alternatively, we can compute a CAD which is sign-invariant with respect to the input polynomials \(f_1,\ldots,f_s\) and all first partial derivatives (with respect to all variables \(x_1,\ldots,x_n\)) of the input polynomials.
Note that these first partial derivatives will have already been added if we applied the smooth stratification algorithm, which computes them for \(k=1\), to find \(W\).

Since the smooth stratification algorithm has compleity doubly exponential in the number of variables, and this is also a bound on the number of strata (and therefore number of new polynomials to be added), it makes sense to avoid this computation if possible. Therefore, the choice was made to use McCallum's projection operator and compute a CAD sign-invariant with respect to \[f_1,\ldots,f_s\] (the polynomials appearing in the formula defining \(V\)) and the first partial derivatives
\[
\partial f_j / \partial x_i
\]
for \(1 \le j \le s\) and \(1 \le i \le n\).
Denote this CAD by \(\cal D\).

\hypertarget{sec:monotone-cells}{%
\chapter{Monotone Cells}\label{sec:monotone-cells}}

Now we have a CAD \(\cal D\) such that each 2-dimensional cell is the graph of a quasi-affine map, let us return to \citep[ Theorem 3.20]{bgv15} and discuss how to obtain monotone cells.

\begin{definition}
\protect\hypertarget{def:sub-cad}{}\label{def:sub-cad}Let \(\cal D\) be a CAD of \(\mathbb{R}^n\) and suppose that \(c = \{ x_1 = c_1,\dots,x_k = c_k \}\) is a \(0\)-dimensional section cell in the decomposition induced by \(\cal D\) on \(\mathbb{R}^k\).
By \citep[ Remark 3.8]{bgv15}, the set of all cells of \(\cal D\) contained in the effing coordinate subspace
\[
\{ x_1=c_1,\dots,x_k=c_k \}
\]
forms a cylindrical decomposition of \(\mathbb{R}^{n-k}\). This decomposition will be called the \emph{sub-decomposition} of \(\cal D\) above \(c\), and \(c\) the \emph{base cell} of the sub-decomposition.
\end{definition}

The construction proceeds by induction on \(n\).

\begin{itemize}
\item
  The base case, \(n=1\) is straightforward, since \((0)\) and \((1)\)-cells are already monotone.
\item
  When \(n>1\), consider each cell \(C\) of \(\cal D\) and let \(C'' := \operatorname{proj}op{1}(C)\)

  \begin{itemize}
  \item
    If \(\dim(C'') = 0\), apply the inductive hypothesis to the sub-decomposition of \(\cal D\) above \(C''\).
  \item
    Otherwise, \(C\) has index \(\{1,i_2,\dots,i_n\} \in \{0,1\}^n\). Let \(\alpha\) be the smallest among \(\{2,\dots,n\}\) such that \(i_\alpha = 1\).
    Then \(C' := \operatorname{proj}op{\alpha}(C)\) is a 2-dimensional sector cell and \(C\) is the graph of a quasi-affine map
    \[
    \mathbf{f} = (f_1,\dots,f_{n-2}) : {\operatorname{span} \{x_1,x_\alpha\}} \to {\operatorname{span} \{x_2,\ldots,x_{\alpha - 1}, x_{\alpha+1},\ldots,x_n\}}.
    \]
    Since \(\mathbf{f}\) is quasi-affine, each component \(f_j : {\operatorname{span} \{x_1,x_\alpha\}} \to {\operatorname{span} \{x_j\}}\) is quasi-affine, too.

    Let \(X \subset {\operatorname{span} \{x_1,x_\alpha\}}\). By \citep[Lemma 3.18]{bgv15}, there exists a refinement of the CAD of \({\operatorname{span} \{x_1,x_\alpha\}}\), obtained by intersecting \(X\) with straight lines and half-planes of the kind
    \[
    \{x_1 < c\}, \{x_1 = c\}, \{x_1 > c\}
    \]
    where \(c \in \mathbb{R}\), such that \(X\) is a union of semi-monotone sets \(B\) and \(f_j\vert_B\) is a monotone function.
    By \citep[ Lemma 3.11]{bgv15}, refinements of this kind preserve the cylindrical structure of \(\cal D\).
  \end{itemize}
\end{itemize}

\hypertarget{two-dimensional-semi-monotone-sectors}{%
\section{Two-dimensional semi-monotone sectors}\label{two-dimensional-semi-monotone-sectors}}

\begin{theorem}
\protect\hypertarget{thm:bgv-monotone}{}\label{thm:bgv-monotone}\citep[Lemma 3.18]{bgv15}

Let \(X \subset \mathbb{R}^2\) be an open, bounded set and \(f : X \to \mathbb{R}\) be a quasi-affine function.
Then there is a cylindrical decomposition of \(\mathbb{R}^2\) compatible with \(X\), obtained by intersecting \(X\) with straight lines \[\{x_1 = c\}\] and half-planes \[\{x_1 < c\},\{x_1 > c\}\] such that the restriction \(f\vert_B\) for every cell \(B \subset X\) is a monotone function.
\end{theorem}

\hypertarget{semi-monotone-sets}{%
\subsection{Two-dimensional semi-monotone sets}\label{semi-monotone-sets}}

The proof of Theorem \ref{thm:bgv-monotone} proceeds in two stages: first, \(X \subset {\operatorname{span} \{x_1,x_\alpha\}}\) is refined such that each \(Y \subset X\) is a semi-monotone set.
Consider the intersection \(X \cap \{x_1 = c\}\) for all \(c\in \mathbb{R}\). This intersection is a finite union of pairwise disjoint intervals. Let \({\cal I} (c)\) be the family of these intervals associated with the point \(c\). Define
\[
\gamma := \{ (x_1,x_2) \in \mathbb{R}^2 \mid x_2 \text{ is an endpoint of an interval in } {\cal I}(x_1) \}.
\]

\begin{lemma}
\protect\hypertarget{lem:gamma-top-bottom}{}\label{lem:gamma-top-bottom}

Let \(C\) be a \((1,0,\ldots,0,1)\)-cell and \(X := {\operatorname{proj}_{{\operatorname{span} \{x_1,x_\alpha\}}}} (C)\). Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) is a cylindrical sector cell in \(\mathbb{R}^2\).
\item
  The family \({\cal I}(C)\) is either empty or contains a single open interval for all \(c\in \mathbb{R}\).
\item
  \(\gamma\) consists of the union of the top and bottom of \(X\), each of which (if non-empty) is the graph of a continuous definable function.
\end{enumerate}

\end{lemma}

\begin{proof}
Let \(X' := {\operatorname{proj}_{\mathbb{R}^{1}}}(C)\) and \(C' := {\operatorname{proj}_{\mathbb{R}^{\alpha-1}}}(C)\).
Observe that \(X'\) is a \((1)\)-cell and \(C'\) is a \((1,0,\ldots,0)\)-cell.
By definition
\[
C = \{ (\mathbf{x},t) \mid \mathbf{x} \in C', f(\mathbf{x}) < t < g(\mathbf{x})\}
\]
where \(f,g : \mathbb{R}^{\alpha - 1} \to \mathbb{R}\) are continuous definable functions such that \(f(\mathbf{x}) < g(\mathbf{x})\) for all \(\mathbf{x} \in C'\).

Since \(C'\) is a \((1,0,\ldots,0)\)-cell, it can be viewed as the graph of a continuous definable map
\[
\mathbf{h} = (h_1,\ldots,h_{\alpha - 2}) : X' \to {\operatorname{span} \{x_2,\ldots,x_{\alpha-1}\}}.
\]
\(C\) can therefore be rewritten in terms of only \(x_1\) and \(t\).
\[
C := \{ (x_1,\mathbf{h}(x_1),t) \mid x_1 \in X', f(x_1,\mathbf{h}(x_1)) < t < g(x_1,\mathbf{h}(x_1))\}.
\]

Define
\begin{align}
\varphi &:\> C'' \to \mathbb{R}& \psi &:\> C'' \to \mathbb{R}\\
\varphi(x_1) &= f(x_1,\mathbf{h}(x_1)) & \psi(x_1) &= g(x_1,\mathbf{h}(x_1))
\label{eq:phi-psi}
\end{align}

Observe that \(\varphi\) and \(\psi\) are continuous, definable functions. By the definition of \(f\) and \(g\), we also have \(\phi(x_1) < \psi(x_1)\) for all \(x_1\in X'\).

Thus, we can write
\begin{equation}
X = \{ (x_1,t) \mid x \in X', \varphi(x_1) < t < \psi(x_1) \}.
\label{eq:cell-x}
\end{equation}
It is clear that \(X\) is a cylindrical sector cell.
By the definition of sector cell, the bottom of \(X\) is the graph of \(\varphi\) and the top of \(X\) is the graph of \(\psi\).

Now consider the family
\[
{\cal I}(c) := \{ t \mid \varphi(c) < t < \psi(c) \}.
\]
Using Equation \eqref{eq:cell-x}, it is easy to deduce that if \(c \in X'\) then \({\cal I}(c)\) contains a single open interval. On the other hand, if \(c \not \in X'\), \({\cal I}(c)\) is clearly empty.

It follows that \(\gamma\) consists of the points of the top and bottom of \(X\), which are the graphs of functions \(\psi\) and \(\varphi\) respectively.
\end{proof}

The refinement is achieved by finding a set of real numbers
\[
(c_1,\ldots,c_t)
\]
such that, for each \(1 \le i < t\),
\[
X \cap \{c_i < x_1 < c_i+1\}
\]
is a semi-monotone set. By \citep[Theorem 1.7]{bgv13}, this can be achieved by ensuring that
\[
\gamma \cap \{ c_i < x_1 < c_{i+1}\}
\]
contains only monotone curve intervals.

Applying Lemma \ref{lem:gamma-top-bottom} to \(C\), we obtain continuous definable functions \(\varphi,\psi : X' \to \mathbb{R}\) defining the bottom, \(X_B\), and top, \(X_T\), of \(X\) respectively.

Let \[
(c_1,\ldots,c_t)
\]
be the critical points of functions \(\varphi\) and \(\psi\). Then, for all \(1 \le i < t\), \(\phi\) (resp \(\psi\)) is either strictly increasing in, strictly decreasing in, or independent of \(x_1\) on the interval \((c_i, c_{i+1})\).

\hypertarget{sec:lagrange-refinement}{%
\subsection{\texorpdfstring{Finding the critical points of \(\varphi\) and \(\psi\)}{Finding the critical points of \textbackslash varphi and \textbackslash psi}}\label{sec:lagrange-refinement}}

We now discuss how to find these critical points.

Let
\begin{equation}
{\cal A} = ({\cal A}_1,\ldots,{\cal A}_n),
\label{eq:proj-fac-set}
\end{equation}
where \({\cal A}_i \subset \mathbb{Z}[x_1,\ldots,x_i]\), be the projection factor set for \(\cal D\). For convenience, we say that \(g(\mathbf{x}) = 0\) for some \(g \in A_k\) and \(\mathbf{x} \in \mathbb{R}^n\), such that \(k < n\), if \(g({\operatorname{proj}_{\mathbb{R}^{k}}}(\mathbf{x})) = 0\).
Let \(C\) be a \((1,0,\ldots,0,1)\)-cell of the decomposition induced by \(\cal D\) on \(\mathbb{R}^{\alpha}\) and consider the \((1,0,\ldots,0)\)-cell
\[
C' := {\operatorname{proj}_{\mathbb{R}^{\alpha - 1}}}(C)
\]
of the decomposition induced by \(\cal D\) on \(\mathbb{R}^{\alpha - 1}\). Observe that
\[
{\operatorname{proj}_{\mathbb{R}^{1}}}(C) = (a,b) \subset \mathbb{R}\cup \{-\infty, \infty\}
\]
and, since \(C'\) is a section cell, there exist polynomials
\[
g_2 \in {\cal A_2},\ldots,g_{\alpha - 1} \in {\cal A_{\alpha - 1}}
\] such that \(g_i(\mathbf{x}) = 0\) for all \(1\le i \le \alpha - 1\) and \(\mathbf{x} \in (C')\).
Therefore, there exists a one-dimensional algebraic variety
\[
V' := \left\{ g_2(\mathbf{x}) = 0, \ldots, g_{\alpha - 1}(\mathbf{x}) = 0 \right\}
\]
such that \(C' \subset V'\).

Now consider the top of \(C\), denoted by \(C_T\).
By definition, if \(C\) is not bounded from above, then \(C_T\) does not exist. Otherwise, \(C_T\) is the graph of a continuous definable function \(h : C' \to \mathbb{R}\).
In the first case, there is nothing to do, since \(C_T\) can be thought of as being independent of \(x_\alpha\).
In the second case, \(C_T\) can be written as
\begin{equation}
\{ (x_1,\ldots,x_\alpha) \mid a < x_1 < b, g_2(x_1,\ldots,x_{\alpha - 1}) = 0, \ldots, g_{\alpha - 1}(x_1,\ldots,x_{\alpha - 1}) = 0, x_\alpha = h(x_1,\ldots,x_{\alpha - 1}) \}.
\label{eq:c-alpha-top}
\end{equation}
By \textbf{TODO} \(C_T\) is \(C^\infty\) smooth, therefore \(h\) is a differentiable function everywhere in \(C'\).

This representation lends itself naturally to the problem of Lagrange multipliers.

\begin{proposition}
\protect\hypertarget{prp:lagrange-multipliers}{}\label{prp:lagrange-multipliers}Let \(f : \mathbb{R}^n \to \mathbb{R}\) and \(g_1,\ldots,g_k : \mathbb{R}^n \to \mathbb{R}\) be continuous functions with continuous first partial derivatives.
Local maxima and minima of \(f\), subject to the constraints \(g_1=0,\ldots,g_k=0\) can be found by computing the critical points of the function
\[
\mathcal{L}(\mathbf{x}, \lambda_1,\ldots,\lambda_k) = f(\mathbf{x}) - \lambda_1 g_1(\mathbf{x}) - \cdots - \lambda_k g_k(\mathbf{x}),
\]
where \(\mathbf{x} \in \mathbb{R}^n\) and \((\lambda_1,\ldots,\lambda_k) \in \mathbb{R}^k\) are new variables.

Critical points can be found by solving the system of equations
\begin{equation}
\dfrac{\partial f}{\partial x_i} - \lambda_1 \dfrac{\partial g_1}{\partial x_i} - \cdots - \lambda_k \dfrac{\partial g_k}{\partial x_i}= 0,
\label{eq:lagrange}
\end{equation}
where \(1\le i \le n-1\),

for \(\lambda_1,\ldots,\lambda_k\).
\end{proposition}

\begin{remark}
Using variables \((x_1,\ldots,x_{\alpha-1})\), constraints \(g_2,\ldots,g_{\alpha - 1}\) and function \(h\) from Equation \eqref{eq:c-alpha-top}, the system from Equation \eqref{eq:lagrange} can be written in matrix form as follows.
\[
\begin{pmatrix}\dfrac{\partial g_{2}}{\partial x_{1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{1}}\\
\vdots &  & \vdots\\
\dfrac{\partial g_{2}}{\partial x_{\alpha-1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{\alpha-1}}
\end{pmatrix}\begin{pmatrix}\lambda_{1}\\
\vdots\\
\lambda_{\alpha-2}
\end{pmatrix}=\begin{pmatrix}\dfrac{\partial h}{\partial x_{1}}\\
\vdots\\
\dfrac{\partial h}{\partial x_{\alpha-1}}
\end{pmatrix}
\]

It is clear that, if a solution exists, then the last column
\(\left(\tfrac{\partial h}{\partial x_{1}},\ldots, \tfrac{\partial h}{\partial x_{\alpha-1}}\right)^T\)
will be a linear combination of the first \(\alpha - 1\) columns (in \(g_2,\ldots,g_{\alpha - 1}\)).
Hence, optimal values for \((x_1,\ldots,x_{\alpha-1})\) exist and satisfy
\begin{equation}
\det\begin{pmatrix}\dfrac{\partial g_{2}}{\partial x_{1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{1}} & \dfrac{\partial h}{\partial x_{1}}\\
\vdots &  &  & \vdots\\
\dfrac{\partial g_{2}}{\partial x_{\alpha-1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{\alpha-1}} & \dfrac{\partial h}{\partial x_{\alpha-1}}
\end{pmatrix}=0.
\label{eq:jacobi-det}
\end{equation}
\end{remark}

Equation \eqref{eq:jacobi-det} gives a direct formula for formula to solve Equation \eqref{eq:lagrange} for \(x_1,\ldots,x_{\alpha - 1}\). Refinement points \((c_1,\ldots,c_t)\) are the \(x_1\)-coordinates of these solutions.

Since \(C_T\) is a section cell, there exists a polynomial \(g_\alpha \in {\cal A}_\alpha\) such that \[
C_T := \{ \mathbf{x} \in \mathbb{R}^\alpha \mid {\operatorname{proj}_{\mathbb{R}^{\alpha - 1}}}(\mathbf{x}) \in C', g_\alpha(\mathbf{x}) = 0 \}.
\] Thus, there exists an algebraic variety
\begin{equation}
V := \left\{ g_2(\mathbf{x}) = 0, \ldots, g_{\alpha-1}(\mathbf{x}) = 0 g_\alpha(\mathbf{x}) = 0 \right\}
\label{eq:variety-v}
\end{equation}
such that \(C_T \subset V\), where \(g_2,\ldots,g_{\alpha - 1}\) are the same polynomials appearing in Equation \eqref{eq:c-alpha-top}.

Note that \(g_\alpha \in \mathbb{Z}[x_1,\ldots,x_\alpha]\), while \(h\) from Equation \eqref{eq:jacobi-det} is expected to be a continuous differentiable function from \(\mathbb{R}^{\alpha - 1} \to \mathbb{R}\).
We need to compute derivatives of the implicit \(g_\alpha\). I.e.,
\begin{equation}
\dfrac{d x_\alpha}{d x_i} = \dfrac{\partial g_\alpha / \partial x_i}{\partial g_\alpha / \partial x_\alpha}
\label{eq:total-deriv}
\end{equation}
for \(1\le i \le \alpha - 1\).
Let \(J_T\) be the determinant of the matrix of partial derivatives from Equation \eqref{eq:jacobi-det} with each \(\partial h / \partial x_i, 1 \le i \le \alpha - 1\) replaced with \(d x_\alpha / d x_i\) from Equation \eqref{eq:total-deriv}. Observe that the denominator of \(\partial h / \partial x_i\), for all \(1 \le i \le \alpha - 1\), is equal to
\[d_T := \partial g_\alpha / \partial x_\alpha,\]
so the last column of the matrix can be written as
\[
\dfrac{1}{d_T} \left( \partial g_{\alpha} / x_1 , \ldots , \partial g_{\alpha} / x_{\alpha - 1}\right)^T.
\]
Thus, the determinant
\[
J_T = \frac{1}{d_T} J'_T,
\]
where \(J'_T\) is the matrix from Equation \eqref{eq:jacobi-det} with the \(\partial h / \partial x_i\) replaced with \(\partial g_\alpha / \partial x_i\) for \(1\le i \le \alpha - 1\). I.e.,
\begin{equation}
\det\begin{pmatrix}\dfrac{\partial g_{2}}{\partial x_{1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{1}} & \dfrac{\partial g_\alpha}{\partial x_{1}}\\
\vdots &  &  & \vdots\\
\dfrac{\partial g_{2}}{\partial x_{\alpha-1}} & \cdots & \dfrac{\partial g_{\alpha-1}}{\partial x_{\alpha-1}} & \dfrac{\partial g_\alpha}{\partial x_{\alpha-1}}
\end{pmatrix}=0.
\label{eq:jacobi-det-2}
\end{equation}

Observe that \(J_T\) is a rational function: a fraction in which the numerator and denominator are both polynomials. \(\mathbf{x} \in \mathbb{R}^{\alpha - 1}\) is a solution of this rational function if and anly if \(J'_T(\mathbf{x}) = 0\) and \(d_T(\mathbf{x}) \ne 0\). Thus, solutions of the system \[
\{ J'_T = 0, d_T \ne 0 \}
\] should be found.
Observe that this is a semialgebraic set, since
\(\{ d_T(\mathbf{x}) \ne 0 \} \leftrightarrow \mathbb{R}^{\alpha - 1 } \setminus \{ d_T(\mathbf{x}) = 0 \}\).
Note that, when \(\deg(d_T) = 0\), \(d_T\) is a constant and therefore has no solutions. Thus, the condition \(d_T = 0\) can be dropped.

Repeating this process to obtain \(J'_B\) and \(d_B\), if sector cell \(C\) is bounded from below, we have a set of polynomial equations
\begin{equation}
\{ g_2,\ldots,g_{\alpha-1}, J'_B, J'_T \},
\label{eq:lagrange-solve}
\end{equation}
and inequalities
\begin{equation}
\{ s_1 g_{1,1} > 0, \ldots, s_\ell g_{1,\ell} > 0, d_B \ne 0, d_T \ne 0 \}
\label{eq:lagrange-solve-ineqs}
\end{equation}
where \(\{ g_{1,1},\ldots,g_{1,\ell} \} \subset \mathbb{Z}[x_1]\) are polynomials from \({\cal A}_1\) and \(s_1,\ldots,s_\ell \in \{-1,1\}\) such that \[
x \in X' \leftrightarrow s_1 g_{1,1}(x) > 0 \land \ldots \land s_\ell g_{1,\ell}(x) > 0.
\]
We can easily find pairs \((s_j, g_{1,j}) \in \{-1,1\} \times {\cal A}_1\) by considering the sign of the sample point \(c\) of \(X'\) on each polynomial \(g_{1,j} \in {\cal A}_1\).

\begin{itemize}
\tightlist
\item
  If \(g_{1,j} > 0\), then \(s_j = 1\).
\item
  If \(g_{1.j}(c) < 0\), then \(s_j = -1\).
\item
  The final case, \(g_{1,j}(c) = 0\), is impossible since an irreducible univariate polynomial cannot be zero over an interval.
  We want to find \(x_1\)-coordinates of the roots of polynomials from Equation \eqref{eq:lagrange-solve} subject to the constraints from Equation \eqref{eq:lagrange-solve-ineqs}.
\end{itemize}

CAD can, of course, be used to do this, since we are really solving the quantifier elimination problem
\[
\exists x_2,\ldots,x_{\alpha - 1},x_\alpha P(x_1,\ldots,x_\alpha)
\] where
\begin{align}
P(x_1,\ldots,x_\alpha) = & s_1 g_{1,1}(x_1) > 0 \land \ldots \land s_\ell g_{1,\ell}(x_1) > 0
\label{eq:lagrange-solve-qe-ineqs} \\
\land & g_2(x_1,x_2) = 0 \land \ldots \land g_{\alpha - 1}(x_1,\ldots,x_{\alpha - 1} = 0
\label{eq:lagrange-solve-qe-constraints} \\
\land & d_B(x_1,\ldots,x_\alpha) \ne 0 land d_T(x_1,\ldots,x_\alpha) \ne 0
\label{eq:lagrange-solve-qe-denominators} \\
\land & ( J'_B(x_1,\ldots,x_{\alpha - 1} = 0 \lor J'_T(x_1,\ldots,x_{\alpha - 1}) = 0 ).
\label{eq:lagrange-solve-qe-jacobis} \\
\end{align}
Computing the projection onto \(\mathbb{R}^1\) of polynomials \(\{g_2,\ldots,g_{\alpha - 1} J'_B, J'_T \}\) from Equations \eqref{eq:lagrange-solve-qe-constraints} and \eqref{eq:lagrange-solve-qe-jacobis}, a system
\[
\cal{F} := \{ f_1=0 ,\ldots,f_r=0 \} \subset \mathbb{Z}[x_1]
\]
is obtained, whose real roots include the refinement points \((c_1,\ldots,c_t)\).
Let \({\cal E} \subset \mathbb{Z}[x_1]\) be the set of polynomials obtained by computing the projection onto \(\mathbb{R}^1\) of \(\{ d_B, d_T \}\) (from Equation \eqref{eq:lagrange-solve-qe-denominators}) and
\[{\cal G} := \{ s_1 g_{1,1}, \ldots, s_\ell g_{1,\ell} \}
\]
from Equation \eqref{eq:lagrange-solve-qe-ineqs}.
\((c_1,\ldots,c_t\) can be found by computing the real roots of \(\cal F\) subject to the inequalities \(\cal G\), then discarding those such that a polynomial in \(\cal E\) is zero.

\begin{quote}
In the implementation \texttt{IPFSFB} is used, to compute a ``finest square-free basis'' of polynomials in \(\cal F\).

\begin{itemize}
\tightlist
\item
  this was just copying from Brown's \texttt{CONSTRUCT} function. it returns a list of real roots in the form \([(M,J),...]\) where \(M\) is the minimal polynomial and \(J\) the isolating interval. It also computes multiplicities, which we don't need.
\item
  in fact, why do we even need a squarefree basis at all. should find out which is the most efficient algorithm from saclib, of squarefree basis or the real root finding algorithms. maybe do some discussion on this.
\end{itemize}
\end{quote}

It is clear that \((c_1,\ldots,c_t)\) lie in an open interval \(X = (a,b) \subset \mathbb{R}\cup \{ -\infty, \infty \}\). Thus, rather than using strict inequalities from Equation \eqref{eq:lagrange-solve-qe-ineqs}, we could find the roots of \(\cal F\) in the interval \((a,b)\).

Each real root will be represented by a pair
\[
c_i := (m_1,J_1)
\]
where \(c_i\) is the unique root of the polynomial \(m_i \in \mathbb{Z}[x_1]\) in the (left-open right-closed) isolating interval \(J_i\).
Note that \(\cal B\) contains only algebraic numbers and roots will appear in ascending order.

\hypertarget{sec:sub-cad}{%
\subsection{Working with sub-decompositions above a 0-cell}\label{sec:sub-cad}}

Note that we are working in a sub-decomposition \(\cal D\) of \(\mathbb{R}^{k+n}\) above a \(0\)-cell \(\mathbf{c}\) of \(\mathbb{R}^k\) (\(k \ge 0\)). Therefore the polynomials appearing in Equation \eqref{eq:variety-v} are actually in \(\mathbb{Z}[y_1,\ldots,y_k][x_1,\ldots,x_n]\).
From a polynomial \(f \in \mathbb{Z}[y_1,\ldots,y_k][x_1,\ldots,x_n]\), a polynomial \(g := f(\mathbf{c}) \in \mathbb{A}[x_1,\ldots,x_n]\) can be obtained by evaluating \(f\) at \(\mathbf{c}\). Evaluated polynomials \(g\) define the sub-cad of \(\mathbb{R}^n\) above \(\mathbf{c}\) because \(\mathbf{c}\) is a \(0\)-cell.

Note that, since \(\mathbf{c}\) is an algebraic number, \(g\) has algebraic coefficients. Since roots of \(g\) are algebraic numbers, there exists a polynomial \(h \in \mathbb{Z}[x_1,\ldots,x_n]\) such that, \(g(\mathbf{x}) = 0\) if and only if \(h(\mathbf{x}) = 0\) for all \(\mathbf{x} \in \mathbb{R}^n\). A method for obtaining the polynomial \(h\) with integer coefficients is now described.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \(f\) is independent of all \(y_1,\ldots,y_k\), there is nothing to do, just set \(h := f\). Otherwise, \(f\) depends on at least one of \(y_1,\ldots,y_k\).
\item
  If \(\mathbf{c}\) is rational, then \(g = f(\mathbf{c})\) has coefficients in \(\mathbb{Q}\). There exists a non-zero \(a \in \mathbb{Z}\) such that \(h := a g\) has integer coefficients and the same roots as \(g\).
\item
  Otherwise, \(\mathbf{c}\) is not rational. Then \(f(\mathbf{c})\) has coefficients in \(\mathbb{A}\). There exists an algorithm, which takes \(g\) as input and returns a polynoial \(h \in \mathbb{Z}[x_1,\ldots,x_n]\) such that \(g(\mathbf{x}) = 0\) if and only if \(h(\mathbf{x}) = 0\) for all \(\mathbf{x} \in \mathbb{R}^n\).
\end{enumerate}

\begin{remark}
Let \(f \in \mathbb{Q}[x_1,\ldots,x_n]\) be a polynomial such that
\[
f(x_1,\ldots,x_n) = \dfrac{a_1}{b_1} m_1 + \cdots + \dfrac{a_k}{b_k} m_k
\]
where \(m_i = x_1^{d_{i,1}} \cdots x_n^{d_{i,n}}\) for \(1 \le i \le k\) is a monomial in \(x_1,\ldots,x_n\).

Let \(M := \operatorname{lcm}(b_1, \ldots, b_k)\) be the least common multiple of denominators and construct
\[
g(x_1,\ldots,x_n) = M f(x_1,\ldots,x_n) = \dfrac{M a_1}{b_1} m_1 + \cdots + \dfrac{M a_k}{b_k} m_k.
\]
Each coefficient in \(g\) will be an integer number since \(M\) is divisible by all \(b_1,\ldots,b_k\) and polynomials \(f\) and \(g\) have the same roots.
\end{remark}

\begin{definition}
\protect\hypertarget{def:norm}{}\label{def:norm}Let \(K\) be a field and \(L\) a finite (algebraic) extension of \(K\).
The field \(L\) can be thought of as a finite dimensional vector space over \(K\).

Consider \(f\) and \(m\) as polynomials in \(\mathbb{Q}[x_1,\ldots,x_n,x_\alpha]\). compute the resultant of \(f\) and \(m\) to obtain a polynomial in \(\mathbb{Q}[x_1,\ldots,x_n]\). somehow this gives us the norm of an algebraic polynomial.
\end{definition}

\begin{remark}
Let \(f \in \mathbb{A}[x_1,\ldots,x_n]\) be a polynomial such that
\[
f(x_1,\ldots,x_n) = a_1 m_1 + \cdots + a_k m_k
\]
where \(m_i = x_1^{d_{i,1}} \cdots x_n^{d_{i,n}}\) is a monomial in \(x_1,\ldots,x_n\) and \(a_i\) is an element of \(\mathbb{Q}(\alpha)\) for \(1 \le i \le k\).

Let \(m \in \mathbb{Z}[\alpha]\) be the minimal polynomial for \(\mathbb{Q}(\alpha)\). \(f\) can be written as a polynomial in \(\mathbb{Q}[x_1,\ldots,x_n,\alpha]\) and \(m\) can be viewed as a polynomial in \(\mathbb{Z}[x_1,\ldots,x_n,\alpha]\) which is independent of all \(x_1,\ldots,x_n\). Compute
\[
g := \operatorname{Res}_\alpha (f,m)
\]
to obtain a polynomial in \(\mathbb{Q}[x_1,\ldots,x_n]\). The property that \(f(\mathbf{x}) = 0\) if and only if \(g(\mathbf{x}) = 0\) follows from the following property of resultants:

\begin{quote}
Let \(I = \langle f, m \rangle\) be the ideal generated by polynomials \(f, m \in K[x_1,\ldots,x_n][\alpha]\), where \(K\) is an algebraically closed field. If at least one of \(f\) and \(m\) is monic, then
\[
\operatorname{Res}_\alpha (f,m) \in I \cap R.
\]
\end{quote}

It follows that \(\mathbf{x} \in K^n\) is a common zero of the elements of \(I \cap R\) if and only if it is a zero of \(\operatorname{Res}_\alpha(f,m)\).

\textbf{TODO} this property came from the wiki page on resultants. does it need proving?
\end{remark}

\hypertarget{two-dimensional-monotone-sections}{%
\section{Two-dimensional monotone sections}\label{two-dimensional-monotone-sections}}

Recall \(X := {\operatorname{proj}_{{\operatorname{span} \{x_1,x_\alpha\}}}}(C)\) and let \((c_1,\ldots,c_r)\) be the refinement points computed in the previous section such that
\[
Y := \{ c_i < x_1 < c_{x+1}\} \cap X,
\]
for some \(1 \le i \le r\), is a two-dimensional semi-monotone set.
Let us return to \citep[Theorem 3.18]{bgv15} to further refine \(Y\) such that every two-dimensional section cell is a monotone cell.

Let \(f_j : Y \to {\operatorname{span} \{x_j\}}\) be a component of the quasi-affine map \(\mathbf{f} : X \to \mathbb{R}\). Since \(\mathbf{f}\) is quasi-affine, each component of \(\mathbf{f}\) is quasi-affine and the restriction of component \(f_j\) to \(Y\) is quasi-affine since \(Y \subset X\).
Hence, \(f_j\) is either strictly increasing in, strictly decreasing in, or independent of each variable \(x_1, x_\alpha\).
In addition, the restriction \(f\vert_{Y \cap \{x_\alpha = c\}}\) for any \(c \in \mathbb{R}\) is either strictly increasing in, strictly decreasing in, or independent of \(x_\alpha\).
We will compute a refinement of \(Y\) such that \(f_j\vert_Y\) is monotone, each \(B \subset Y\) in the refinement.
As before, only refinements of the kind
\[
\{ x_1 < c \}, \{ x_1 = c \}, \{ x_1 > c \},
\]
\(c \in \mathbb{R}\), which preserves both the cylindrical structure and existing monotone cells will be performed.

\hypertarget{case-1-2-le-j-le-alpha---1}{%
\subsection{\texorpdfstring{Case 1: \(2 \le j \le \alpha - 1\)}{Case 1: 2 \textbackslash le j \textbackslash le \textbackslash alpha - 1}}\label{case-1-2-le-j-le-alpha---1}}

\begin{lemma}
\protect\hypertarget{lem:one-dim-qa-is-monotone}{}\label{lem:one-dim-qa-is-monotone}Let \(Y \subset \mathbb{R}^n\) be the graph of a quasi-affine map
\[
\mathbf{f} : (a,b) \to \mathbb{R}^{n-1}
\]
such that \((a,b) \subset \mathbb{R}\). Then \(Y\) is a monotone cell.
\end{lemma}

\begin{proof}
It is clear that
\[
\dim(Y) = 1.
\]
Hence, we need to show that \(Y\) is either strictly increasing in, strictly decreasing in, or independent of \(x_i\) for all \(1\le i \le n\).
Consider the projection map \({\operatorname{proj}_{{\operatorname{span} \{x_i\}}}} : \mathbb{R}^n \to {\operatorname{span} \{x_i\}}\).

Suppose that the restriction
\[
{\operatorname{proj}_{{\operatorname{span} \{x_i\}}}}\vert_Y
\]
is injective, Then it is clear that the image \({\operatorname{proj}_{{\operatorname{span} \{x_i\}}}}(Y)\) is \(1\)-dimensional, since \(Y\) itself is \(1\)-dimensional. On the other hand, suppose that the image
\[
{\operatorname{proj}_{{\operatorname{span} \{x_i\}}}}(Y)
\]
is one-dimensional, then it is clear that \({\operatorname{proj}_{{\operatorname{span} \{x_i\}}}}\vert_Y\) is injective if \(\mathbf{f}\) is either strictly increasing in, strictly decreasing in, or independent of \(x_i\). It follows that \(\mathbf{f}\) is a monotone map, therefore its graph, \(Y\), is a monotone cell.
\end{proof}

Suppose that \(2 \le j \le \alpha - 1\).
Since
\[
{\operatorname{proj}_{{\operatorname{span} \{x_j,x_\alpha\}}}}(C)
\]
is one-dimensional, connected and the graph of a quasi-affine map, it follows from Lemma \ref{lem:one-dim-qa-is-monotone} that \({\operatorname{proj}_{{\operatorname{span} \{x_j,x_\alpha\}}}}(C)\) is a monotone cell and \(f_j\vert_Y\) is already a monotone function. No refinement is needed.

\hypertarget{case-2-alpha-1-le-j-le-n}{%
\subsection{\texorpdfstring{Case 2: \(\alpha + 1 \le j \le n\)}{Case 2: \textbackslash alpha + 1 \textbackslash le j \textbackslash le n}}\label{case-2-alpha-1-le-j-le-n}}

Now suppose that \(\alpha + 1 \le j \le n\).
By \citep[Theorem 3]{bgv13}, if functions \[\inf_{x_\alpha} f_j : {\operatorname{span} \{x_1\}} \to {\operatorname{span} \{x_j\}} \text{ and } \sup_{x_\alpha} f_j : {\operatorname{span} \{x_1\}} \to {\operatorname{span} \{x_j\}}\] are monotone, then \(f_j\) itself is monotone.
Hence, we need to find refinement points
\[
\{ b_1,\ldots,b_r \} \subset (c_i,c_{i+1})
\]
such that, for each \(1\le \ell < r\), the restrictions of both \(\inf_{x_\alpha} f_j\) and \(\sup_{x_\alpha} f_j\) to \(B := \{ b_\ell < x_1 < b_{\ell + 1} \}\) are monotone.

Consider \[
Z := {\operatorname{proj}_{{\operatorname{span} \{x_1,x_j\}}}}(C).
\]
If \(\dim(Z) < 2\), then it is clear that \(\dim(Z) = 1\), because
\[
Y' := {\operatorname{proj}_{\mathbb{R}^{1}}}(C)
\] is one-dimensional.
It follows that \(\inf_{x_\alpha} f_j\) and \(\sup_{x_\alpha} f_j\) coincide. Since \(Z\) is one-dimensional, connected and the graph of a quasi-affine map, Lemma \ref{lem:one-dim-qa-is-monotone} implies that \(f_j\) is already monotone and no refinement is needed.

On the other hand, if \(\dim(Z) = 2\), since \(\mathbf{f}\) is quasi-affine, \({\operatorname{proj}_{{\operatorname{span} \{x_1,x_j\}}}}\vert_C\) is injective.
Let \(Z_T\) be the graph of \(\sup_{x_\alpha} f_j\). Despite the notation, \(Z_T\) is not necesarily the top of \(Z\). In particular, \(Z_T\) may have non-empty intersection with \(Z\).
Since semialgebraic sets are closed under intersection and projection, there exist points
\[\{b_1,\ldots,b_k\} \subset (c_i,c_{i+1})
\] such that for all \(1 \le i < k\) \[
Z^{b_i,b_{i+1}}_T := Z_T \cap \{ b_i < x_1 < b_{i+1} \}
\]
is either a subset of \(Z\) or is disjoint from \(Z\).
First suppose that \(Z^{b_i,b_{i+1}}_T \subset Z\) for some \(1 \le i < k\).
In this case, \(Z\) is not bounded from above, so \(\sup_{x_\alpha} f_j \vert_{\{ b_i < x_1 < b_{i+1} \}}\) is independent of \(x_1\) and is therefore already monotone.
On the other hand, suppose that \(Z^{b_i,b_{i+1}}_T \cap Z = \emptyset\).
In this case, \(Z^{b_i,b_{i+1}}_T \subset {\operatorname{proj}_{{\operatorname{span} \{x_1,x_j\}}}}(C_T)\).
If there exists a point \(b \in (b_i,b_{i+1})\) such that \({\operatorname{proj}_{{\operatorname{span} \{x_1,x_j\}}}}(C_T) \cap \{x_1 = b\} \cap Z \neq \emptyset\),
then it is clear that \(C_T \cap \{ b_i < x_1 < b_{i+1} \}\) is not the graph of a continuous function.
I.e., \({\operatorname{proj}_{{\operatorname{span} \{x_1,x_\alpha,x_j\}}}}(C_T)\) contains an open interval above \((b,y) \in Y_T\).
Since \(\dim(C) = 2\), all blow-up points \((b,y)\) have dimension \(0\) and therefore there is a finite number of them. Repeating this process for \(\alpha + 1 \le j \le n\), it follows that there exist points
\[\{ b_{i,1}, \ldots, b_{i,k_i} \} \subset (b_i, b_{i+1})
\] such that, for all \(1 \le j < k_i\), \(C_T \cap \{ b_{i,j} < x_1 < b_{i,j+1} \}\) is the grah of a continuous map.
In particular, \(C_T \cap \{ b_{i,j} < x_i < b_{i,j+1} \}\) is the graph of \(\mathbf{f}\vert_{Y_T \cap \{ b_{i,j} < x_1 < b_{i,j+1} \}}\).

Apply the same argument to \(\inf_{x_\alpha} f_j\) (for \(C_B\)) so that, \(C_T\) and \(C_B\), if non-empty, are split into one-dimensional countinuous curves which are graphs of continuous functions, and the intervals above \(0\)-dimensional blow-up points. Once this property has been satisfied, we are left with a similar construction of optimisation with constraints as in Scetion \ref{sec:lagrange-refinement}.

\hypertarget{critical-points-of-the-top-and-bottom-of-c}{%
\subsection{\texorpdfstring{Critical points of the top and bottom of \(C\)}{Critical points of the top and bottom of C}}\label{critical-points-of-the-top-and-bottom-of-c}}

We now discuss how to perform this refinement on the CAD structure. Let us assume that \(C_T\ne \emptyset\). We must construct subsets \(W \subset Y\) such that \(f_j\vert_{W_T}\) is a smooth, continuous functions.
Let
\[
{\cal A} = ({\cal A}_1, \ldots, {\cal A}_n)
\]
be the projection factor set as defined in Equation \eqref{eq:proj-fac-set} and
\[
C' := {\operatorname{proj}_{\mathbb{R}^{j-1}}}(C), C^j := {\operatorname{proj}_{\mathbb{R}^{j}}}(C),
\]
Begin with \(j := \alpha+1\) so that \(C'\) is a cylindrical sector cell and there exists an algebraic variety \(V\) containing polynomials \(g_2,\ldots,g_{j-1}\) with each \(g_i \in {\cal A}_i, 2 \le i \le j-1\), defined in Equation \eqref{eq:c-alpha-top}, such that \(C'_T\subset V\).
By definition \[
C^j_T = {\operatorname{cl} \left( C^j \right)} \cap (C'_T \times \mathbb{R})
\] and there exists a polynomial \(g_j \in {\cal A}_j\) such that \(g_j(\mathbf{x}) = 0\) for all \(\mathbf{x} \in C^j_T\). Since \(C^j_T\) is either empty or the graph of a continuous function everywhere except, possibly, for a finite number of blow-up points, we need to find \(x_1\)-coordinates of points in \(C'_T\) such that \(g_j\) vanishes over an open interval.
Since \(C^j_T\) is one-dimensional, one way to achieve this is by computing a smooth stratification of \(C^j_T\). If the projection of a one-dimensional stratum onto \(x_1\) is a \(0\)-dimensional point \(b \in \mathbb{R}\), then \(b\) is the \(x_1\)-coordinate of a blow-up point.

Alternatively, since the refinement points form a \(0\)-dimensional semialgebraic subset of \(\mathbb{R}\), this set can be represented as a first-order Boolean formula
\[
\exists x_2,\ldots,x_{j-1} \exists_\infty x_j ((x_1,\ldots,x_{j-1}) \in C'_T, g_j(x_1,\ldots,g_j) = 0)
\]
where \(\exists_\infty x\) is a special quantifier defined in \texttt{QEPCAD} meaning ``there exist infinitely many values of \(x\)''.
Using \(\exists_\infty\), som of the costly computations with algebraic numbers can be avoided, thereby improving efficiency in practice. \textbf{TODO refer to qepcad user documentation.}
Theoretically speaking, \citep[Algorithm 14.21]{bpr2006} provides a singly exponential upper bound for quantifier elimination. \textbf{TODO what is the bound?}

Eliminating the \(j-1\) quantifiers, we obtain the desired points \((b_{i,1},\ldots,b_{i,k_i})\), where each \(b_{i,j}\) is the \(x_1\)-coordinate of a blow-up point of \(g_j\).
Now we can assume that \(C^j_T\cap \{ b_{i,j} < x_1 < b_{i,j+1}\}\) is the graph of a continuous function. More precisely, the implicit function \(g_j\) can be considered as a function from \(C'_T \cap \{ b_{i,j} < x_1 < b_{i,j+1}\}\) to \(\mathbb{R}\). We have a very similar construction as in Section \ref{sec:lagrange-refinement}.
That is, polynomials \(g_2,\ldots,g_{j-1}\) will provide the constraints in the first \(j-2\) columns of the matrix in Equation \eqref{eq:jacobi-det}, while \(\partial h / \partial x_i, 1 \le i \le j - 1\) in the last column should be replaced with \(\partial g_j / \partial x_i\)
Denote this polynomial by \(J_T\), and repeat with \(C^j_B\) if appropriate. Inequalities \(s_1 g_{1,1} > 0, \ldots, s_1 g_{1,\ell} > 0\) (from Equation \eqref{eq:lagrange-solve-qe-ineqs}), \(d_T \ne 0\) and \(d_B\) (from Equation \eqref{eq:lagrange-solve-qe-denominators}) are obtained and solved for \(x_1\) in a very similar way as in Section \ref{sec:lagrange-refinement}. We obtain a set of refinement points
\[
\{ b_{j,1}, \ldots, b_{j,r_j} \} \subset (c_i,c_{i+1})
\]
such that each of \(C^j_T\) and \(C^j_B\) is either empty or the graph of a continuous, monotone function.

The process is completed by induction in \(j\). Suppose that the refinement has been performed for \(\alpha + 1 \le j\). If \(j = n\) we are done, and \(C\) is now monotone. Otherwise, let \(j := j+1\). By the induction hypothesis, we know that \(C^{j-1}_T \cap \{b_{j-1,i} < x_1 < b_{j-1,i+1}\}, 1 \le i < r_{j-1}\) is either empty or the graph of a continuous function.
If \(C^{j-1}_T = \emptyset\), there is nothing to do and the process will terminate, since \(C^j_T\) is empty.
Otherwise, take \(g_{j-1} \in {\cal A}_{j-1}\) used in the induction hypothesis and find \(g_j \in {\cal A}_j\) such that \(g_j(\mathbf{x}) = 0\) for all \(\mathbf{x} in C^j_T\).
Perform the same computation described abov, to refine \(C^j_T\) such that one-dimensional components are graphs of continuous, monotone functions and repeat with \(C^j_B\).
As before, a set of refinement poits
\[
b_{j,1}, \ldots, b_{j,r_j}
\]
is obtained

When the process terminates, the union of sets of refinement points \[
\{b_{\alpha + 1,1}, \ldots, b_{\alpha + 1,r_{\alpha + 1}}\}, \ldots, \{b_{n,1}, \ldots, b_{n,r_n}\}
\]
forms the refinement of \(C\) into two- and one-dimensional monotone cells.

\hypertarget{implementation-details}{%
\section{Implementation Details}\label{implementation-details}}

We now discuss implementation details of this step of the algorithm. First psuedocode is presented.

\hypertarget{sec:monotone-algorithm}{%
\subsection{Algorithm}\label{sec:monotone-algorithm}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Input:}
\[({\cal E}, {\cal A})\]

\begin{itemize}
\item
  \(\cal E\): a cylindrical algebraic decomposition of \(\mathbb{R}^{k+n}\), such that each cell is the graph of a quasi-affine map. Each cell \(C\) of \(\cal E\) has a truth-value (\emph{true} or \emph{false} attached.
\item
  \({\cal A} = {\cal A}_1,\ldots,{\cal A}_{k+n}\) is the family of projection polynomials where each \({\cal A}_i \subset \mathbb{Z}[x_1,\ldots,x_i]\).
\end{itemize}

\textbf{Output:}
\[
{\cal R} := \{ {\cal R}_{\mathbf{b}} = \{ c_1,\ldots,c_t \} \subset \mathbb{A}\mid \mathbf{b} \in \mathbb{R}^{k-1} \text{ is a } (0,\ldots,0) \text{-cell in the decomposition induced by } {\cal E} \text{ on } \mathbb{R}^k \}
\]
such that, for each \({\cal R}_\mathbf{b}\), intersecting the sub-cad \(\cal D\) above \(\mathbf{b}\) with straight lines and half-planes of the kind \(\{x_1 < c_i \}, \{x_1 = c_i \}, \{x_1 > c_i\}, 1 \le i \le t\) results in a refinement of \(\cal D\) such that each true cell of \(\cal D\) with dimension at most \(2\) is monotone.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

First, define a subroutine
\[{\rm sub}_{\mathbf{y}} (g) \mid g \in \mathbb{Z}[y_1,\ldots,y_m,x_1,\ldots,x_n], \mathbf{y} \in \mathbb{A}^m, n > 0,\]
which computes \(h := g(\mathbf{y}) \in \mathbb{A}[x_{1},\ldots,x_m]\) and returns the normalised polynomial of \(h\), in \(\mathbb{Z}[x_{m+1},\ldots,x_n]\) (see Section \ref{sec:sub-cad}).

It will be convenient to overload this operator and write \({\rm sub}_{\mathbf{y}} (L)\), where \(L\) is a set (or list) of polynomials to mean \(\{ {\rm sub}_{\mathbf{y}} (g) \mid g \in L \}\).

Now define a structure to store refinement polynomials
\[
{\cal F} := \{ {\cal F}_{\mathbf{b}} := \emptyset \mid \mathbf{b} \in \mathbb{R}^{k-1}, k > 0 \text{ is a } (0,\ldots,0) \text{-cell in the decomposition induced by } {\cal E} \text{ on } \mathbb{R}^{k-1} \}
\]
and a similar structure to store refinement points
\[
{\cal R} := \{ {\cal R}_{\mathbf{b}} := \emptyset \mid \mathbf{b} \in \mathbb{R}^{k-1}, k > 0 \text{ is a } (0,\ldots,0) \text{-cell in the decomposition induced by } {\cal E} \text{ on } \mathbb{R}^{k-1} \}
\]
\emph{(Note: for each \((0,\ldots,0)\)-cell \(\mathbf{b}\), \({\cal F}_\mathbf{b}\) is a set of univariate polynomials, \({\cal R}_{\mathbf{b}}\) is the set of roots of polynomials \({\cal F}_\mathbf{b}\). When \(k=1\), then the CAD of \(\mathbb{R}^0\) consisting of the unique point of \(\mathbb{R}^0\) is used -- practically speaking, we work directly with the CAD \(\cal E\).)}

Let \(\mathbf{b}\) be a \((0,\ldots,0)\)-cell of the decomposition induced by \(\cal E\) on \(\mathbb{R}^{k-1}, k > 0\). Let \(\cal D\) be the sub-decomposition of \(\mathbb{R}^n\) of \(\cal E\) above \(\mathbf{b}\).

Consider each cell \(C\) of \(\cal D\) with truth value \emph{true}. Let \(C\) have index
\[
(0,\ldots,0,1,i_{k+1},\ldots,i_{k+n})
\]
in \(\cal E\). If \(i_{k+1} + \cdots + i_n > 2\), then \(\dim(C) > 2\) and the algorithm will fail. Otherwise, let \(\alpha\) be the smallest among \(x+1,\ldots,k+n\) such that \(i_{k+1} = \ldots = i_{\alpha - 1} = 0\) and \(i_\alpha = 1\).
Then:

\begin{itemize}
\item
  Let

  \begin{itemize}
  \item
    \(\mathbf{b} := {\operatorname{proj}_{\mathbb{R}^{k-1}}}(C)\),

    \emph{(Note: observe that \(\mathbf{b} \in A^{k-1}\). If \(k = 1\), then \(\mathbf{b}\) is the unique cell, \(\mathbf{0}\), in the CAD of \(\mathbb{R}^0\). In this case, it is clear that \({\rm sub}_\mathbf{0} (g) \equiv g\).)}
  \item
    \(C'' (C''_B, C''_T) \subset \mathbb{A}:= {\operatorname{proj}_{\mathbb{R}^{k}}}(C)\),
  \item
    \({\cal G} := {\rm sub}_{\mathbf{b}} \{ g_i \mid k+1 \le i \le \alpha - 1, g_i \in {\cal A}_i, g_i(\mathbf{x}) = 0 \ \forall \mathbf{x} \in {\operatorname{proj}_{\mathbb{R}^{\alpha-1}}}(C) \}\),
  \item
    \(C' := {\operatorname{proj}_{\mathbb{R}^{\alpha}}}(C)\).
  \end{itemize}
\item
  \(C'_T\) and \(C'_B\) be the top and bottom, respectively, \(C'\).
\end{itemize}

(\emph{Note: If \(C'\) is not bounded from above (resp. below) by a continuous definable function, i.e., there is no section above (resp. below) \(C'\), then let \(C'_T := \emptyset\) (resp \(C'_B\)) and skip any computations involving \(C'_T\) (resp \(C'_B\)).)}

\begin{itemize}
\item
  Let \(j = \alpha\) and do:

  \begin{itemize}
  \item
    **(*)** For \(\delta \in \{B, T\}\), if \(C_\delta\) is not empty, do:

    \begin{itemize}
    \item
      Let \(\rm{sub}_{\mathbf{b}} (g_j) \in \mathbb{Z}[x_{k+1,\ldots,x_j}]\) be such that \(g_\alpha(\mathbf{x}) = 0\) for all \(\mathbf{x} \in C'_\delta\).
    \item
      Compute
      \[
      f_\delta := \det\begin{pmatrix}\dfrac{\partial g_{k+1}}{\partial x_{k}} & \cdots & \dfrac{\partial g_{j-1}}{\partial x_{k}} & \dfrac{\partial g_{j}}{\partial x_{k}}\\
      \vdots &  &  & \vdots\\
      \dfrac{\partial g_{k+1}}{\partial x_{j-1}} & \cdots & \dfrac{\partial g_{j-1}}{\partial x_{j-1}} & \dfrac{\partial g_{j}}{\partial x_{j-1}}
      \end{pmatrix},
      \]
      from Equation \eqref{eq:jacobi-det}, using constraints \(g_{k+1},\ldots,g_{\alpha+1}\), and discarding denominators \(\partial g_\alpha / \partial x_\alpha\) of the total derivatives in the last column.
    \end{itemize}
  \item
    Let \[{\cal H} := \{ g_{k+1},\ldots,g_{j-1}, f_B, f_T \}\]
    be a set of polynomials and compute
    \[
    {\cal F}_{\mathbf{b}} := {\cal F}_{\mathbf{b}} \cup {\operatorname{proj}_{\mathbb{R}^{1}}}({\cal H}) \subset \mathbb{Z}[x_k].
    \]
  \item
    If \(j < n\), then

    \begin{itemize}
    \item
      Add \(g_j\) to \(\cal G\), i.e., let
      \[
      {\cal G} := {\cal G} \cup \{ g_j \}.
      \]
    \item
      Let \(j := j+1\).
    \item
      Let
      \[
      C' := {\operatorname{proj}_{\mathbb{R}^{j}}}(C)
      \]
      \(C'\) is a section cell, and its top and bottom may not be graphs of continuous functions. Use QE to compute
      \[
      ...
      \]
    \end{itemize}
  \end{itemize}
\item
  For each \((0,\ldots,0)\)-cell \(\mathbf{b} \in \mathbb{A}^k\), consider
  \[
  {\cal F}_{\mathbf{b}} \in {\cal F} \in \mathbb{Z}[k],
  \]
  compute
  \[
  {\cal R}_{\mathbf{b}} := (c_1,\ldots,c_t)
  \]
  by isolating the real roots of polynomials in \({\cal F}_{\mathbf{b}}\).
\item
  Return the family \({\cal R}\) of refinement points.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{TODO}
- what if \(f_j\) does not exist
- what if \(\alpha = k+1\)

\hypertarget{sec:compute-refinement}{%
\section{Computing the refinements}\label{sec:compute-refinement}}

We now describe how to refine the CAD \(\cal D\) to be compatible with the refinement points in \(\cal R\).

For \(0 \le k \le n\), consider each refinemen point \(\mathbf{c} = (c_1,\ldots,c_{k-1}, c_k) \in {\cal R}_k\). It is important to note that refinement points appear in ascending order.
Let \({\cal D}'\) be the sub-cad of \(\mathbb{R}^{n-k}\) above \((c_1,\ldots,c_k)\), which is a \((0,\ldots,0)\)-cell of the CAD induced by \(\cal D\) on \(\mathbb{R}^k\) and let \({\cal D}''\) be the CAD induced by \({\cal D}'\) on \(\mathbb{R}^{k+1}\). We want to refine \({\cal D}''\) such that \(\mathbf{c}\) is a new \((0)\)-cell.
We need only to consider coordinate \(k+1\) of \(\mathbf{c}\). Denote it by \(c_{k+1}\).
For each \((0)\)-cell \(b_{k+1}\) of \({\cal D}''\), compute \(s := \operatorname{sign}(b_{k+1} - c_{k+1})\). If \(s \le 0\), consider the next \((0)\)-cell in \({\cal D}''\). Otherwise, \(s > 0\) and there is a \((1)\)-cell \(C\) in \({\cal D}''\) such that \(c_{k+1} \in C\). This is the cell we need to refine.
Make two new copies of \(C\), so that we have three identical cells \(C_1,C_2,C_3\). Recall that, to each cell belongs a sample point and possibly some other information. E.g., in QEPCAD, each cell has a set of signs of projection factors, which should remain unchanged, and a positional index which describes where in the CAD the cell can be found. Let \(C_1\) have positional index \((j_1,\ldots,j_k,j_{k+1})\). New cells \(C_2\) and \(C_3\) should have positional indeices \((j_1,\ldots,j_k,j_{k+1} + 1\) and \((j_1,\ldots,j_k,j_{k+1}+2)\) respectively. For each eisting cell with positional index \((l_1,\ldots,l_k,l_{k+1})\) with \(l_k+1 > j_{k+1}\), the index should be updated to \((l_1,\ldots,l_k,l_{k+1} + 2\). We now need to update the sample points. The sample point of the sector cell \(C_2\) should be \(\mathbf{c}\). This might turn out to be the case by chance. In this case, there is nothing to be done with \(C_2\) and the sample points of sector cells \(C_1\) and \(C_3\) are incorrect. Otherwise, \(c_{k+1}\) is either an element of \(C_1\) (sample point of \(C_1\) is already correct) or \(c_{k+1}\) is an element of \(C_3\) (sample point of \(C_3\) is already correct). Let \(C\) be the open interval \((a_1,a_2)\). If the sample point of \(C_1\) needs to be updated, then set it to \((a_1 + c_{k+1}) / 2\) and if the sample point of \(C_3\) needs updating, then set it to \((a_2 + c_{k+1}) / 2\). Observe that, if we have updated the sample point of a cell \(C\), then the sample points of all cells in the sub-CAD above \(C\) are now incorrect. Since polynomials are delineable over the original cell, then they will be delineable over the smaller cells in the refinement, so we simply need to run the sample point computing part of the lifting phase recursively on the stack above \(C\). This involves evaluating each level \(k+1\) projection factor \(f\) ot the new sample point \(\mathbf{b}\) and finding the roots of the (possibly algebraic) univariate polynomial \(f(\mathbf{b},x_n)\).

Repeating this process with each refinement point in \(\mathbf{R}_k\), we obtain the refinement described in \citep[Lemma 3.11]{bgv15}.

\hypertarget{frontier-condition}{%
\chapter{Frontier Condition}\label{frontier-condition}}

Now suppose we have a CAD \(\cal D'\) monotone with respect to \(V_1,\ldots,V_k\). Our final step, according to \citep[Theorem 3.20]{bgv15} is to refine the frontier \(\partial C\) of each \(2\)-dimensional cell \(C \subset V\) so that \(\partial C\) is a union of cells of \(\cal D'\).

For each cell \(C \subset V\), compute \(\partial C\). Since \(C\) is monotone, we can assume that \(\partial C\) is homeomorphic to a circle. Construct a partition \(\cal U\) of \(\partial C\) into monotone one-dimensional curves and points, such that \(\cal U\) is compatible with all one-dimensional cells of \(\cal D'\).
Let \(\mathbf{c} = (c_1,\ldots,c_n)\) be one of the one-dimensional components of \(\cal U\). If \(c_1\) is not a \(0\)-dimensional cell of the decomposition induced by \(\cal D'\) on \(\mathbb{R}^1\), then perform a refinement of the kind \(x_1 < c_1, x_1 = c_1, x_1 > c_1\). Recall that these refinements, according to \citep[Lemma 3,11]{bgv15}, preserve the cylindrical structure and monotone cells. Otherwise, \(c_1\) is a \(0\)-cell and we apply the same argument to the sub-CAD of \(\cal D'\) above \(c_1\).

Now let \(T \in {\cal U}\) be one of the one-dimensional components. If \(T\) is not an existing 1-dimensional cell of \(\cal D'\), then it is a subset of a 2-dimensional cell, \(Z\), of \(\cal D'\). In fact, it divides \(Z\) into two cells \(Z \setminus T\), both of which, according to \citep[Theorem 11]{bgv13}, are 2-dimensional monotone cylindrical cells. Hence, replacing \(Z\) by \(T\) and the two components of \(Z \setminus T\) makes \(Z\) compatible with \(\partial C\) and ensures that \(Z\) is refined into monotone cells.

Repeating this process with each \(0\)- and \(1\)-dimensional component of \(\cal U\), we obtain a refinement of \(\cal D'\) compatible with \(\partial C\).
This completes the construction of a monotone CAD due to \citet{bgv15}.

However, a difficulty arises when we try to translate this construction into an algorithm. We need to compute \(\partial C\) for each \(2\)-dimensional cell \(C \subset V\).

\begin{lemma}
Let \(S \subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula \(F\)
containing \(s\) different polynomials in \(\mathbb{R}[x_1, \ldots ,x_n]\) having maximum degree \(d\).
There is an algorithm, taking \(F\) as input, which represents the semialgebraic set \({\operatorname{fr} \left(  S  \right)}\) by a quantifier-free Boolean formula \(F'\) with complexity
\[(sd)^{O(n^2)}.
\]
This is also an upper bound on the number of polynomials in \(F'\) and their degrees.
\end{lemma}

\begin{proof}
Observe that \({\operatorname{fr} \left(  S  \right)}\) can be represented by a first-order Boolean formula
\[
{\operatorname{fr} \left(  S  \right)} = \left\{ \mathbf{x} \in (\mathbb{R}^n \setminus S) \mid \forall \varepsilon >0\> \exists \mathbf{y} \in S\> (\Vert \mathbf{x} - \mathbf{y} \Vert < \varepsilon ) \right\}.
\]
Using singly-exponential quantifier elimination algorithm \citep[ Algorithm 14.21]{bpr2006}, we represent \({\operatorname{fr} \left(  S  \right)}\)
as a quantifier-free Boolean formula \(F'\) with the bounds required in the lemma.
\end{proof}

We see that the ``obvious'' way of computing the frontier involves solving a quantifier elimination problem with two quantifier alternations. Even using an efficient QE algorithm, this still has complexity singly exponential in the number of variables. If possible, we would like to avoid calling this singly exponential subroutine on each cell.

\hypertarget{sec:lazard-3}{%
\section{Lazard's method for dimension not greater than 3}\label{sec:lazard-3}}

\citet{lazard10} presents an algorithm for constructing an \(\mathbf{F}\)-invariant cylindrical algebraic decomposition of \(\mathbb{R}^n, n\le 3\) such that every cell is a topologically regular set and the frontier condition is satisfied.

According to \citep[TODO]{lazard10}, in dimension \(\le 2\), there is nothing to do. Furthermore, a cell \(C\) satisfies the frontier condition if no cells bordering it are bad.

\begin{lemma}
\protect\hypertarget{lem:no-blow-up}{}\label{lem:no-blow-up}\citep[Theorem 4.4]{lazard10}
Let \(\mathcal{D}\) be a sign-invarient decomposition of \(\mathbb{R}^n\) and \(C\) be a cell of \(\mathcal{D}\) with \(C' := \operatorname{proj}_{\mathbb{R}^{n-1}}(C)\). If the decomposition induced by \(\cal D\) on \(\mathbb{R}^{n-1}\) is strong and none of \(C'\) and any cell adjacent to it is bad, \(C\) is well-bordered, and \({\operatorname{fr} \left( C \right)}\) is a union of some cells of \(\mathcal{D}\).
\end{lemma}

\begin{proof}
This result follows from the following fact about roots of multivariate polynomials: given a polynomial \(f \in \mathbb{Q}[x_1,\ldots,x_{n-1}][x_n]\), i.e., considered as a univariate polynomial with polynomial coefficients, its complex roots depend continuously on the parameters in the region of the parameter space where the polynomial does not vanish identically. In fact, this is only true in the projective closure of \(\mathbb{C}\) as some roots may pass through the point at infinity if the leading coefficient is zero.

First suppose that \(C\) is a section cell. I.e., it is a root of some polynomial \(f\) and \(\partial C\) is defined as the limit of this root over the boundary of \(C'\). Thus \({\operatorname{proj}_{\mathbb{R}^{n-1}}}\) is a continuous, injective map from \(\partial C\) to \(\partial C'\). This follows from the assumption that the decomposition induced by \(\cal D\) on \(\mathbb{R}^{n-1}\) is strong and that if the root defining the section \(C\) is infinite over some cell \(C'' \subset C'\), then it is also infinite over \(\partial C''\).

Now suppose that \(C\) is a sector cell having section cells (if they exist) \(C_B\) and \(C_T\) as the bottom and top of \(C\) respectively. Let us describe the boundary of \(C\). We will only consider the case where \(C \cap \{ \mathbf{x} \times \mathbb{R}\}\) is an open interval bounded from below by a point in \(C_B\) and above by a point in \(C_T\).

Let \(\dim(C) = d + 1\). \(\partial C\) consists of

\begin{itemize}
\tightlist
\item
  \(C_B\) and \(C_T\), both having dimension \(d\),
\item
  the cells in \(\partial C_B\) and \(\partial C_T\), which have dimension \(< d\) and are contained in \(\partial C' \times \mathbb{R}\),
\item
  the intervals (which may be empty) bounded by the points in \(\partial C_B\) and \(\partial C_T\), contained in \(C' \times \mathbb{R}\). Since \(C_B\) and \(C_T\) are section cells, they are roots of polynomials \(f\) and \(g\) and, if finite, the points in \(\partial C_B\) and \(\partial C_T\) are also roots of \(f\) and \(g\) (respectively). Therefore, these intervals are contianed in some cells of \(\cal D\). More precisely, the cells with dimension \(d\) contained in \(\partial C' \times \mathbb{R}\) are exactly those lying over a cell \(C'' \subset \partial C'\) with dimension \(d-1\).
\end{itemize}

A cell of dimension \(< d\) either belongs to \(\partial C_B\) or \(\partial C_T\), or is a sector over a cell \(D \subset \partial C'\) having dimension less than \(d-1\).
As \(C'\) is well-bordered, \(D\) belongs to the boundary of some cell \(E \subset \partial C'\) having dimension \(d-1\).
Thus, the sector above \(D\) is contained in the boundary of the sector above \(E\), which has dimension \(d\)

This proves that, if the decomposition induced by \(D\) on \(\mathbb{R}^{n-1}\) is strong, then \(C\) is well-bordered and also satisfies the frontier condition. In addition, this proves that \(C\) is a topologically regular cell as \(C\) and \(\partial C\) are either homeomorphic to \(C'\) and \(\partial C'\), if \(C\) is a sector cell, or to an open cylinder, either bounded or unbounded, and its boundary. It is clear that an open cylinder contained in \(C' \times \mathbb{R}\), where \(C'\) is topologically regular, is also topologically regular.

The other cases are deduced by omitting the cells defined from \(C_B\) and \(C_T\) as appropriate.
\end{proof}

Let \(\cal D\) be the CAD of \(\mathbb{R}^3\) constructed by \citet{lazard10} at the end of Section 5,2. The results in \citep[Section 5.3]{lazard10} assume two properties of \(\cal D\). Firstly \({\operatorname{fr} \left(  C  \right)}\), where \(\dim(C) = k\), is the closure of the union of some cells of \(\cal D\) of dimension \(k-1\). Secondly, according to \citep[Proposition 5.13]{lazard10}, any bad cells in the decomposition induced by \(\cal D\) on \(\mathbb{R}^2\) (those above which some polynomial vanishes over an open interval) are 0-dimensional isolated points.

\begin{lemma}

\citep[ Proposition 5.13]{lazard10}
Let \(\mathcal{D}\) be a sign-invarient decomposition of \(\mathbb{R}^3\), and suppose that \(C\) is a topologically regular cell in \(\mathcal{D}\).
Suppose that \(D\) is a cell of \(\mathcal{D}\) such that \(B := D \cap {\operatorname{fr} \left(  C  \right)} \neq \emptyset\) and \(B \neq D\). Then either

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(C\) is a \(1\)-dimensional section cell whose endpoint, \(B\), projects on a bad cell, or
\item
  there exists a cell \(E\) of \(\mathcal{D}\) such that \(\dim(E) < \dim(C)\) and \(\emptyset \neq D \cap {\operatorname{fr} \left(  E  \right)} \neq D\).
\end{enumerate}

\end{lemma}

To illustrate this, consider the example of the whitney umbrella \(W := \{ x^2 - y^2 z = 0 \}\). Let \(C := \{ x > 0, y > 0, x^2 - y^2 z = 0 \} \subset W\) be one of the 2-dimensional topologically regular cells in a CAD of \(\mathbb{R}^3\) compatible with \(W\).
Then case \(2\) applies, with \(D = \{ x = 0, y = 0 \}\) and \(E = \{ x > 0, y = 0, z = 0 \}\).
Choosing \(C = E\), (and the same \(D\)) we get case \(1\).

By the proof of (TODO laz Th 4.4), \(D\) will always be a \((0,0,1)\)-cell in the cylinder above a bad cell \(D'\).

Let us consider each case for \(C\) by cell index.

\begin{itemize}
\item
  \((1,1,1)\)-cell: since \(C\) is well-bordered, its boundary is the closure of some 2-dimensional cells of \(\cal D\) and \(B\) is contained in the union of the boundaries of the 2-cells. Thus, case 2 applies and we can choose an appropriate 2-dimensional cell in \({\operatorname{fr} \left( C \right)}\) for \(E\).
\item
  \((1,0,1)\)- or \((0,1,1)\)-cell, we write \((i,j,1)\)-cell where \(i+j=1\): observe that \(C\) (if bounded) is delineated by some \((i,j,0)\)-cells (one-dimensional curve intervals). Take \(B\) to be the one-dimensional interval delineated by the endpoints of these cells. Since \(B \neq C\), at least one of these endpoints is not a \((0,0,0)\)-cell of \(\cal D\). Case 2 applies, taking as \(E\) the delineating \((i,j,0)\)-cell.
\item
  \((1,0,0)\)- or \((0,1,0)\)-cells: consider the previous case, letting \(C = E\).
\item
  \((1,1,0)\)-cell: these are necesarily the root of a polynomial \(f \in \mathbb{Q}[x_1,x_2,x_3]\) which vanishes identically on \(D'\), a \((0,0)\) cell in the decomposition induced by \(\cal D\) on \(\mathbb{R}^2\).
  Let \(V_r\) be a small neighbourhood (with radius \(r > 0\)) centered aronud \(D'\) and consider \(V_r'\), the cylinder above the boundary of \(V_r\). Since \(C\) is a monotone cell, the maximum and minimum values of \(x_3\) in this intersection are reached on the boundary of \(C\), for sufficiently small \(r\). The limits, as \(r\) tends to \(0\), of this maximum and minimum clearly belong to the boundary of \(B\), if these limits do not tend to infinity. Note that both the maximum and minimum cannot be infinite, since this would imply that either \(B\) is empty, or coincides with \(D\). Therefore, the non-infinite limits are the endpointns of some \(1\)-dimensional cell belonging to the boundary of \(C\). Case 2 applies, taking \(E\) to be this \(1\)-dimensional cell.
\item
  \((0,0,1)\)- or \((0,0,0)\)-\$cells: cannot satisfy the hypothesis, there is nothing to do.
\end{itemize}

\citep[Proposition 5.14]{lazard10}
Let \(f \in \mathbb{Q}[x_1,x_2,x_3]\) be an irreducible polynomial given by
\[f = g_dx^d + \ldots + g_1x + g_0\]
with each \(g_i \in \mathbb{Q}[x_1,x_2]\), and
\[\mathbf{p} = (p_1,p_2)\]
be a common root of \(g_d,\ldots,g_1,g_0\).
Let \(g\in \mathbb{Q}[x_1,x_2]\) be an irreducible polynomial having \(\mathbf{p}\) as a root.
The limits of the common roots of \(f\) and \(g\) as \((x_1, x_2) \to \mathbf{p}, (x_1, x_2) \ne \mathbf{p}\) may be computed as solutions of a zero-dimensional
polynomial system.

\begin{proof}
Since \(f\) is irreducible, it has at least two coefficients, \(g_i,g_j \in \mathbb{Q}[x_1,x_2]\), whose GCD is a constant.
Therefore, any ideal generated by these coefficients has dimension zero. Any ideal containing these coefficients also contains another element, \(h\), which is not a multiple of \(g\).

The saturation by \(h\) of the ideal \(\langle f,g \rangle\) is defined as the ideal
\[
S := \langle f, g, 1 - zh \rangle \cap \mathbb{Q}[x_1,x_2,x_3].
\]
The irreducible components of the zero set of \(S\) are those of the zero set of \(\langle f,g \rangle\) at which \(h\) is not identically zero. It follows that the vertical line \(\{ x_1 = p_1, x_2 = p_2 \}\) which is part of the zero set of \(f\) ,\(g\) and \(h\), is not contained in the zero set of \(S\). Meanwhile, the zero set of \(S\) contains the limit points we are interested in finding.

It follows that the ideal generated by \(S\) and the coefficients \(g_0,\ldots,g_d\) of \(f\) is zero-dimensional and the limits of \(\{ f=0,g=0 \}\) as \((x_1,x_2) \to \mathbf{p}\) can be computed as the zeros of \(S\).
\end{proof}

\hypertarget{an-aside-on-polynomial-ideals-and-zariski-closures}{%
\subsection{An aside on polynomial ideals and Zariski closures}\label{an-aside-on-polynomial-ideals-and-zariski-closures}}

\citet{lazard10} uses the trick of saturating the ideal \(\langle f,g \rangle\) by some \(h\), which is not a multiple of \(g\). The key to this trick lies in Zariski closures. Let us take an aside to discuss this. We closely follow \citet{cox2013} and all results are proved in a generic polynomial ring \(K[x_1,\ldots,x_n]\) unless otherwise stated.

\hypertarget{ideals-groebner-bases-and-buchbergers-algorithm}{%
\subsubsection{Ideals, Groebner bases and Buchberger's algorithm}\label{ideals-groebner-bases-and-buchbergers-algorithm}}

\begin{definition}

Let \(K[x_1,\ldots,x_n]\) be a polynomial ring. A subset \(I \subset K[x_1,\ldots,x_n]\) is called a polynomial ideal if

\begin{itemize}
\tightlist
\item
  \(0 \in I\),
\item
  if \(a,b \in I\) then \(a+b \in I\), and
\item
  if \(a \in I, b \in K[x_1,\ldots,x_n]\), then \(ab \in I\).
\end{itemize}

\end{definition}

\begin{definition}
Let \(K\) be a field and \(f_1,\ldots, f_k \in K[x_1,\ldots,x_n]\). We set
\[
\left\langle f_{1},\ldots,f_{k}\right\rangle =\left\{ h_{1}f_{1}+\cdots+h_{k}f_{k}\mid h_{1},\ldots,h_{k}\in K[x_{1},\ldots,h_{n}]\right\}
\]
and call it the ideal generated by \(f_1,\ldots,f_k\).
\end{definition}

\citet{hilbert1890} proved, nonconstructively, that every polynomial ideal is finitely generated.

\begin{theorem}
Every ideal \(I \subset k[x_1, \ldots, x_n]\) has a finite generating set. I.e., \(I = \langle g_1, \ldots, g_t\rangle\) for some finite collection of polynomials \(g_1, \ldots, g_t\in I\).
\end{theorem}

A proof can be found in \citep[p76]{cox2013}.

Later, \citet{buchberger1965} published an algorithm for computing this finite set of generators. He also introduced the concept of a Groebner basis.

A Groebner basis requires an ordering on monomials to be fixed.

\begin{definition}

A monomial ordering on \(K[x_1, \ldots, x_n]\) is a relation \(\succ\) on \(\mathbb{Z}^n_{\ge 0}\), or
equivalently, a relation on the set of monomials \(x^\alpha, \alpha\in \mathbb{Z}_{\ge 0}\), satisfying the following properties.

\begin{itemize}
\tightlist
\item
  \(\succ\) is a total order\footnote{
  Total order: a reflexive, antisymmetric, and transinive relation $R$ on a set $X$ such that either $(a,b) \in R$ or $(b,a) \in R$ for all $a,b \in X$.
  } (or linear order) on \(\mathbb{Z}^n_{\ge 0}\).
\item
  If \(\alpha \succ \beta\) and \(\gamma \in \mathbb{Z}^n_{\ge 0}\), then \(\alpha + \gamma \succ \beta + \gamma\).
\item
  \(\succ\) is a well-ordering on \(\mathbb{Z}^n_{\ge 0}\).
  I.e., every nonempty subset of \(\mathbb{Z}^n_{\ge 0}\) has a minimal element under \(\succ\).
\end{itemize}

\end{definition}

Some examples of monomial orderings used in computing Groebner bases include

\begin{itemize}
\item
  \textbf{lex:} Let \(\alpha = (\alpha_1, \ldots, \alpha_n), \beta = (\beta_1, \ldots, \beta_n) \in \mathbb{Z}^n_{\ge 0}\). We say \(\alpha \succ \beta\) if the leftmost nonzero element of \(\alpha - \beta \in \mathbb{Z}^n\) is positive. This imposes a lexicographic order on variables \(x_1 \succ x_2 \succ \cdots \succ x_n\).
\item
  \textbf{grlex:} (graded lex) Let \(\alpha, \beta \in \mathbb{Z}^n_{\ge 0}\) and let \(|\alpha| = \alpha_1 + \cdots + \alpha_n\) and \(|\beta| = \beta_1 + \cdots + \beta_n\). We sate \(\alpha \succ \beta\) if \(|\alpha| > |\beta|\), or if \(|\alpha| = |\beta|\) and \(\alpha \succ_{\rm{lex}} \beta\).
\item
  \textbf{grevlex:} (graded reverse lex) Let \(\alpha, \beta \in \mathbb{Z}^n_{\ge 0}\), and d efine \(|\alpha|\) and \(|\beta|\) as before. We set \(\alpha \succ_{\rm{grevlex}} \beta\) if \(|\alpha| > |\beta|\) or if \(|\alpha| = |\beta|\) and the rightmost nonzero entry of \(\alpha - \beta\) is negative.
\end{itemize}

\begin{definition}

Let \(f\) be a polynomial in \(K[x_1,\ldots,x_n]\) with monomials labelled by indices in \(\mathbb{Z}^n\), of the form \(\sum_{\alpha} a_\alpha x_1^{\alpha_1} \cdots x_n^{\alpha_n}\), and fix a monomial order \(\succ\). Define the following

\begin{itemize}
\item
  \(\operatorname{multideg}(f) = \max\left( \alpha \in \mathbb{Z}^n_{\ge 0} \mid a_{\alpha} \ne 0 \right)\),
\item
  \(\operatorname{lc}(f) = a_{\alpha} \mid \alpha = \operatorname{multideg}(f)\),
\item
  \(\operatorname{lm}(f) = x_1^{\alpha_1} \cdots x_n^{\alpha_n} \mid \alpha = \operatorname{multideg}(f)\).
\item
  \(\operatorname{lt}(f) = \operatorname{lc}(f) \cdot \operatorname{lm}(f)\)
\end{itemize}

\end{definition}

\begin{definition}
Fix a monomial ordering \(\succ\) on \(K[x_1,\ldots,x_n]\). Let \(I \subset K[x_1,\ldots,x_n]\) be an ideal. A finite set \(G = \{ g_1, \ldots, g_t \} \subset I\) is called a Groebner basis if
\[
\langle \operatorname{lt}(g_1),\ldots,\operatorname{lt}(g_t) \rangle = \langle\operatorname{lt}(I)\rangle
\]
where \(\operatorname{lt}(I) = \{ \operatorname{lt}(f) \mid f \in I \}\)
\end{definition}

\begin{definition}
We write \(\overline{f}^{F}\) for the remainder of division of \(f\) by the tuple \(F = (g_1,\ldots,g_t)\). If \(F\) is a Groebner basis, \(F\) can be considered as an (unordered) set by \citep[ p83, Proposition 1]{cox2013}.
\end{definition}

\begin{definition}
Let \(f,g \in K[x_1,\ldots,x_n]\) such that \(\operatorname{multideg}(f) = \alpha\) and \(\operatorname{multideg}(g) = \beta\). Define \(\gamma = \max(\alpha, \beta)\) (where \(\max\) is taken component-wise). \(x_1^{\gamma^1} \cdots x_n^{\gamma^n} = \operatorname{lcm}( \operatorname{lm}(f), \operatorname{lm}(g) )\) is called the least common multiple of the leading monomials of \(f\) and \(g\).
\end{definition}

\begin{lemma}
\protect\hypertarget{lem:multideg}{}\label{lem:multideg}

Let \(f,g \in K[x_1,\ldots,x_n]\) be nonzero polynomials. Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\operatorname{multideg}(fg) = \operatorname{multideg}(f) + \operatorname{multideg}(g)\),
\item
  If \(f+g \ne 0\) then \(\operatorname{multideg}(f+g) \le \max(\operatorname{multideg}(f), \operatorname{multideg}(g))\).
  As a special case, if \(\operatorname{multideg}(f) \ne \operatorname{multideg}(g)\) then equality occurs.
\end{enumerate}

\end{lemma}

\begin{proof}
Write \(f = ax^\alpha + f'\) and \(f = bx^\beta + g'\) so that \(\operatorname{multideg}(f) = \alpha\) and \(\operatorname{multideg}(g) = \beta\). Observe that \(\operatorname{multideg}(f') < \alpha\) and \(\operatorname{multideg}(g') = \beta\) and \(\operatorname{lm}(f) \cdot \operatorname{lm}(g) = x^\alpha \cdot x^\beta = x^{\alpha + \beta}\). Since \(\operatorname{multideg}(f') < \alpha\) and \(\operatorname{multideg}(g') < \beta\), we have \(\operatorname{multideg}(f' \cdot g') < \alpha + \beta\). Hence \(\operatorname{multideg}(f \cdot g) = \alpha + \beta\). This proves property 1.

Now consider \((ax^\alpha + f') + (bx^\beta + g') = (ax^\alpha + bx^\beta) + (f' + g')\). We have \(\operatorname{multideg}(f') < \alpha\) and \(\operatorname{multideg}(g') < \beta\) as before, so it suffices to consider \(ax^\alpha + bx^\beta\). If \(\alpha \ne \beta\) then \(\operatorname{multideg}(f+g) = \max(\alpha, \beta)\). If \(\alpha = \beta\) then if \(a+b\ne 0\) we have \(ax^\alpha + bx^\alpha = (a+b)x^\alpha\), hence \(\operatorname{multideg}(f+g) = \alpha\). Otherwise we have \(ax^\alpha + bx^\alpha = 0x^\alpha\) so \(\operatorname{multideg}(f + g) = \operatorname{multideg}(f' + g') < \alpha\). This proves property 2.
\end{proof}

\begin{lemma}
\protect\hypertarget{lem:remainder-condition}{}\label{lem:remainder-condition}Let \(I \subset K[x_1,\ldots,x_n]\) be an ideal, \(G = \{g_1,\ldots, g_t\}\) be a Groebner basis for \(I\) and \(f\) be an arbitrary polynomial in \(K[x_1,\ldots,x_n]\).
Then there exists a unique \(r \in K[x_1,\ldots,x_n]\) such that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  no term of \(r\) is divisible by any of \(\operatorname{lt}(g_1), \ldots, \operatorname{lt}(g_t)\), and
\item
  there exists \(g\in I\) such that \(f = g + r\).
\end{enumerate}

In particular, \(r\) is the remainder of division of \(f\) by all elements of \(G\) (taken in any order).
\end{lemma}

\begin{proof}
Firstly, using division, we can write \(f = h_1 g_1 + \cdots + h_t g_t + r\), hence \(r\) is not divisible by any polynomials in \(G\) (first condition).
This decomposition of \(f\) can be used to set \(g = h_1 g_1 + \cdots + h_t g_t \in I\), so that \(f = g + r\) (satisfying the second condition).

Now, to prove that \(r\) is unique, suppose that \(f = g + r = g' + r'\) for \(g,g'\) and \(r,r'\) satisfying both conditions. Then \(r-r' = g-g' \in I\) (by definition of an ideal). Assume \(r\ne r'\), then \(\operatorname{lt}(r-r') = \langle \operatorname{lt}(I)\rangle = \langle \operatorname{lt}(g_1),\ldots, \operatorname{lt}(g_t) \rangle\) since \(G\) is a Groebner basis for \(I\). By \citep[ p70, Lemma 2]{cox2013}, this implies \(\operatorname{lt}(r-r')\) is divisible by some \(\operatorname{lt}(g_i)\), which is a contradiction since \(r\) and \(r'\) cannot be divisible by any of the \(\operatorname{lt}(g_i)\)'s.

The final part of the proposition follows from uniqueness of \(r\).
\end{proof}

\begin{corollary}
\protect\hypertarget{cor:div-zero}{}\label{cor:div-zero}Let \(G = \{ g_1,\ldots,g_k \}\) be a Groebner basis for an ideal \(I \subset K[x_1,\ldots,x_n]\) and let \(f \in K[x_1,\ldots,x_n]\). Then \(f \in I\) if and only if the remainder on division of \(f\) by \(G\) is zero.
\end{corollary}

\begin{proof}
If the remainder on division is zero, then we already proved that \(f \in I\).
Conversely, if \(f \in I\) then \(f = f+0\) satisfies the two conditions of Lemma\textasciitilde\ref{lem:remainder-condition}. It follows that the remainder on division of \(f\) by \(G\) is zero.
\end{proof}

\begin{definition}
Let \(f,g \in K[x_1,\ldots,x_n]\). The \(S\)-polynomial of \(f\) and \(g\) is defined as
\[
S(f,g) = \dfrac{\operatorname{lcm}(\operatorname{lt}(f),\operatorname{lt}(g))f}{\operatorname{lt}(f)} - \dfrac{\operatorname{lcm}(\operatorname{lt}(f),\operatorname{lt}(g))g}{\operatorname{lt}(g)}.
\]
\end{definition}

\(S\)-polynomials are constructed to reduce the degree of terms, as shown in the following lemma.

\begin{lemma}
\protect\hypertarget{lem:linear-combination}{}\label{lem:linear-combination}Suppose that \(f \in K[x_1,\ldots, x_n]\) is a sum of polynomials \(\sum_{i=1}^s p_i\) such that \(\operatorname{multideg}(p_i) = \delta\) for all \(1\le i \le s\).
If \(\operatorname{multideg}( \sum_{i=1}^s p_i )\) is a linear combination \(\sum_{(i,j) \in \{1\ldots,s\}^2} a_{ij} S(p_i,p_j)\) where all \(a_{ij} \in K\). Furthermore all \(\operatorname{multideg}(S(p_i,p_j)) < \delta\).
\end{lemma}

\begin{proof}
We can write each \(p_i = c_i (x_1^{\delta_1} \cdots x_n^{\delta_n} + g_i)\) where \(\delta = (\delta_1,\ldots, \delta_n)\), \(c_i \in K\) and \(\operatorname{multideg}(g_i) < \delta\).
In order for \(\operatorname{multideg}(\sum_{i=1}^s p_i) < \delta\), leading monomials of \(p_i\)'s must cancel in the sum. I.e., \(\sum_{i=1}^s c_i\operatorname{lt}(p_i) = 0\) implies \(\sum_{i=1}^s c_i = 0\).

Since \(\operatorname{multideg}(p_i) = \operatorname{multideg}(p_j)\) for all \(i.j\), \(\operatorname{lcm}(\operatorname{lt}(p_i),\operatorname{lt}(p_j)) = x_1^{\delta_i} \cdots x_n^{\delta_n} = h = \tfrac{1}{c_i}\operatorname{lt}(p_i) = \tfrac{1}{c_j}\operatorname{lt}(p_j)\). Consider
\[
S(p_i,p_j) = \dfrac{\operatorname{lcm}(p_i,p_j)p_i}{\operatorname{lt}(p_i)} - \dfrac{\operatorname{lcm}(p_i,p_j)p_j}{\operatorname{lt}(p_j)} = \dfrac{h p_i}{c_i h} - \dfrac{h p_j}{c_j h} = \dfrac{1}{c_i}p_i - \dfrac{1}{c_j}p_j.
\]
Hence
\[
S(p_i,p_j) = \sum_{i=1}^s c_i\dfrac{1}{c_i}(x_1^{\delta_1}\cdots x_n^{\delta_n} + g_i) - \dfrac{1}{c_j}c_j(x_1^{\delta_1}\cdots x_n^{\delta_n} + g_j) = \sum_{i=1}^s g_i - g_j.
\]
Since \(\operatorname{multideg}(g_i) < \delta\) and \(\operatorname{multideg}(g_j) < \delta\), their linear combination, \(S(p_i,p_j)\) has multidegree less than \(\delta\).

Now return to the sum
\[
\sum_{i=1}^s p_i = \sum_{i=1}^s c_i (x_1^{\delta_1} \cdots x_n^{\delta_n} + g_i).
\]
Since terms of the kind \(x_1^{\delta_1}\cdots x_n^{\delta_n}\) cancel,
\[\sum_{i=1}^s p_i = \sum_{i=1}^s c_ig_i = c_1g_1 + \cdots + c_s g_s.\]
We show that this is a linear combination of \(S\)-polynomials.

Consider the sum
\[
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = \sum_{i=1}^{s-1} c_i( g_i - p_s)
= \sum_{i=1}^{s-1} cg_i - c_ig_s,
\] hence
\[
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = c_1g_1 + \cdots + c_{s-1}g_{s-1} - \left( c_1 + \cdots + c_{s-1} \right) p_s.
\]
Since \(c_1 + \cdots + c_{s-1} + c_s = 0\), we have \(c_1 + \ldots + c_{s-1} = -c_s\), and we can write
\[
\sum_{i=1}^{s-1} c_i S(p_i,p_s) = g_1 + \cdots + g_{s-1} - (-c_s) \cdot p_s = \sum_{i=1}^{s} c_i g_i,
\]
proving that \(\sum_{i=1}^s p_i\) is a linar combination of \(S\)-polynomials.
\end{proof}

We are now ready to present Buchhberger's Criterion, the condition under which Buchberger's algorithm will terminate.

\begin{lemma}
\protect\hypertarget{lem:buchberger-criterion}{}\label{lem:buchberger-criterion}Let \(I\) be a polynomial ideal. Then a basis \(G = \{g_1, \ldots, g_t\}\) of \(I\) is a Groebner basis of \(I\) if and only if, for all pairs \(i \ne j\), the
remainder from division of \(S(g_i, g_j)\) by \(G\) (with a fixed order) is zero.
\end{lemma}

\begin{proof}
\(\Rightarrow:\)
If \(G\) is a Groebner basis for \(I\), then \(S(g_i,g_j) \in I\) for all \(g_i,g_j \in G\) and, by Corollary \ref{cor:div-zero}, the remainder of \(\overline{S(g_i,g_j)}^F\) is zero.

\(\Leftarrow:\)
Let \(f \in I\) be a nonzero polynomial. We need to show that \(\operatorname{lt}(f) \in \langle \operatorname{lt}(g_1), \ldots, \operatorname{lt}(g_k) \rangle\). We have to show that
\[
f = \sum^k_{i=1} h_ig_i
\]
where \(h_i \in K[x_1,\ldots,x_n], 1 \le i \le k\). By Lemma \ref{lem:multideg}, we have
\[
\operatorname{multideg}(f) \le \max(\operatorname{multideg}(h_ig_i) \mid h_ig_i \ne 0).
\]
We want to try to find the `'most efficient'' representation of \(f\). I.e., one where
\[
\delta = \max(\operatorname{multideg}(h_ig_i) \mid h_ig_i \ne 0)
\]
is minimal. Such a \(\delta\) exists by the well-ordering property (a minimal element always exists). We have
\[
\operatorname{multideg}(f) \le \delta = \max(\operatorname{multideg}(h_ig_i) \mid h_ig_i \ne 0)
\]

First consider the case when \(\operatorname{multideg}(f) = \delta\). We have \(\operatorname{multideg}(f) = \operatorname{multideg}(h_ig_i)\) for some \(1 \le i \le k\). Therefore \(\operatorname{lt}(f)\) is divisible by \(\operatorname{lt}(g_i)\). Hence \(\operatorname{lt}(f) \in \langle g_i, \ldots, g_k \rangle\).

Now suppose that \(\operatorname{multideg}(f) < \delta\). We can write \(f\) as follows
\[
\sum_{i=1}^{k}h_{i}g_{i}=\sum_{i=1}^{k}\operatorname{lt}(h_{i})g_{i}+\sum_{i=1}^{k}(h_{i}-\operatorname{lt}(h_{i}))g_{i}
\]
and use this representation to isolate terms with maximum multidegree
\[
\sum_{\operatorname{multideg}(h_{i}g_{i})=\delta}\operatorname{lt}(h_{i})g_{i}+\sum_{\operatorname{multideg}(h_{i}g_{i})=\delta}(h_{i}-\operatorname{lt}(h_{i}))g_{i}+\sum_{\operatorname{multideg}(h_{i}g_{i})<\delta}h_{i}g_{i}.
\]
The last two terms have \(\operatorname{multideg}< \delta\), so we attempt to rewrite \(\sum_{\operatorname{multideg}(h_ig_i)= \delta} \operatorname{lt}(h_i)g_i\) to decrease \(\delta\), thereby obtaining a contradiction. Applying Lemma \ref{lem:linear-combination} with \(p_i = \operatorname{lt}(h_i)g_i\) with multidegree \(\delta\) and \(f\) with multidegree \(< \delta\), we can write \(\sum_{\operatorname{multideg}(h_ig_i) = \delta} \operatorname{lt}(h_i)g_i\) as a linear combination (with coefficients in \(K\)) of \(S\)-polynomials having multidegree \(< \delta\). Hence, we know that \(f\) can be rewritten as a sum of polynomials with multidegree \(< \delta\), contradicting the assumption that \(\delta\) is minimal.

Given an expression \(f = \sum^t_{i=1} h_i g_i\) with minimal \(\delta\), we begin by isolating the part of the sum having multidegree \(\delta\).

\begin{align}
f=&\sum_{{\rm multideg}(h_{i}g_{i})=\delta}h_{i}g_{i}+\sum_{{\rm multideg}(h_{i}g_{i})<\delta}h_{i}g_{i}\\
=&\sum_{{\rm multideg}(h_{i}g_{i})=\delta}(h_{i}-{\rm lt}(h_{i}))g_{i}+\sum_{{\rm multideg}(h_{i}g_{i})<\delta}h_{i}g_{i} \label{eq:multideg-delta-simp}
\end{align}
The second and third sums in Equaton \eqref{eq:multideg-delta-simp} have multidegree \(< \delta\). Since \(\operatorname{multideg}(f) < \delta\), the multidegree of the first sum in Equation \eqref{eq:multideg-delta-simp} must also have multidefree \(< \delta\).

The key to decreasing \(\delta\) is to rewrite the first term in this sum in two stages:

\begin{itemize}
\tightlist
\item
  use \citep[Lemma 5]{cox2013} to rewrite the first term in the sum in terms of \(S\)-polynomials,
\item
  then use \(S(g_i,g_j) = 0\) to rewrite the \(S\)-polynomials without cancellation.
\end{itemize}

By \citep[Lemma 5]{cox2013},
\[
\sum_{\rm(multideg)(h_i g_i) < \delta} \rm{lt}(h_i) g_i
\]
is a linear combination of the coeffinients in \(K\) of the \(S\)-polynomials
\[
S(\operatorname{lt}(h_i) g_i, \operatorname{lt}(h_j), g_j),
\]
since each \(\operatorname{lt}(f_i) g_i\) has multidegree \(\delta\) while the sum has multidegree \(< \delta\).

We have
\begin{equation}
\label{eq:sum-lt}
S(\rm{lt}(h_i) g_i, \rm{lt}(h_j) g_j) = x^{\delta - \gamma_{i,j}} S(g_i,g_j)
\end{equation}
where
\(x^{\gamma_{i,j}} = \operatorname{lcm}( \operatorname{lm}(g_i), \operatorname{lm}(g_j))\) it follows that the first sum (Equation \eqref{eq:sum-lt}) is a linear combination of \(x^{\delta - \gamma_{i,j}} S(g_i,g_j)\) for appropriate pairs \((i,j)\).

Consider one of the \(S(g_i,g_j)\). Since \(\overline{S(g_i,g_j)}^G = 0\), we can rewrite it as
\begin{equation}
\label{eq:s-sum-a}
S(g_i,g_j) = \sum^t_{\ell = 1} A_\ell g_\ell,
\end{equation}
where \(A \in K[x_1,\ldots,x_n]\) and
\begin{equation}
\label{eq:s-lt}
\rm{multideg}(A_\ell g_\ell) \le \rm{multideg}(S(g_i,g_j))
\end{equation}
where \(A_\ell g_\ell \ne 0\).
By multiplying both sides of Equation \eqref{eq:s-sum-a} by \(x^{\delta - \gamma_{i,j}}\), we get
\[
x^{\delta - \gamma_{i,j}}S(g_i,g_j) = \sum^t_{\ell = 1} B_\ell g_\ell,
\]
where \(B_\ell = x^{\delta - \gamma_{i,j}} A_\ell\). Then it follows from Equation \eqref{eq:s-lt} that
\[
\rm{multideg}(B_\ell g_\ell) \le \rm{multideg}(S(g_i,g_j)) < \delta
\]
since \(\rm{lt}(S(g_i,g_j)) < \rm{lcm}(\rm{lm}(g_i), \rm{lm}(g_j)) = x^{\gamma_{i,j}}\).

It follows that we can rewrite the first term in the sum as
\[
\sum_{\rm{multideg}(h_i g_i) = \delta} \rm{lt}(h_i) g_i = \sum^t_{\ell = 1} \tilde{B_\ell} g_\ell
\]
with the property that when \(\tilde{B_\ell}g_\ell \ne 0\), we have \(\rm{multideg}(\tilde{B_\ell} g_\ell) < \delta\).

we have obtained an expression for \(f\) as a polynomial combination of the \(g_i\)'s where every term has multidegree \(< \delta\). This contradicts the assumption that \(\delta\) was minimal and completes the proof.
\end{proof}

The basic idea of Buchberger's algorithm is that polynomials are added to the input set until a Groebner basis is obtained -- i.e., until Buchberger's criterion is satisfied.

There now follows a worked example to illustrate Buchberger's algorithm.

Consider \(I = \langle f_1, f_2 \rangle = \langle x^3 - 2xy, x^2 y - 2y^2 + x \rangle \subset Q[x,y]\) with grlex ordering.
\(\langle f_1, f_2 \rangle\) is not a Groebner basis for \(I\).
Indeed,
\begin{align*}
S(f_1,f_2) &= \dfrac{x^{3}y}{x^{3}}\left(x^{3}-2xy\right)-\dfrac{x^{3}y}{x^{2}y}\left(x^{2}y-2y^{2}+x\right) \\
&= \left(x^{3}y-2xy^{2}\right)-\left(x^{3}y-2xy^{2}+x^{2}\right)\\
&= -x^2 \not \in \{\operatorname{lt}(f_1), \operatorname{lt}(f_2)\}
\end{align*}
Compute \[
\overline{ S(f_1,f_2) }^F.
\]
We have
\[
S\left(f_{1},f_{2}\right)=-x^{2}=g_{1}\left(x^{3}-2xy\right)+g_{2}\left(x^{2}y-2y^{2}+x\right)+h.
\]
Setting \(g_1 = -y,g_2 = x\) gives
\begin{align*}
&-y\left(x^{3}-2xy\right)+x\left(x^{2}y-2y^{2}+x\right) + h\\
=&-x^{3}y+2xy^{2}+x^{3}y-2xy^{2}+x^{2} + h\\
\Rightarrow& h = -x^2\\
\end{align*}
Add \(-x^2\) to \(F\).
Since \(-x^2 \in I\), we have \(\overline{S(f_1,f_2)}^F = 0\).

We now need to consider \(S(f_1,f_3)\) and \(S(f_2,f_3)\).
\begin{align*}
S\left(f_{1},f_{3}\right)&=\dfrac{x^{3}}{x^{3}}\left(x^{3}-2xy\right)-\dfrac{x^{3}}{x^{2}}x^{2}=-2xy\\S(f_{2},f_{3})&=\dfrac{x^{2}y}{x^{2}y}\left(x^{2}y-2y^{2}+x\right)-\dfrac{x^{2}y}{x^{2}}x^{2}=-2y^{2}+x
\end{align*}
The remainder of \(\overline{S(f_1,f_3)}^F\) is \(-2xy \i I\), so we add \(-2xy\) to \(F\). Similarly, the remainder \(\overline{S(f_2,f_3)}^F\) is \(-2y^{2}+x\), so we add \(-2y^{2}+x\) to \(F\).

We have \[F = \left( x^3 - 2xy, x^2 y - 2y^2 + x, -x^2, -2xy, -2y^2 + x \right),\]
and \(\overline{S(f_i,f_j)}^F=0\) for all \(f_i,f_j \in F\). We conclude that \(F\) is a Groebner basis for \(I\).

We now present the algorithm.

\textbf{Input:} \(F = \{ f_1,\ldots,f_k \} \subset K[x_1,\ldots,x_n]\) -- a finite set of multivariate polynomials

\textbf{Output:} A Groebner basis \(G\) for \(I = \langle f_1,\ldots,f_k \rangle\), s.t. \(F \subset G\)

\begin{itemize}
\item
  Let \(G := F\)
\item
  do

  \begin{itemize}
  \item
    let \(G' := G\)
  \item
    for \(f,g\in G\) s.t. \(f \neq g\):

    \begin{itemize}
    \item
      let \(r = \overline{S(f,g)}^{G'}\)
    \item
      if \(r \ne 0\) then \(G := \{r\} \cup G\)
    \end{itemize}
  \end{itemize}
\item
  while \(G \ne G'\)
\item
  return \(G\)
\end{itemize}

See \citep[ p91, Theorem 2]{cox2013} for a proof that this algorithm does indeed produce a Groebner basis for \(F\) and always terminates in a finite number of steps. Following Buchberger's algorithm, there were several improvements in efficiency, for example \ldots{} and Groebner basis remain a vital tool in computer algebra.

\hypertarget{zariski-closures-and-saturations}{%
\subsubsection{Zariski closures and saturations}\label{zariski-closures-and-saturations}}

Let \(f_1,\ldots,f_k \in K[x_1,\ldots,x_n]\). We define
\[
V(f_1,\ldots,f_k) := \{ x \in K^n \mid f_1(x), \ldots, f_k(x) = 0 \}.
\]
If \(I \subset K[x_1,\ldots,x_n]\) is a polynomial ideal, we write
\[
V(I) := \{ x \in K^n \mid f(x) = 0 \text{ for all } f \in I \}.
\]

Let \(V \subset K^n\) be an affine algebraic variety. Then
\[
I(V) := \{ f \in K[x_1,\ldots,x_n] \mid f(a) = 0 \text{ for all } a \in V \}.
\]

To every variety belongs an ideal:

\begin{lemma}
If \(V \subset K^n\) is an affine variety, then \(V(I) \subset K[x_1,\ldots,k_n]\) is an ideal (called the ideal of \(V\)).
\end{lemma}

\begin{proof}

We prove \(I\left(V\right)\) satisfies the properties of an ideal.

\begin{itemize}
\item
  \(0\left(x\right)=0\) for all \(x\in K^{n}\), hence \(0\left(x\right)=0\) for all \(x\in V\), so \(0\in I\left(V\right)\).
\item
  Let \(x\in V\). If \(f,g\in I\left(V\right)\) then by definition we have \(f\left(x\right)=0\) and \(g\left(x\right)=0\). Then \(f\left(x\right)+g\left(x\right)=0+0=0\), hence \(f+g\in I\left(V\right)\).
\item
  Let \(x\in V\). If \(f\in I\left(V\right)\) and \(h\in K[x_{1},\ldots,x_{n}]\). By definition we have \(f\left(x\right)=0. h\left(x\right)f\left(x\right)=h\left(x\right)\cdot 0=0\), hence \(hf\in I\left(V\right)\) for all \(h\in K[x_{1},\ldots,x_{n}]\).
\end{itemize}

\end{proof}

\ldots and to every ideal belongs a variety.

\begin{lemma}
\(V(I)\) is an affine variety. In particular if \(I = \langle f_1,\ldots,f_k\rangle\) then \(V(I) = V(f_1,\ldots,f_k)\).
\end{lemma}

\begin{proof}
By the Hilbert Basis Theorem \(I\) is finitely generated, therefore \(I = \langle f_1,\ldots, f_k \rangle\) for some finite set of generators in \(K[x_1,\ldots,x_n]\). We want to show that \(V(I) = V(f_1,\ldots,f_k)\).

Since \(f1 \ldots,f_k \in I\) and \(f(a) = 0\) for all \(f\in I\), \(V(I) \subset V(f_1,\ldots,f_k)\).
On the other hand, suppose \(x \in V(f_1,\ldots,f_k)\). Since \(I = \langle f_1,\ldots,f_k \rangle\), every \(f \in I\) can be written
\[
f = h_1f_1 + \cdots + h_kf_k.
\]
Since \(f_i(x) = 0\) for all \(1 \le i \le k\), we have
\[
f(x) = h_1(x) \cdot 0 + \cdots + h_k(x) \cdot 0 = 0 + \cdots + 0 = 0.
\]
Therefore \(V(f_1,\ldots,f_k) \subset V(I)\), hence \(V(I) = V(f_1,\ldots,f_k)\).
\end{proof}

Let \(S \subset K^n\) be an arbitrary subset, not necesarily an affine algebraic variety. \(I(S)\) (defined in the same way as above) is an ideal and by the ideal-variety correspondance, \(V(I(S))\) if an affine algebraic variety.

\begin{lemma}
Let \(S \subset K^n\). \(V(I(S))\) is the smallest affine algebraic variety containing \(S\).

(I.e., for all affine algebraic varieties \(W \supset S\), \(V(I(S)) \subset W\).)
\end{lemma}

\begin{proof}
If \(S \subset W\), then \(I(W) \subset I(S)\) because the operation \(I\) is inclusion reversing.
In addition, \(V(I(S)) \subset V(I(W))\) because \(V\) is also inclusion reversing.
Since \(W\) is an affine algebraic variety, \(V(I(W)) = W\), so we have \(V(I(S)) \subset W\).
\end{proof}

\begin{definition}
The Zariski closure of a subset \(S \subset K^n\) is the smallest affine algebraic variety containing \(S\). We denote the Zariski closure of \(S\) by \(\overline{S}\).
\end{definition}

The following property relating Zariski closures and ideals is relevant to \citep[Proposition 5.14]{lazard10}.

\begin{lemma}
\citep[ p203, part of Theorem 10]{cox2013}
Let \(I,J \subset K[x_1,\ldots,x_n]\) be ideals, then
\({\operatorname{cl} \left(  V(I) \setminus V(J)  \right)} \subset V(I : J^\infty)\),
\end{lemma}

\begin{proof}
We claim that \(I \subset I:J \subset I:J^\infty \subset I(V(i0) \setminus V(J))\). We have \(I \subset I:J \subset I:J^2 \subset \cdots \subset I:J^\infty\) by the ascending chain condition.
Suppose that \(f \in I:J\infty\) and \(a \in V(I) \setminus V(J)\). Then \(fg^N \in I\) for all \(g \in J\) and a suitable (large enough) \(N\ge 0\). Since \(a \in V(I)\), \(f(a)g^N(a) = 0\) (for all \(g\in J\) and large enough \(N\)). Since \(a \not \in V(J)\), there exists \(f \in J\) and \(N \ge 0\) such that \(g(a) \ne 0\). Hence \(f(a) = 0\) for all \(a \in V(I) \setminus V(J)\). We have \(f \in I(V(I) \setminus V(J))\). Transitivity of \(\subset\) proves the claim. Since \(V\) reverses incl0usion, we have \(= {\operatorname{cl} \left(  V(i) \setminus V(J)  \right)} = V(I(V(i) \setminus V(J))) \subset V(I:J^\infty)\).
\end{proof}

Now we can return to \citep[Proposition 5.14]{lazard10}. By \citep[Proposition 5.13]{lazard10}, we may assume that \({\operatorname{fr} \left(  C  \right)}\) is the closure of some one-dimensional cells and that blow-up points, if they exist, are 0-dimensional cylindrical cells in the induced decomposition of \(\mathbb{R}^2\).
We begin with an irreducible polynomial \(f \in \mathbb{Q}[x_1,x_2,x_3]\), such that there exists a \((1,1,0)\)-cell \(C \subset \{ \mathbf{x} \in \mathbb{R}^3 \mid f(\mathbf{x}) = 0 \}\), a point \(\mathbf{p} = (p_1,p_2) \in \mathbb{R}^2\) such that \(\mathbf{p}\) is a blow-up point of \(f\) and \(g \in \mathbb{Q}[x_1,x_2]\) such that \(g(\mathbf{p}) = 0\).
Consider the variety \(V(\langle f \rangle + \langle g \rangle ) = V(f) \cap V(g)\), which contains some of the one-dimensional cells which form part of \({\operatorname{fr} \left( C \right)}\) and the blow-up subset \(B \subset \mathbf{p} \times \mathbb{R}\).
The saturation by \(h\) of \(I\),
\[
S := \langle f, g, 1 - zh \rangle \cap \mathbb{Q}[x_1,x_2,x_3]
\]
is constructed.
By \citep[Theorem 10]{cox2013} (TODO),
\[
{\operatorname{cl} \left(  V(\langle f,g \rangle) \setminus V(\langle h \rangle)  \right)} \subset S.
\]
Since our blow-up point \(\mathbf{p}\) is \(0\)-dimensional, computing this Zariski closure effectively ``fills in the hole'' left by removing the blow-up subset from \(V(\langle f,g \rangle)\). Thus, we have the limit points of the cell \(C\) as it approaches the blow-up subset \(B\).
In order to find the refinement points above \(\mathbf{p}\), we compute a generating set (Groebner basis) \(\{ f_1,\ldots,f_k \}\) for \(S\) and solve the system of equations
\[
f_1 = 0, \ldots, f_k = 0, g = 0, h = 0.
\]

Note that this procedure only works if the blow-up points have dimension zero, otherwise the Zariski Closure will not be sufficient to find the limit points.

\hypertarget{algorithm-for-lifting-with-bad-points-in-mathbbr3}{%
\subsection{\texorpdfstring{Algorithm for lifting with bad points in \(\mathbb{R}^3\)}{Algorithm for lifting with bad points in \textbackslash mathbb\{R\}\^{}3}}\label{algorithm-for-lifting-with-bad-points-in-mathbbr3}}

Let \(\cal D\) be a cylindrical algebraic decomposition of \(\mathbb{R}^n, n \le 3\). If \(n < 3\), \(\cal D\) already satisfies the frontier condition since there are no bad cells in the decomposition induced by \(\cal D\) on \(\mathbb{R}^1\). Othewrise \(n=3\) and we apply \citet{lazard10}, Algorithm 5.15 to \(\cal D\) to produce a set of refinement points. This algorithm, written using our notation, is reproduced below.

\begin{itemize}
\item
  Let \(\cal D'\) be the decomposition induced by \(\cal D\) on \(\mathbb{R}^2\).
\item
  For each \((0,0)\)-cell (point) \(\mathbf{p}\) of \(\cal D'\), determine whether it is a bad cell. \(\mathbf{p}\) is a bad cell if there exists a polynomial \(f \in {\cal A}_3\) such that \(f\) has constant sign on a \((0,0,1)\)-cell \(C\) of \(\cal D\) such that \(\mathbf{p} = {\operatorname{proj}_{\mathbb{R}^{2}}}(C)\).
\end{itemize}

(Note that this can easily be done by checking sings of projection factors for each \(f \in {\cal A}_3\) assigned to \(C\)).

\begin{itemize}
\item
  Let \(g_1 \in {\cal A}_1, g_2 \in {\cal A}_2\) such that \(g_1(\mathbf{p}) = 0\) and \(g_2(\mathbf{p}) = 0\).
\item
  Let \({\cal A'} := {\cal A}_1 \cup {\cal A}_2\).
\item
  For each \(g \in {\cal A'}\), do

  \begin{itemize}
  \item
    If \(g \in \mathbb{Q}[x_1]\), then \(h := g_2\). Otherwise, \(g \in \mathbb{Q}[x_1,x_2]\) and \(h := g_1\).
  \item
    Define the saturation
    \[
    I := \langle f, g, 1 - z h \rangle,
    \]
    where \(z\) is a new variable.
  \item
    Compute a generator system \(S\), i.e., a Groebner basis, \(S\) for the ideal \(I\).
  \item
    Compute
    \[
    L := \{ \rm{sub}_{\mathbf{p}}(f') \in \mathbb{Q}[x_3] \mid f' \in S \}
    \]
    and compute the roots
    \[
    (c_1,\ldots,c_t)
    \]
    of \(L\).
  \item
    Let
    \[
    {\cal R}_{\mathbf{p}} := (c_1,\ldots,c_t).
    \]
  \end{itemize}
\item
  return \(\cal R\).
\end{itemize}

Compute the refinement of sections above bad cells using the same method described in Section \ref{sec:compute-refinement}.

\hypertarget{generalisation-of-lazard}{%
\section{Generalisation of Lazard}\label{generalisation-of-lazard}}

We can now generalise this result to cells of dimension \(\le 2\) in a CAD of arbitrary dimension.
Our goal is to construct a CAD of \(\mathbb{R}^n\), compatible with \(V := V_1 \cup \ldots, \cup V_k\) such that \(\dim(V_i) \le 2\) for all \(1 \le i \le k\), such that each cell is monotone with respect to \(V\) and and each cell \(C \subset V\) satisfies the frontier condition.
In Section \ref{sec:quasi-affine}, we constructed a decomposition such that ecah cell has constant sign on every polynomial defining \(V\), with the result that each cell in the decomposition is smooth. In Section \ref{sec:monotone-cells}, we refined that decomposition so that each cell \(C \subset V\) is monotone.
In order to extend \citet{lazard10}, Algorithm 5.14, we will require this monotonicity property. We will also require an additional property.

\begin{lemma}
\protect\hypertarget{lem:lazard-5-2}{}\label{lem:lazard-5-2}\citep[Proposition 5,2]{lazard10}
Let \(\cal D\) be a CAD of \(\mathbb{R}^n\) and \(\cal D'\) the decomposition induced by \(\cal D\) on \(\mathbb{R}^{n-1}\). Let \(C\) be a cell of \(\cal D\) and \(C' := {\operatorname{proj}_{\mathbb{R}^{n-1}}} (C)\) such that \(C'\) is well-bordered.
If \(p \in {\operatorname{fr} \left( C' \right)}\), then \(I := (p \times \mathbb{R}) \cap {\operatorname{fr} \left( C \right)}\) is connected.
\(I\) is thus a point or a closed segment, either bounded or unbounded.
Furthermore, if \(C\) is a sector cell, then the set of points of \(I\) which do not belong to the boundaries of the section cells delimiting \(C\) is either empty or an open interval.
\end{lemma}

By @\ref{lem:no-blow-up}, if no cell adjacent to \(C\) is bad and the induced decomposition is strong, then \(C\) is well-bordered, topologically regular and satisfies the forntier condition. Thus, we need to look at what happens in the neighbourhood of blow-up poits only.

\begin{lemma}
Let \(\cal D\) be a sign-invariant CAD of \(\mathbb{R}^n\) , \(C\) be a cell of \(\cal D\) and \(C' := {\operatorname{proj}_{\mathbb{R}^{n-1}}}(C)\) satisfy the frontier condition. If no cell in \({\operatorname{fr} \left( C' \right)}\) is bad, then \(C\) satisfies the frontier condition.
\end{lemma}

Proof is either by Lazard or Davenport, Locatelli and Sankaran.

If there is a blow-up point, then the following situation will occur.

\begin{lemma}

Let \(\mathcal{D}\) be a sign-invarient decomposition of \(\mathbb{R}^n\) compatible with a semialgebraic set \(V \subset \mathbb{R}^n\) having dimension at most \(2\), and suppose that \(C \subset V\) is a topologically regular cell in \(\mathcal{D}\).
Suppose that \(D\) is a cell of \(\mathcal{D}\) such that \(B := D \cap {\operatorname{fr} \left(  C  \right)} \neq \emptyset\) and \(B \neq D\). Then either

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(C\) is a \(1\)-dimensional section cell whose endpoint, \(B\), projects on a bad cell, or
\item
  there exists a cell \(E\) of \(\mathcal{D}\) such that \(\dim(E) < \dim(C)\) and \(\emptyset \neq D \cap {\operatorname{fr} \left(  E  \right)} \neq D\).
\end{enumerate}

\end{lemma}

By the proof of \citep[Theorem 4.4]{lazard10}, \(D\) will always be a \((0,\ldots,0,1)\)-cell in the cylinder above a bad cell \(D'\).

Since \(\dim(V) \le 2\), \(C\) has dimension at most \(2\). We consider each case by cell index.

\begin{itemize}
\item
  \((i_1,\ldots,i_{n-1},1)\)-cell, where \(\sum_{j=1}^{n-1} i_j = 1\): observe that \(C\) (if bounded) is delineated by some \((i_1,\ldots,i_{n-1},0)\)-cells (one-dimensional curve intervals). Take \(B\) to be the one-dimensional interval delineated by the endpoints of these curves. Since \(B \neq C\), at least one of these endpoints is not a \((0,,\ldots,0,0)\)-cell of \(\cal D\). Case 2 applies, taking as \(E\) the delineating \((i_1,\ldots,i_{n-1},0)\)-cell.
\item
  \((i_1,\ldots,i_{n-1},0)\)-cells, where \(\sum_{j=1}^{n-1} i_j = 1\): consider the previous case, letting \(C = E\).
\item
  \((i_1,\ldots,i_{n-1},0)\)-cell, where \(\sum_{j=1}^{n-1} i_j = 2\):
  are necesarily the root of a polynomial \(f \in \mathbb{Q}[x_1,\ldots,x_n]\) which vanishes identically on \(D'\), a \((0,\ldots,0)\) cell in the decomposition induced by \(\cal D\) on \(\mathbb{R}^{n-1}\).
  Let \(V_r\) be a small neighbourhood (with radius \(r > 0\)) centered aronud \(D'\) and consider \(V_r'\), the cylinder above the boundary of \(V_r\). Since \(C\) is a monotone cell, the maximum and minimum values of \(x_n\) in this intersection are obtained on the boundary of \(C\), for sufficiently small \(r\). The limits, as \(r\) tends to \(0\), of this maximum and minimum clearly belong to the boundary of \(B\), if these limits do not tend to infinity. Note that both the maximum and minimum cannot be infinite, since this would imply that either \(B\) is empty, or coincides with \(D\). Therefore, the non-infinite limits are the endpointns of some \(1\)-dimensional cell belonging to the boundary of \(C\). Case 2 applies, taking \(E\) to be this \(1\)-dimensional cell.
\item
  \((0,\ldots,0,1)\)- or \((0,\ldots,0,0)\)-cells: do not satisfy the hypothesis, there is nothing to do.
\end{itemize}

The previous two results mean that we can extend \citet{lazard10} Theorem 5.13 to 2-dimensional cells in sign-invariant decompositions of \(\mathbb{R}^n\).

Let \(f \in \mathbb{Q}[x_1,\ldots,x_n]\) be an irreducible polynomial given by
\[f = g_dx^d + \ldots + g_1x + g_0\]
with each \(g_i \in \mathbb{Q}[x_1,\ldots,x_{n-1}]\), and
\[\mathbf{p} = (p_1,\ldots,p_{n-1})\]
be a common root of \(g_d,\ldots,g_1,g_0\).
Let \(g_j\in \mathbb{Q}[x_1,\ldots,x_j], j \in \{1,\ldots,n-1\} \setminus \ell\), where \(1 \le \ell \le n-1\), be irreducible polynomials having \(\mathbf{p}\) as a root.
The limits of the common roots of \(f\) and the \(g_i\)'s as \((x_1, x_2) \to \mathbf{p}, (x_1, x_2) \ne \mathbf{p}\) may be computed as solutions of a zero-dimensional
polynomial system.

\begin{proof}
\textbf{This is wrong!}

Since \(f\) is irreducible, it has at least two coefficients, \(g_i,g_j \in \mathbb{Q}[x_1,\ldots,x_{n-1}]\), whose GCD is a constant.
Therefore, any ideal generated by these coefficients has dimension zero. Any ideal containing these coefficients also contains another element, \(h\), which is not a multiple of \(g\).

The saturation by \(h\) of the ideal \(\langle f,g \rangle\) is defined as the ideal
\[
S := \langle f, g, 1 - zh \rangle \cap \mathbb{Q}[x_1,x_2,x_3].
\]
The irreducible components of the zero set of \(S\) are those of the zero set of \(\langle f,g \rangle\) at which \(h\) is not identically zero. It follows that the vertical line \(\{ x_1 = p_1, x_2 = p_2 \}\) which is part of the zero set of \(f\) ,\(g\) and \(h\), is not contained in the zero set of \(S\). Meanwhile, the zero set of \(S\) contains the limit points we are interested in finding.

It follows that the ideal generated by \(S\) and the coefficients \(g_0,\ldots,g_d\) of \(f\) is zero-dimensional and the limits of \(\{ f=0,g=0 \}\) as \((x_1,x_2) \to \mathbf{p}\) can be computed as the zeros of \(S\).
\end{proof}

\hypertarget{a-novel-algorithm-for-the-obtaining-the-frontier-condition-on-a-cylindrical-decomposition-of-mathbbrn}{%
\chapter{\texorpdfstring{A novel algorithm for the obtaining the frontier condition on a cylindrical decomposition of \(\mathbb{R}^n\)}{A novel algorithm for the obtaining the frontier condition on a cylindrical decomposition of \textbackslash mathbb\{R\}\^{}n}}\label{a-novel-algorithm-for-the-obtaining-the-frontier-condition-on-a-cylindrical-decomposition-of-mathbbrn}}

So far, we have been concerned only with cylindrical algebraic decomposition compatible with subsets of \(\mathbb{R}^n\) having dimension at most two. We will now present a novel algorithm for obtaining the frontier condition on a cylindrical algebraic decomposition of \(\mathbb{R}^n\) compatible with a set of arbitrary dimension.

\begin{theorem}
\protect\hypertarget{thm:novel-frontier-main}{}\label{thm:novel-frontier-main}Let \(S \subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula \(F\) with \(s\) different polynomials of maximum degree \(d\) in \(\mathbb{R}[x_1,\ldots,x_n]\).
There is an algorithm, taking \(F\) as input, which outputs a cylindrical decomposition \(\mathcal D\) of \(\mathbb{R}^n\) compatible with \(S\) and
satisfying the frontier condition.
The complexity of this algorithm is \((sd)^{O(1)^{n2^n}}\).
This is also an upper bound on the number of cells in \(\mathcal D\), number of polynomials defining cells and their degrees.
\end{theorem}

\begin{remark}
Algorithm in Theorem \ref{thm:novel-frontier-main} is understood as a Blum-Shub-Smale (BSS) real numbers machine \citet{blum1998}.
A similar statement is also true for the Turing machine model, in which case the complexity bound
depends, in addition, polynomially on maximal bit-size of coefficients (cf.~\citet{collins1975}).
\end{remark}

\hypertarget{subroutines}{%
\section{Subroutines}\label{subroutines}}

We first present some subroutines necesary to obtain a CAD with frontier condition.

\hypertarget{the-classical-cad}{%
\subsection{The ``Classical'' CAD}\label{the-classical-cad}}

We have been working with cylindrical algebraic decomposition throughout this work. Here we present a slightly improved version of the algorithm due to \citet{bpr2006}.

\begin{proposition}
\protect\hypertarget{prp:novel-frontier-collins}{}\label{prp:novel-frontier-collins}\citep[Algorithm 11.2]{bpr2006}
Let \(\mathbf{F} := f_1,\ldots,f_s\) be polynomials in \(\mathbb{R}[x_1, \ldots ,x_n]\) having maximum degree \(d\).
There is an algorithm, taking \(\{f_1,\ldots,f_s\}\) as input, which produces a cylindrical decomposition \(\mathcal E\) of \(\mathbb{R}^n\) such that every cell in \(\mathcal{E}\) has constant sign on every polynomial \(f_1,\ldots,f_s\).
The complexity of the algorithm is \((sd)^{O(1)^{n}}\).
This is also an upper bound on the number of cells in \(\mathcal E\), number of polynomials defining cells and their degrees.
\end{proposition}

This is the so-called \(\mathbf{F}\)-invariant CAD. We also present two variations of the algorithm for constructing a ``coarser'' CAD, i.e., one containing fewer cells.

\begin{proposition}
\protect\hypertarget{prp:novel-frontier-collins-sets}{}\label{prp:novel-frontier-collins-sets}Let \(S_1,\ldots,S_k\) be a finite collection of semialgebraic subsets of \(\mathbb{R}^n\) defined by quantifier-free Boolean formulas \(F_1,\ldots,F_k\) respectively. Together, these formulas include \(s\) different polynomials in \(\mathbb{R}[x_1,\ldots,x_n]\), having maximum degree \(d\).
There is an algorithm, taking \(\{F_1,\ldots,F_k\}\) as input, which produces a cylindrical decomposition \(\mathcal E\) of \(\mathbb{R}^n\) compatible with each \(S_i, 1 \le i \le k\).
Complexity, number of cells, number of polynomials and degrees are the same as in Proposition \ref{prp:novel-frontier-collins}.
\end{proposition}

\begin{proof}
Let \(f_1,\ldots,f_s \in \mathbb{R}[x_1,\ldots,x_n]\) be the polynomials from formulas \(F_1,\ldots,F_k\) and let \(\mathcal{E}'\) be the CAD of \(\mathbb{R}^n\) produced by Proposition @ref\{prp:novel-frontier-collins\} with \(f_1,\ldots,f_s\) as input. Since \(F_i\) for each \(1\le i\le k\) provides a set of sign conditions on polynomials \(f_1,\ldots,f_s\), \(\mathcal{E}'\) is a refinement of the CAD produced by this algorithm.

Truth values of \(F_1,\ldots,F_k\) on ecah cell can easily be computed from the CAD produced by Proposition \ref{prp:novel-frontier-collins} by considering the signs of \(f_1,\ldots,f_s\) on ecah cell, which we computed in the construction of \(\mathcal{E}'\).
Observe that this does not change the asymptotic complexity or bounds in Propoosition \ref{prop:collins}.
\end{proof}

The construction described in the above proof is very naive. This algorithm, in a more tractable form, is presented in, e.g., \citet{collins1991}, and an alternative approach is presented in \citet{bradford2014}.

\begin{proposition}
\protect\hypertarget{prp:novel-frontier-collins-one-set}{}\label{prp:novel-frontier-collins-one-set}Let \(S\subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula \(F\) containing \(s\) different polynomials in \(\mathbb{R}[x_1,\ldots,x_n]\), having maximum degree \(d\).
There is an algorithm, taking \(F\) as input, which produces a cylindrical decomposition \(\mathcal E\) of \(\mathbb{R}^n\) compatible with \(S\).
Complexity, number of cells, number of polynomials and degrees are the same as in Proposition \ref{prp:novel-frontier-collins}.
\end{proposition}

\begin{proof}
Observe that this is the same as the algorithm as in Proposition \ref{prop:collins-sets} taking \(\{F\}\) as input.
\end{proof}

\hypertarget{computing-the-frontier}{%
\subsection{Computing the Frontier}\label{computing-the-frontier}}

Now we describe an algorithm, having singly-exponential complexity, for finding the frontier, \({\operatorname{fr} \left( S \right)}={\operatorname{cl} \left( ( \right)}S) \setminus S\),
of a semialgebraic set \(S \subset \mathbb{R}^n\).

\begin{lemma}
\protect\hypertarget{lem:novel-frontier-fr}{}\label{lem:novel-frontier-fr}Let \(S \subset \mathbb{R}^n\) be a semialgebraic set defined by a quantifier-free Boolean formula \(F\)
containing \(s\) different polynomials in \(\mathbb{R}[x_1, \ldots ,x_n]\) having maximum degree \(d\).
There is an algorithm, taking \(F\) as input, which represents the semialgebraic set \({\operatorname{fr} \left( ( \right)}S)\) by a quantifier-free Boolean formula \(F'\) with complexity \((sd)^{O(n^2)}\).
This is also an upper bound on the number of polynomials in \(F'\) and their degrees.
\end{lemma}

:::
Observe that \({\operatorname{fr} \left( S \right)}\) can be represented by a first-order Boolean formula
\[
{\operatorname{fr} \left( S \right)} = \left\{ \mathbf{x} \in (\mathbb{R}^n \setminus S) \mid \forall \varepsilon >0\> \exists \mathbf{y} \in S\> (\Vert \mathbf{x} - \mathbf{y} \Vert < \varepsilon ) \right\}.
\]
Using singly-exponential quantifier elimination algorithm \citet{bpr2006}, Algorithm 14.21, we represent \({\operatorname{fr} \left( ( \right)}S)\)
as a quantifier-free Boolean formula \(F'\) with the bounds required in the lemma.
:::

\hypertarget{obtaining-the-frontier-condition}{%
\section{Obtaining the frontier condition}\label{obtaining-the-frontier-condition}}

Recall that, according to Definition \ref{def:cells}, to each cylindrical cell in a CAD of \(\mathbb{R}^n\) a (multi-)index
\((i_1, \ldots ,i_n) \in \{ 0,1 \}^n\) is assigned.
Introduce a lexicographic order \(<_{\rm{lex}}\) on the set of all cell indices as follows.
For any two indices, \(M:=(i_1,\ldots,i_n)\) and \(N:=(j_1,\ldots,j_n)\), we set \(M <_{\rm{lex}}N\)
iff for the maximal \(k,\ 0 \le k <n\), such that \(i_1=j_1, \ldots, i_k=j_k\) we have \(i_{k+1} < j_{k+1}\).
If \(M <_{\rm{lex}}N\) or \(M = N\), we write \(M \le_{\rm{lex}}N\).

\begin{lemma}
\protect\hypertarget{lem:novel-frontier-fr-lex-less}{}\label{lem:novel-frontier-fr-lex-less}Let \(\mathcal{D}\) be a CAD of \(\mathbb{R}^n\) and let \(C\) be a cell of \(\mathcal{D}\) with index \(M\).
Then \({\operatorname{fr} \left( C \right)}\) is contained in a union of cells of \(\mathcal{D}\) with indices lexicographically less than \(M\).
\end{lemma}

\begin{proof}
Proceed by induction on \(n\).

When \(n=1\), the cell \(C\) either has index \(M=(0)\) or \(M=(1)\).
If \(M=(0)\) then \(C\) is a single point and its frontier is empty.
If \(M=(1)\), \(C\) is an open interval. By the definition of CAD, endpoints of \(C\) are \((0)\)-cells.

Now let \(n>1\) and let \(C\) have index \(M=(i_1,\ldots,i_n)\).
The projection \(C'=\operatorname{proj}_{\mathbb{R}^{n-1}}(C)\) is a cell in the induced decomposition \(\mathcal{D'}\) of \(\mathbb{R}^{n-1}\)
with index \((i_1,\ldots,i_{n-1})\).
By the induction hypothesis, \({\operatorname{fr} \left( C' \right)}\) is contained in a union of cells of \(\mathcal{D'}\) with indices
\((j_1,\ldots,j_{n-1}) <_{\rm{lex}}(i_1,\ldots,i_{n-1})\).

If \(i_n=0\), then \(C\) is a section cell.
Its frontier \({\operatorname{fr} \left( ( \right)}C)\) is contained in \({\operatorname{fr} \left( ( \right)}C') \times \mathbb{R}\) and, therefore, in a union of
cells of \(\mathcal D\) with indices \((j_1,\ldots,j_{n-1}, j_n)\) for some \(j_n \in \{ 0,1 \}\). We have shown that \((j_1,\ldots,j_{n-1}, j_n) <_{\rm{lex}}M\).

If \(i_n=1\), then \(C\) is a sector cell.
In this case, \({\operatorname{fr} \left( ( \right)}C)\) is contained in \(({\operatorname{fr} \left( ( \right)}C') \times \mathbb{R}) \cup C_T \cup C_B\), hence in the
union of cells of \(\mathcal D\) with indices \((j_1,\ldots,j_{n-1}, j_n)\) for some \(j_n\)
and two cells, \(C_T\) and \(C_B\), having the same index \((i_1,\ldots,i_{n-1},0)\).
All of these indices are lexicographically less than \(M\).
\end{proof}

In further proofs we will need the following technical statement.

\begin{lemma}
\protect\hypertarget{lem:novel-frontier-section-split}{}\label{lem:novel-frontier-section-split}Let \(f: X \to \mathbb{R}\) be a continuous polynomial function on an open set
\(X \subset \mathbb{R}^n\) having the graph \(F \subset \mathbb{R}^{n+1}\).
Let \(G\) be a semialgebraic subset of \(F\), which is closed in \(F\), and having dimension less than \(\dim (F)=n\).
Then \({\operatorname{fr}_{F} \left( F \setminus G \right)} = G\), where \(\operatorname{fr}_{F}\) denotes the frontier in \(F\).
\end{lemma}

\begin{proof}
Let \(Y = \operatorname{proj}_{\mathbb{R}^{n-1}}(G)\) and observe that \(X = \operatorname{proj}_{\mathbb{R}^{n-1}}(F)\).
Let us first prove that \({\operatorname{fr}_{X} \left( X \setminus Y \right)} = Y\).
By the definition of frontier, we have
\[{\operatorname{fr}_{X} \left( X \setminus Y \right)}={\operatorname{cl}_{X} \left( X \setminus Y \right)} \setminus (X \setminus Y),\]
where \(\operatorname{cl}_X\) denotes the closure in \(X\).
\({\operatorname{cl}_{X} \left( X \setminus Y \right)}=X\). Indeed, \(X\setminus Y\) is open and \(n\)-dimensional since \(Y\) is closed in \(X\) and \(\dim(Y)<n\).
Assume that \({\operatorname{cl}_{X} \left( X \setminus Y \right)} \ne X\). Then there is a nonempty subset \(Z\subset X\) such that \(Z \not \subset {\operatorname{cl}_{X} \left( X \setminus Y \right)}\). Since \(X \setminus Y \subset {\operatorname{cl}_{X} \left( X \setminus Y \right)}\), \(Z\) is necessarily a subset of \(Y\) and \(Z\) has dimension \(<n\). This implies that \({\operatorname{cl} \left( X \right)}{X\setminus Y}\) is not, which is a contradiction.
It follows that \({\operatorname{fr}_{X} \left( X \setminus Y \right)}=X \setminus (X \setminus Y)= X \cap Y = Y\).

Finally, since \(f\) is a continuous function, and therefore \(Y\) and \(X\) are homeomorphic to \(G\) and \(F\)
respectively, we obtain the required formula \({\operatorname{fr}_{F} \left( F \setminus G \right)} = G\).
\end{proof}

We now prove that the decomposition induced on \(\mathbb{R}^k, 1 \le k \le n-1\) by any CAD satisfying the frontier condition also satisfies the frontier condition.

\begin{theorem}
\protect\hypertarget{thm:novel-frontier-proj}{}\label{thm:novel-frontier-proj}Let \(\mathcal{D}\) be a CAD of \(\mathbb{R}^n\) compatible with a semialgebraic set \(S\subset \mathbb{R}^n\) and satisfying the frontier condition.
Then the decomposition induced by \(\mathcal{D}\) on \(\mathbb{R}^{k}\) for all \(1\le k < n\) is a cylindrical decomposition of \(\mathbb{R}^k\) compatible with \(\operatorname{proj}_{\mathbb{R}^k}(S)\) and satisfying the frontier condition.
\end{theorem}

\begin{proof}
Let \(\mathcal{D}\) be a CAD compatible with \(S\) and satisfying the frontier condition.
By the definition of CAD, \(\operatorname{proj}_{\mathbb{R}^k0}(S)\) is a union of cells in the decomposition induced by \(\mathcal{D}\) on \(\mathbb{R}^k\) for all \(1\le k \le n-1\).

We now prove that if \(\mathcal{D}\) satisfies the frontier condition then all decompositions induced by \(\mathcal{D}\) on \(\mathbb{R}^k\) for all \(1 \le k \le n-1\) satisfy the frontier condition.
Consider \(\Gamma\), the union of cells of \(\mathcal{D}\) contained in the \(k\)-dimensional cylinder \(\operatorname{proj}_{\mathbb{R}^{n-1}}(C) \times \mathbb{R}\) where \(C\) is a cell of \(\mathcal{D}\).
Observe that \(\bigcup_{C \in \Gamma} C = \operatorname{proj}_{\mathbb{R}^{n-1}}(C) \times \mathbb{R}\).
Consider \[
{\operatorname{fr} \left( \Gamma \right)} := \bigcup_{C \in \Gamma} {\operatorname{fr} \left( C \right)} \setminus \bigcup_{C \in \Gamma} C . % \left( \proj_{\R^{n-1}}(C) \times \R \right).
\]
Observe that \({\operatorname{fr} \left( \Gamma \right)}\) is a union of cells of \(\mathcal{D}\) since every cell \(C\) in \(\Gamma\) satisfies the frontier condition. \% since \(\operatorname{proj}_{\mathbb{R}^{n-1}}(C) \times \mathbb{R}\) is the union of cells of \(\mathcal{D}\) contained in \(\Gamma\) and every cell \(C\) in \(\Gamma\) satisfies the frontier condition.
We claim that \({\operatorname{fr} \left( \Gamma \right)}\) is the union of some similarly defined cylinders of dimension less than \(k\).
Proceed by induction on \(k\).

The base case, \(k=1\), is simple since \({\operatorname{fr} \left( \Gamma \right)} = \emptyset\).

Now suppose that \(k>1\). Each sector cell in \(\Gamma\) has dimension \(k\) and each section cell in \(\Gamma\) has dimension \(k-1\), so the dimension of the union of frontiers of all cells in \(\Gamma\) is at most \(k-1\).
Hence \(\dim({\operatorname{fr} \left( \Gamma \right)})\) is at most \(k-1\).
By the cylindrical property of CAD, the projection of any two cells contained in \({\operatorname{fr} \left( \Gamma \right)}\) is either disjoint or coincides. Therefore, \({\operatorname{fr} \left( \Gamma \right)}\) is a union of cylinders \(\Gamma' := \operatorname{proj}_{\mathbb{R}^{n-1}}(B) \times \mathbb{R}\) where \(B\) is a cell of \(\mathcal{D}\) contained in \({\operatorname{fr} \left( \Gamma \right)}\). Observe tthat each cylinder \(\Gamma'\) has dimension less than \(k\).
By the induction hypothesis, \({\operatorname{fr} \left( \Gamma' \right)}\) is a union of cylinders with dimension less than \(\dim(\Gamma')\).

By the definition of CAD, each of these cylinders \(\Gamma'\) projects onto a single cell in the decomposition \(\mathcal{D'}\) induced by \(\mathcal{D}\) on \(\mathbb{R}^{n-1}\). Hence \({\operatorname{fr} \left( C' \right)}\), where \(C' := \operatorname{proj}_{\mathbb{R}^{n-1}}(C)\) for all \(C \in \Gamma\) is a union of cells \(B' := \operatorname{proj}_{\mathbb{R}^{n-1}}(B)\) of \(\mathcal{D'}\) for all \(B \in \Gamma'\).
It follows that \(\mathcal{D'}\) satisfies the frontier condition.

The proof that every decomposition induced by \(\mathcal{D}\) on \(\mathbb{R}^{k}, 1 \le k \le n-1\) satisfies the frontier condition is completed by iterating the projection operation.
\end{proof}

\hypertarget{proof-of-theorem-refthmnovel-frontier-main}{%
\subsection{Proof of Theorem \ref{thm:novel-frontier-main}}\label{proof-of-theorem-refthmnovel-frontier-main}}

We are now ready to prove the main result. The worked example, presented in Section \ref{sec:worked-example} is referenced to help illustrate the procedure.
We begin with a mathematical description of the algorithm.

\hypertarget{algorithm}{%
\subsubsection{Algorithm}\label{algorithm}}

\textbf{Input:} \(F\), a quantifier-free Boolean formula defining a semialgebraic set \(S \subset \mathbb{R}^n\)

\textbf{Output:} \(\mathcal{D}\), a CAD of \(\mathbb{R}^n\) compatible with \(S\) and satisfying the frontier condition\textbackslash{}

First, apply algorithm from Proposition \ref{prp:novel-frontier-collins-one-set} to \(F\). We obtain a CAD \(\mathcal E\) of \(\mathbb{R}^n\)
compatible with \(S\).

The algorithm computes a sequence of pairs \(({\mathcal E}_M,\ X_M)\) where \(M \in \{0,1\}^{n-1}\) is an index, \(\mathcal{E}_M\) is a CAD of \(\mathbb{R}^n\), which is a refinement of \(\mathcal{E}\), and \(X_M \subset \mathbb{R}^n\) is a semialgebraic set contained in the union of all cells of \({\mathcal E}_M\) with indices \(\le_{\rm{lex}}(i_1,\ldots,i_{n-1},1)\). This family of cells will be denoted by \(\mathcal{U}_M\). Note that index \(M\) refers to the pair rather than its elements and \(\mathcal{E}_M\) and \(X_M\) are written with indices for convenience.

The sequence of pairs is computed recursively, starting with index \(M=(1,1, \ldots ,1)\),
in descending order of indices \(M=(i_1, \ldots, i_{n-1})\) with respect to \(<_{\rm{lex}}\).
Let the initial pair \(({\mathcal E}_{(1, \ldots, 1)},\ X_{(1, \ldots, 1)}) = ({\mathcal E},\ \emptyset)\). The algorithm will construct a sequence (from right to left):
\begin{equation}
({\mathcal E}_{\mathbf{0}}, X_{\mathbf{0}}) <_{\rm{lex}}\cdots <_{\rm{lex}}
%({\mathcal E}_L, X_L) \lex 
({\mathcal E}_N, X_N) <_{\rm{lex}}({\mathcal E}_M, X_M)
<_{\rm{lex}}\cdots
<_{\rm{lex}}({\mathcal E} , \emptyset),
\label{eq:sequence}
\end{equation}
where index \((0,0,\ldots,0)\) is abbreviated to \(\mathbf{0}\) and \(X_{\mathbf{0}}= \bigcup \{ C \in{\mathcal U}_{(0, \ldots ,0)} \}\).

For a given index \(M=(i_1,\ldots,i_{n-1})\), assume that the algorithm has computed the pair \((\mathcal{E}_M,\ X_M)\).
Now we describe how the next pair, \(({\mathcal E}_N,\ X_N)\), where \(N=(j_1, \ldots ,j_{n-1})\) is the index immediately prior to \(M\) with respect to \(<_{\rm{lex}}\), is computed.
Applying algorithm from Proposition \ref{prp:novel-frontier-collins-sets} to \({\mathcal E}_M\) and \(X_M\), we get a CAD
\({\mathcal E}_{N}\) of \(\mathbb{R}^n\) compatible with \(X_M\) and every cell of \({\mathcal E}_M\) (see construction of \(\mathcal{E}_{(0,1)}\) in step \ref{step:one-zero} of the worked example).
Consider the family \({\mathcal A}_0\) of cells in \({\mathcal E}_{N}\) with indices \((i_1,\ldots,i_{n-1},0)\)
(section cells)
and the family \({\mathcal A}_1\) of cells in \({\mathcal E}_{N}\) with indices \((i_1,\ldots,i_{n-1},1)\)
(sector cells).
Using algorithm from Lemma \ref{lem:novel-frontier-fr}, compute the set
\begin{equation}\
X_{N}:= \bigcup_{C \in {\mathcal A}_0}{\operatorname{fr} \left( ( \right)}C) \cup \bigcup_{C \in {\mathcal A}_1}({\operatorname{fr} \left( ( \right)}C) \setminus (C_T \cup C_B)).
\label{eq:front}
\end{equation}
Observe that for every cell \(C \in {\mathcal A}_1\), \(C_T\) and \(C_B\) are section cells with index \((i_1,\ldots,i_{n-1},0)\) in \({\mathcal A}_0\).
According to Lemma @ref\{lem:novel-frontier-fr-lex-less), \(X_{N}\) is contained in the union of cells in \({\mathcal E}_{N}\)
with indices \(<_{\rm{lex}}(i_1,\ldots,i_{n-1},0)\) (see construction of \(X_{(1,0)}\) in step \ref{step:one-one} of the worked example).

When the algorithm reaches the final pair \(({\mathcal E}_{\mathbf{0}}, X_{\mathbf{0}})\) in the sequence,
it computes a CAD \(\mathcal D\), using algorithm from Proposition \ref{prp:novel-frontier-collins-sets}, compatible
with \(X_{\mathbf{0}}\) and every cell of \({\mathcal E}_{\mathbf{0}}\). The algorithm terminates by returning \(\mathcal D\).
\medskip

\hypertarget{correctness}{%
\subsubsection{Correctness}\label{correctness}}

Let \(L=(k_1, \ldots ,k_{n-1})\) be the index immediately prior
to \(N=(j_1, \ldots ,j_{n-1} )\) with respect to \(<_{\rm{lex}}\).
The algorithm computes \({\mathcal E}_L\) as the refinement of \({\mathcal E}_N\) compatible with \(X_N\) (see Equation \eqref{eq:front}). Suppose that the algorithm has computed the final decomposition \(\mathcal{D}\), as the refinement of \(\mathcal{E}_{\mathbf{0}}\) compatible with \(X_{\mathbf{0}}\) in the sequence \ref{eq:sequence}. Now construct a new sequence of decompositions (from left to right)
\begin{equation}
\mathcal{E}'_{\mathbf{0}} <_{\rm{lex}}\cdots <_{\rm{lex}}\mathcal{E}'_L <_{\rm{lex}}\mathcal{E}'_N <_{\rm{lex}}\mathcal{E}'_M <_{\rm{lex}}\cdots <_{\rm{lex}}\mathcal{E}'_{(1,\ldots,1)}

(#eq:seq-ind-hyp)
\end{equation}
where the initial element \(\mathcal{E}'_{\mathbf{0}}\) is the refinement of \(\mathcal{E}_{\mathbf{0}}\) compatible with \(\mathcal{D}\) and each \(\mathcal{E}'_I\) is the refinement of \(\mathcal{E}_I\) compatible with all cells in \(\mathcal{E}'_J\) where \(J\) is the index immediately prior to \(I\) with respect to \(<_{\rm{lex}}\).
We want to prove that every cell in \(\mathcal{E}'_L\) with index \(\le_{\rm{lex}}(i_1,\ldots,i_{n-1},1)\) satisfies the frontier condition.

\% SECTION CASE
If \(C\) is a cell in \({\mathcal E}_N\) with index \((i_1, \ldots ,i_{n-1} ,0)\) (section cell),
then \(C\) is a union of cells of \({\mathcal E}_L\) and, hence, of \(\mathcal{E}'_L\), with indices \(\le_{\rm{lex}}(i_1, \ldots ,i_{n-1} ,0)\).
Let \(C' \subset C\) be one of the cells in this refinement of \(C\) with index \((i_1, \ldots ,i_{n-1} ,0)\) and \(B\) be
the union of cells contained in the refinement of \(C\) with indices \(<_{\rm{lex}}(i_1, \ldots ,i_{n-1} ,0)\).
According to Lemma \ref{lem:novel-frontier-section-split}, \({\operatorname{fr}_{C} \left( C \setminus B \right)}=B\) where \({\operatorname{fr}_{X} \left( Y \right)}\) denotes the frontier of \(Y\) in \(X\).
Hence, \({\operatorname{fr}_{C} \left( C' \right)} \subset B\).
On the other hand, \({\operatorname{fr} \left( ( \right)}C') \setminus {\operatorname{fr} \left( C \right)}{C'}\) is a subset of \({\operatorname{fr} \left( ( \right)}C)\), which is a union of cells of \(\mathcal{E}_L\) (and of the refinement \(\mathcal{E}'_L\)) with index \(<_{\rm{lex}}(i_1,\ldots,i_{n-1},0)\).
By the induction hypothesis, all cells of \(\mathcal{E}'_L\) with index \(<_{\rm{lex}}(i_1,\ldots,i_{n-1},0)\) satisfy the frontier condition. In particular, \({\operatorname{fr} \left( ( \right)}C)\) and \({\operatorname{fr} \left( ( \right)}B)\subset {\operatorname{fr} \left( ( \right)}C)\) is a union of cells of \(\mathcal{E}'_L\).
It follows from the cylindrical structure of \(\mathcal{E}'_L\) that \(C'\) satisfies the frontier condition.

\% SECTOR CASE
If \(C\) is a cell in \({\mathcal E}_N\) with index \((i_1, \ldots ,i_{n-1} ,1)\) (sector cell),
then \(C\) is a union of cells of \({\mathcal E}_L\) with indices \(\le_{\rm{lex}}(i_1, \ldots ,i_{n-1} ,1)\).
A similar argument to that used for section cells shows that each cell \(C'\) in this union,
having index \((i_1, \ldots ,i_{n-1} ,1)\), satisfies the frontier condition in \(\mathcal{E}'_L\). Note that when using
Lemma \ref{lem:novel-frontier-section-split} we consider sector cell \(C\) as a graph of a constant function over itself.

\% final note: plot twist, E'\_M is just D.
Finally, each decomposition \(\mathcal{E}'_I\), \(I \in \{0,1\}^{n-1}\), in the sequence \ref{eq:seq-ind-hyp} coincides with \(\mathcal{D}\). Indeed, \(\mathcal{D}\) is a refinement of \(\mathcal{E}_I\) and \(\mathcal{E}'_I\) is a refinement of \(\mathcal{E}_I\) compatible with all cells of \(\mathcal{D}\). In other words, no refinement of \(\mathcal{D}\) is required to obtain \(\mathcal{E}'_{(1,\ldots,1)}\).
It follows that every cell of \(\mathcal{D}\) satisfies the frontier condition.

\hypertarget{complexity}{%
\subsubsection{Complexity}\label{complexity}}

The number of different indices \((i_1, \ldots, i_n)\), where each \(i_k \in \{ 0,1 \}\), is \(2^n\).
Therefore, the algorithm makes \(O(2^n)\) ``steps'\,': computing successive pairs \(({\mathcal E}_M, X_M)\) in the sequence (\ref{eq:sequence}).
On each step, passing from a pair \((\mathcal{E}_M,\ X_M)\) to the next pair \((\mathcal{E}_N,\ X_N)\), the algorithm applies Proposition \ref{prp:novel-frontier-collins} to \(({\mathcal E}_M, X_M)\) and obtains a CAD
\({\mathcal E}_N\) which is a refinement of \({\mathcal E}_M\) compatible with \(X_M\).
Then Lemma \ref{lem:novel-frontier-fr} is applied to each cell with index \((i_1,\ldots,i_{n-1},i_n)\) in \({\mathcal E}_N\)
to obtain \(X_N\).

Suppose that there are \(s_M\) polynomials defining \({\mathcal E}_M\) and \(X_M\), having degrees at most \(d_M\).
Then, according to Proposition \ref{prp:novel-frontier-collins-sets}, the CAD \({\mathcal E}_N\) is defined by
\(s_N:=(s_Md_M)^{O(1)^n}\) polynomials of degrees \(d_N=(s_Md_M)^{O(1)^n}\).
The number of cells in \({\mathcal E}_N\) is asymptotically the same: \((s_Md_M)^{O(1)^n}\).
Then the algorithm applies Lemma \ref{lem:novel-frontier-fr-lex-less} to compute \(X_N\).
The complexity of this application is \((s_Md_M)^{n^2O(1)^n}\), which is asymptotically the same as \((s_Md_M)^{O(1)^n}\).
Thus, the overall complexity of this ``step'\,' is again \((s_Md_M)^{O(1)^n}\). The overall complexity is obtained by iterating this process for each index.
Given that \(s_{(1, \ldots,1)}=s\) and \(d_{(1, \ldots,1)}=d\), we conclude that
the complexity of the algorithm is
\[
(sd)^{O(1)^{n2^n}}.
\]
This is also an upper bound on the number of cells in \(\mathcal D={\mathcal E}_{\mathbf{0}}\), the number of polynomials defining cells and their degrees.
\textbackslash end\{proof\}

\hypertarget{an-aside-on-constructing-the-intermediate-decompositions}{%
\subsection{An Aside on Constructing the Intermediate Decompositions}\label{an-aside-on-constructing-the-intermediate-decompositions}}

Throughout this algorithm we construct ``a CAD compatible with \(F\) and all cells of \(\mathcal{E}\)'\,'.
This can be achieved by constructing a CAD, using Proposition \ref{prp:novel-frontier-collins}, such that each cell has constant sign on the polynomials defining \(F\) and all cells of \(\mathcal{E}\). Such a CAD is clearly compatible with \(F\) and all cells of \(\mathcal{E}\). However, it may include some cells, outside \({\operatorname{cl} \left( ( \right)}S)\), which we are not interested in.

An alternative is to use the algorithm described in Proposition \ref{prp:novel-frontier-collins-sets} to construct a CAD compatible with \(\{F, C_1,\ldots,C_r\}\) where \(C_i,1\le i \le r\) is a cell of \(\mathcal{E}\) such that \(\bigcup_{1\le i \le r} C_i = \mathbb{R}^n\). Observe that this CAD is compatible with the required sets.

Both options have the same asymptotic complexity. Therefore, the choice of CAD subroutine does not change the complexity bound obtained in the proof of Theorem \ref{thm:novel-frontier-main}. In the proof, Proposition \ref{prp:novel-frontier-collins-one-set}, constructing a CAD compatible with a semialgebraic set \(S\subset \mathbb{R}^n\), is used to construct the initial CAD and Proposition @ref\{prp:novel-frontier-collins-sets), constructing a CAD compatible with a family of sets, is used for constructing the refinements of intermediate decompositions.

It is assumed that every cell in \(\mathcal{E}\) can be represented as a quantifier-free Boolean formula. This is always possible by Thom's Lemma, but, as shown by Brown in \citet{brown99}, the polynomials produced during the construction of \(\mathcal{E}\) may not be sufficient to do so. It is possible to obtain the required polynomials by using Collins' extended projection. Brown \citet{brown99} also presents an algorithm that ensures every cell can be represented by a formula containing projection polynomials and, possibly, a small number of derivatives. This may be the preferred option since fewer extra polynomials are needed.

\hypertarget{sec:novel-frontier-worked-example}{%
\section{Worked Example}\label{sec:novel-frontier-worked-example}}

We demonstrate the algorithm from Theorem\textasciitilde{}\ref{th:main} by applying it to the set
\[
S := \{ -1 < x < 1, \vert x\vert <y <1, z=\vert x/y\vert \}
\]
from Example\textasciitilde{}\ref{exm:top-bottom-not-cylindrical}. Construct a CAD \(\mathcal{E}\) of \(\mathbb{R}^3\) compatible with \(S\) (see Table \ref{exm:cells-of-e}). Observe that \(S\) is a single 2-dimensional cylindrical \((1,1,0)\)-cell of \(\mathcal{E}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (\#step:one-one)
  The initial pair \((\mathcal{E}_{(1,1)}, X_{(1,1)}) = (\mathcal{E}, \emptyset)\). We now describe how the next pair in the sequence (\ref{eq:sequence}) is computed.
  \(\mathcal{E}_{(1,0)}\), the CAD compatible with all cells of \(\mathcal{E}_{(1,1)}= \mathcal{E}\) and \(X_{(1,1)} = \emptyset\), is equal to \(\mathcal{E}\). \(X_{(1,0)}\) is contained in the union of cells of \(\mathcal{E}_{(1,0)}\) with index \(<_{\rm{lex}}(1,1,0)\) and includes
  \[
  {\operatorname{fr} \left( ( \right)}S) = S_B \cup S_T \cup \{ (-1,1,1), (1,1,1) \}
  \]
  where
  \[
  S_T = \{ -1 < x < 1, y = 1, z = \vert x \vert \}
  \]
  and
  \begin{align*}
  S_B = &\{ -1 < x < 0, y = -x, z = 1 \} \cup \\
  & \{ x = y = 0, 0 \le z \le 1 \} \cup\\
  & \{ 0 < x < 1, y = x, z = 1 \}.
  \end{align*}
  Observe that \(C_T\) could be a \((1,0,0)\)-cell (although it is not a cell in \(\mathcal{E}_{(1,0)}\)), but \(C_B\) cannot be a cell in any cylindrical decomposition since it is not the graph of a continuous function.
\item
  (\#step:one-zero)
  Given \((\mathcal{E}_{(1,0)}, X_{(1,0)})\), compute the next pair.
  \(\mathcal{E}_{(0,1)}\) is compatible with every cell of \(\mathcal{E}_{(1,0)} = \mathcal{E}\) and \(X_{(1,0)} \supset {\operatorname{fr} \left( ( \right)}S)\).
  The blow-up subset \(\{ x = y = 0, 0 \le z \le 1 \}\) in \(X_{(1,0)}\) results in a refinement of the decomposition induced by \(\mathcal{E}_{(1,0)}\) on \(\mathbb{R}^1\) such that it includes the cells \(\{-1 < x < 0\}, (0), \{ 0 < x < 1 \}\). Thus \(\mathcal{E}_{(0,1)}\) includes a cell \(S'' = \{ x = 0, 0 < y < 1, z = 0 \}\) and \(S\) is split into three cells \(S', S'', S'''\) with indices \((1,1,0),(1,0,0)\) and \((1,1,0)\) respectively.
  Cells \(C_1,C_2,C_3\) and \(C_4\) of \(\mathcal{E}_{(1,0)} = \mathcal{E}\) are also refined in this step so that they are compatible with \({\operatorname{fr} \left( ( \right)}S)\) (see Table \ref{exm:cells-of-e-refined}). As argued in the Correctness section, frontiers \({\operatorname{fr} \left( S \right)}{S'}\) and \({\operatorname{fr}_{S} \left( S''' \right)}\) coincide with \(S''\), so no further refinements of cells with index \((1,1,1)\) and \((1,1,0)\) are needed.
  \(X_{(0,1)}\) contains \({\operatorname{fr} \left( ( \right)}C'_2), {\operatorname{fr} \left( ( \right)}C'''_2), {\operatorname{fr} \left( ( \right)}C'_3)\) and \({\operatorname{fr} \left( ( \right)}C'''_3)\).
\item
  (\#step:zero-one)
  Observe that, in this particular case, \(X_{(0,1)}\) is already a union of cells of \(\mathcal{E}_{(0,1)}\), so \(\mathcal{E}_{(0,0)} = \mathcal{E}_{(0,1)}\) as no refinement is needed.
  \(X_{(0,0)}\) contains \({\operatorname{fr} \left( ( \right)}S')\).
\item
  \(X_{(0,0)}\) is already a union of cells, so no refinement of \(\mathcal{E}_{(0,0)} = \mathcal{E}_{(0,1)}\) is needed. The algorithm terminates and returns \(\mathcal{D} = \mathcal{E}_{(0,1)}\).
\end{enumerate}

\begin{example}
\protect\hypertarget{exm:cells-of-e}{}\label{exm:cells-of-e}** TODO: table environment **

\begin{longtable}[]{@{}lll@{}}
\toprule
Label & Index & Formula\tabularnewline
\midrule
\endhead
& \((1,1,1)\) & \(\{ x < -1 \}\)\tabularnewline
\(C_1\) & \((0,1,1)\) & \(\{ x = -1 \}\)\tabularnewline
& \((1,1,1)\) & \(\{ -1 < x < 1, y < \vert x \vert \}\)\tabularnewline
\(C_2\) & \((1,0,1)\) & \(\{ -1 < x < 1, y = \vert x \vert \}\)\tabularnewline
& \((1,1,1)\) & \(\{ -1 < x < 1, \vert x \vert < y < 1, z < \vert x/y \vert \}\)\tabularnewline
\(S\) & \((1,1,0)\) & \(\{ -1 < x < 1, \vert x \vert < y < 1, z = \vert x/y \vert \}\)\tabularnewline
& \((1,1,1)\) & \(\{ -1 < x < 1, \vert x \vert < y < 1, z > \vert x/y \vert \}\)\tabularnewline
\(C_3\) & \((1,0,1)\) & \(\{ -1 < x < 1, y = 1 \}\)\tabularnewline
& \((1,1,1)\) & \(\{ -1 < x < 1, y > 1 \}\)\tabularnewline
\(C_4\) & \((0,1,1)\) & \(\{ x = 1 \}\)\textbackslash{}\tabularnewline
& \((1,1,1)\) & \(\{ x > 1 \}\)\textbackslash{}\tabularnewline
\bottomrule
\end{longtable}

All cells of the CAD \(\mathcal{E}\), the initial CAD computed in Section \ref{sec:novel-frontier-worked-example}.
\end{example}

\begin{example}
\protect\hypertarget{exm:cells-of-e-refined}{}\label{exm:cells-of-e-refined}:** TODO: table environment **

\begin{longtable}[]{@{}lll@{}}
\toprule
Label & Index & Formula\tabularnewline
\midrule
\endhead
\({C'_1}\) & \((0,0,0)\) & \(\{ x = 0, y = 1, z = 1 \}\)\tabularnewline
\({C'_2}\) & \((1,0,0)\) & \(\{ -1 < x < 0, y = -x, z = 1 \}\)\tabularnewline
\({C''_{2,1}}\) & \((0,0,0)\) & \(\{ x = y = 0, z = 0 \}\)\tabularnewline
\({C''_{2,2}}\) & \((0,0,1)\) & \(\{ x = y = 0, 0 < z < 1 \}\)\tabularnewline
\({C''_{2,3}}\) & \((0,0,0)\) & \(\{ x = y = 0, z = 1 \}\)\tabularnewline
\({C'''_2}\) & \((1,0,0)\) & \(\{ 0 < x < 1, y = x, z = 1 \}\)\tabularnewline
\(S'\) & \((1,1,0)\) & \(\{ -1 < x < 0, -x < y < 1, z = -x/y \}\)\tabularnewline
\(S''\) & \((0,1,0)\) & \(\{ x = 0, 0 < y < 1, z = 0 \}\)\tabularnewline
\(S'''\) & \((1,1,0)\) & \(\{ 0 < x < 1, x < y < 1, z = x/y \}\)\tabularnewline
\(C'_3\) & \((1,0,0)\) & \(\{ -1 < x < 0, y = 1, z = -x \}\)\tabularnewline
\(C''_3\) & \((0,0,0)\) & \(\{ x = 0, y = 1, z = 0\}\)\tabularnewline
\(C'''_3\) & \((1,0,0)\) & \(\{ 0 < x < 1, y = 1, z = x \}\)\tabularnewline
\({C'_4}\) & \((0,0,0)\) & \(\{ x = 1, y = 1, z = 1 \}\)\tabularnewline
\bottomrule
\end{longtable}

Cells of the CAD \(\mathcal{E}_{(0,1)}\) computed in step \ref{step:one-zero} of Section\textasciitilde{}\ref{sec:worked-example}. Note that only cells which are part of \({\operatorname{cl} \left( ( \right)}S)\) are listed.
\end{example}

Well-known implementations of cylindrical algebraic decomposition such as \emph{QEPCAD B} \citep{brownQepcad} and Maple's \emph{CylindricalAlgebraicDecompose} \citep{chen2014} are unable to obtain the frontier condition in general. In particular, when applied to set \(S\) from Example\textasciitilde{}\ref{exm:top-bottom-not-cylindrical}, both \emph{CylindricalAlgebraicDecompose} and \emph{QEPCAD B} create three cells above the origin: \(B' = \{ x = y = 0, z < 0\}\), \(B'' = \{ x = y = 0, z = 0\}\) and \(B''' = \{ x = y = 0, z > 0\}\). Observe that \(B''' \cap {\operatorname{fr} \left( ( \right)}S) \ne \emptyset\), but \(B''' \not \subset {\operatorname{fr} \left( ( \right)}S)\) so the frontier of \(S\) is not a union of cells in the decomposition.

\hypertarget{pseudo-code}{%
\section{Pseudo-code}\label{pseudo-code}}

We now present the algorithm from Theorem\textasciitilde{}\ref{thm:novel-frontier-main} as pseudo-code. First define the following basic subroutines.

\begin{itemize}
\item
  \({\mathcal B}:= {\mathcal A}\ \&\ G\) takes a CAD \(\mathcal A\) of \(\mathbb{R}^n\) and a semialgebraic set \(G \subset \mathbb{R}^n\),
  and returns a CAD \(\mathcal B\) of \(\mathbb{R}^n\) compatible with \(G\) and all cells of \(\mathcal A\).
  This subroutine follows from the algorithm in Proposition\textasciitilde{}\ref{prop:collins-sets}.
\item
  \(Y := {\operatorname{fr} \left( ( \right)}X)\) takes a set \(X \subset \mathbb{R}^n\) and returns its frontier.
  This subroutine follows from the algorithm in Lemma\textasciitilde{}\ref{le:frontier}.
\item
  \(N := \rm{decrement}(M)\) takes an index \(M \in \{0,1\}^k\) and returns the index \(N \in \{0,1\}^k\) immetiately prior to \(M\) with respect to \(<_{\rm{lex}}\).
\end{itemize}

\textbf{Input:}

\(F\): a quantifier-free Boolean formula representing a semialgebraic set \(S \subset \mathbb{R}^n\).

\textbf{Output:}

\(\cal D\): a CAD of \(\mathbb{R}^n\) compatible with \(S\) and satisfying the frontier condition.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\item
  Let \({\mathcal E}:= \mathbb{R}^n\ \&\ S\), where \(\mathbb{R}^n\) is a trivial CAD of \(\mathbb{R}^n\),
\item
  \(M := (1,\ldots,1) \in \{0,1\}^{n-1}\),
\item
  \(({\mathcal E}_M, F_M):=({\mathcal E}, \emptyset)\).
\item
  while \((0,\ldots,0) <_{\rm{lex}}M\), do

  \begin{itemize}
  \item
    Let \(N := {\rm decrement(M)}\).
  \item
    Construct \(X_N\) from cells of \(\mathcal E_M\) using ``\(\fr\)'\,' subroutine and formula\textasciitilde\eqref{eq:front}.
  \item
    Let \({\mathcal E}_N := {\mathcal E}_M\ \&\ X_N\),
  \item
    \(M := N\).
  \end{itemize}
\item
  Return \({\mathcal E}_M\)
\end{itemize}

\hypertarget{generalisations-and-further-work}{%
\section{Generalisations and further work}\label{generalisations-and-further-work}}

\hypertarget{first-order-formulas-with-quantifiers}{%
\subsection{First-order formulas with quantifiers}\label{first-order-formulas-with-quantifiers}}

Theorem \ref{thm:novel-frontier-main} describes an algorithm which takes a quantifier-free formula as input. However, Theorem \ref{thm:novel-frontier-proj} implies that this algorithm also works with first-order formula containing quantifiers. Indeed, by the Tarski-Seidenberg theorem, if \(\Phi(x_1,\ldots,x_n)\) is a first-order formula, then \((x_1,\ldots,x_n) \in \mathbb{R}^n\) satisfying \(\Phi(x_1,\ldots,x_n) \in \mathbb{R}^n\) is a semialgebraic set. In particular, let \(A \subset \mathbb{R}^n\) and \(B = \{ (y,x) \in \mathbb{R}^{n+k} \mid \Phi(y,x) \}\) be semialgebraic sets, then we can write
\begin{align*}
\{ y \in \mathbb{R}^k \mid \exists x \in A, \Phi(y,x) \} &= {\operatorname{proj}_{\mathbb{R}^{k}}}((\mathbb{R}^k \times A) \cap B)\\
\{ y \in \mathbb{R}^k \mid \forall x \in A, \Phi(y,x) \} &= \mathbb{R}^k \setminus {\operatorname{proj}_{\mathbb{R}^{k}}}((\mathbb{R}^k \times A) \cap (\mathbb{R}^{n+k} \setminus B)).
\end{align*}
In other words, quantifier elimination can be defined as projections and Boolean operations on semialgebraic sets, all of which preserve the frontier condition.

\hypertarget{pfaffian-functions-and-fewnomials}{%
\subsection{Pfaffian functions and fewnomials}\label{pfaffian-functions-and-fewnomials}}

Theorem \ref{thm:novel-frontier-main} can be extended to restricted sub-Pfaffian sets, as described by \citet{gv04}.
In particular, it can be used to prove the existence of decompositions with frontier condition compatible with semialgebraic sets defined by \emph{fewnomials} \citep[Section 2.6]{gv04}, whose structure would be destroyed by a change of coordinates, and obtain an upper bound on the number of cells in these decompositions.

The idea of the proof is still valid. Only a modification to the subroutines for computing the frontier, and for constructing a classical CAD, is needed. For the former, replace the quantifier elimination algorithm in Lemma \ref{lem:novel-frontier-fr} with the result of \citep[Section 5]{gv04}. In the latter case, the classical CAD algorithm from Proposition \ref{prp:novel-frontier-collins} should be replaced by the main result of \citet{gv01} (see also \citep[Section 7]{gv04}). The rest of the proof can be reproduced almost identically.

Note that it is not currently clear how this result can be implemented, since in the algorithm for cylindrical decomposition in \citet{gv01} the oracle is needed to decide whether a sub-Pfaffian set is empty or not.

\hypertarget{further-work}{%
\subsection{Further Work}\label{further-work}}

The complexity upper bound of the algorithm from Theorem\textasciitilde{}\ref{th:main} is significantly worse than the bound
for classical CAD algorithm presented by \citet{collins1975} and \citet{wuthrich2005}.
This is caused by the parameter of its recursive loop: the index of a cylindrical cell, which is exponential in the ambient dimension.\\
It is difficult to see another parameter that could make the recursion significantly shorter. Thus, if any progress is to be made towards a better asymptotic complexity, the method used may need to be based on a completely different ideas.
On the other hand, there is a lower bound on complexity of the classical CAD algorithm due to \citet{davenportHeintz1988}. However, it is not yet known whether the lower bound for CAD with frontier condition is greater than that of the classical CAD.
Another strand of research could be to explore this question, possibly by attempting to raise this lower bound for CAD with frontier condition.

Another improvement in the algorithm might come from a different subroutine for computing the frontier
of a cylindrical cell.
The subroutine from Lemma\textasciitilde{}\ref{le:frontier} works for any semialgebraic set and does not take advantage of its
cylindrical structure.
We may be able to exploit this structure by factorising the equational part of the formula
representing a cell into irreducible components, generalising the method due to \citet{lazard10} presented in Section \ref{sec:lazard-3}.

Finally, since some initial CAD is refined repeatedly, the classical CAD algorithm from Proposition\textasciitilde{}\ref{prop:collins} could be replaced with an incremental algorithm, E.g., the algorithm presented by \citet{kremer2020}. It is not clear whether substituting the CAD algorithm will reduce the complexity bound. The set \(X_N\) is still computed at each step, using a singly exponential algorithm, and the initial CAD may need to be refined at every step and this refinement may result in the incremental algorithm backtracking all the way to the decomposition induced on \(\mathbb{R}^1\). However, this change would be very useful in practice as unnecesary CAD recomputations could be avoided, E.g., if \(\mathcal{E}_N\) is already compatible with the set \(X_N\), the algorithm in its current form will compute the refinement even though it is not needed.

  \bibliography{references.bib}

\end{document}
